[
  {
    "category": "Easy",
    "Problems": [
      {
        "Topic": "Array Concept",
        "Info": {
          "Definition": "An array is a data structure that contains a group of elements. Typically these elements are all of the same data type, such as an integer or string. Arrays are commonly used to organize data so that a related set of values can be easily sorted or searched.",
          "Algorithms": {
            "Traversal": "for(int i = 0; i < arr.length; i++) {\n  System.out.println(arr[i]);\n}",
            "Insertion": "for(int i = arr.length-1; i > position; i--) {\n  arr[i] = arr[i-1];\n}\narr[position] = newValue;",
            "Deletion": "for(int i = position; i < arr.length-1; i++) {\n  arr[i] = arr[i+1];\n}",
            "Search": "for(int i = 0; i < arr.length; i++) {\n  if(arr[i] == searchValue) {\n    return i;\n  }\n}\nreturn -1;",
            "Update": "arr[position] = newValue;"
          },
          "Complexities": {
            "Time Complexities": {
              "Traversal": "O(n)",
              "Insertion": "O(n)",
              "Deletion": "O(n)",
              "Search": "O(n)",
              "Update": "O(1)"
            },
            "Space Complexity": "O(1)"
          }
        }
      },
      {
        "Topic": "Linear Search",
        "Info": {
          "Definition": "Linear Search is a searching algorithm that finds the position of a target value within an array. It sequentially checks each element of the array for the target value until a match is found or until all the elements have been searched.",
          "Algorithms": {
            "Basic Method": "for i = 0 to arr.length\nif arr[i] == x\n    return i\nreturn -1"
          },
          "Complexities": {
            "Time Complexities": {
              "Best case": "O(1)",
              "Average case": "O(n)",
              "Worst case": "O(n)"
            },
            "Space Complexity": "The space complexity of the linear search is O(1)."
          }
        }
      },
      {
        "Topic": "Binary Search",
        "Info": {
          "Definition": "Binary Search is a searching algorithm for finding an element's position in a sorted array. In this approach, the element is always searched in the middle of a portion of an array. Binary search can be implemented only on a sorted list of items. If the elements are not sorted already, we need to sort them first.",
          "Algorithms": {
            "Iterative Method": "do until the pointers low and high meet each other.\nmid = (low + high)/2\nif (x == arr[mid])\n    return mid\nelse if (x > arr[mid]) // x is on the right side\n    low = mid + 1\nelse                       // x is on the left side\n    high = mid - 1",
            "Recursive Method": "binarySearch(arr, x, low, high)\nif low > high\n    return False \nelse\n    mid = (low + high) / 2 \n    if x == arr[mid]\n        return mid\n    else if x > arr[mid]        // x is on the right side\n        return binarySearch(arr, x, mid + 1, high)\n    else                               // x is on the left side\n        return binarySearch(arr, x, low, mid - 1)"
          },
          "Complexities": {
            "Time Complexities": {
              "Best case": "O(1)",
              "Average case": "O(log n)",
              "Worst case": "O(log n)"
            },
            "Space Complexity": "The space complexity of the binary search is O(1)."
          }
        }
      },
      {
        "Topic": "Stack Data Structure",
        "Info": {
          "Definition": "A stack is a linear data structure that follows the principle of Last In First Out (LIFO). This means the last element inserted inside the stack is removed first.You can think of the stack data structure as the pile of plates on top of another.LIFO Principle of Stack :In programming terms, putting an item on top of the stack is called push and removing an item is called pop.",
          "Algorithms": {
            "Push Operation": "void push(st *s, int newitem) {\n  if (isfull(s)) {\n    cout << \"STACK FULL\";\n  } else {\n    s->top++;\n    s->items[s->top] = newitem;\n  }\n  size++;\n}",
            "Pop Operation": "int pop(st *s) {\n  if (isEmpty(s)) {\n    cout << \"STACK EMPTY\";\n    return -1;\n  } else {\n    return s->items[s->top--];\n  }\n}",
            "isEmpty Operation": "bool isEmpty(st *s) {\n  return s->top == -1;\n}",
            "isFull Operation": "bool isFull(st *s) {\n  return s->top == s->capacity - 1;\n}",
            "Peek Opeartion": "int peek(st *s) {\n  if (isEmpty(s)) {\n    cout << \"STACK EMPTY\";\n    return -1;\n  } else {\n    return s->items[s->top];\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Push": "O(1)",
              "isEmpty": "O(1)",
              "isFull": "O(1)",
              "Pop": "O(1)",
              "Peek": "O(1)"
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Queue Data Structure",
        "Info": {
          "Definition": "A queue is a useful data structure in programming. It is similar to the ticket queue outside a cinema hall, where the first person entering the queue is the first person who gets the ticket.Queue follows the First In First Out (FIFO) rule - the item that goes in first is the item that comes out first.",
          "Algorithms": {
            "Enqueue Operation": "void enqueue(int item) {\n  if (isFull()) {\n    cout << \"Queue is full\";\n  } else {\n    rear = (rear + 1) % capacity;\n    arr[rear] = item;\n    count++;\n  }\n}",
            "Dequeue Operation": "int dequeue() {\n  if (isEmpty()) {\n    cout << \"Queue is empty\";\n    return INT_MIN;\n  } else {\n    int item = arr[front];\n    front = (front + 1) % capacity;\n    count--;\n    return item;\n  }\n}",
            "isEmpty Operation": "bool isEmpty() {\n  return (count == 0);\n}",
            "isFull Operation": "bool isFull() {\n  return (count == capacity);\n}",
            "Peek Opeartion": "int peek() {\n  if (isEmpty()) {\n    cout << \"Queue is empty\";\n    return INT_MIN;\n  } else {\n    return arr[front];\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Enqueue": "O(1)",
              "Dequeue": "O(1)",
              "isEmpty": "O(1)",
              "isFull": "O(1)",
              "Peek": "O(1)"
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Circular Queue",
        "Info": {
          "Definition": "A circular queue is the extended version of a regular queue where the last element is connected to the first element. Thus forming a circle-like structure.The circular queue solves the major limitation of the normal queue. In a normal queue, after a bit of insertion and deletion, there will be non-usable empty space.",
          "Algorithms": {
            "Enqueue Operation": "void enqueue(int item) {\n  if (isFull()) {\n    cout << \"Queue is full\";\n  } else {\n    rear = (rear + 1) % capacity;\n    arr[rear] = item;\n    count++;\n  }\n}",
            "Dequeue Operation": "int dequeue() {\n  if (isEmpty()) {\n    cout << \"Queue is empty\";\n    return INT_MIN;\n  } else {\n    int item = arr[front];\n    front = (front + 1) % capacity;\n    count--;\n    return item;\n  }\n}",
            "isEmpty Operation": "bool isEmpty() {\n  return (count == 0);\n}",
            "isFull Operation": "bool isFull() {\n  return (count == capacity);\n}",
            "Peek Opeartion": "int peek() {\n  if (isEmpty()) {\n    cout << \"Queue is empty\";\n    return INT_MIN;\n  }\n  return arr[front];\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Enqueue": "O(1)",
              "Dequeue": "O(1)",
              "isEmpty": "O(1)",
              "isFull": "O(1)",
              "Peek": "O(1)"
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Bubble Sort",
        "Info": {
          "Definition": "Bubble Sort is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order. The pass through the list is repeated until the list is sorted.",
          "Algorithms": {
            "Code": "Bubble Sort is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order. The pass through the list is repeated until the list is sorted.\n\nvoid bubbleSort(int arr[], int n) {\n  for (int i = 0; i < n-1; i++)\n    for (int j = 0; j < n-i-1; j++)\n      if (arr[j] > arr[j+1])\n        swap(arr[j], arr[j+1]);\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Worst and Average Case": "O(n^2)",
              "Best Case": "O(n) when the array is already sorted"
            },
            "Space Complexity": "O(1) - Only requires a constant amount of additional space."
          }
        }
      },
      {
        "Topic": "Insertion Sort",
        "Info": {
          "Definition": "Insertion Sort is a simple sorting algorithm that builds the final sorted array one item at a time. It is much less efficient on large lists than more advanced algorithms such as quicksort, heapsort, or merge sort.",
          "Algorithms": {
            "Code": "Insertion Sort is a simple sorting algorithm that builds the final sorted array one item at a time. It is much less efficient on large lists than more advanced algorithms such as quicksort, heapsort, or merge sort.\n\nvoid insertionSort(int arr[], int n) {\n  int i, key, j;\n  for (i = 1; i < n; i++) {\n    key = arr[i];\n    j = i - 1;\n    while (j >= 0 && arr[j] > key) {\n      arr[j + 1] = arr[j];\n      j = j - 1;\n    }\n    arr[j + 1] = key;\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Worst and Average Case": "O(n^2)",
              "Best Case": "O(n) when the array is already sorted"
            },
            "Space Complexity": "O(1) - It is an in-place sorting algorithm."
          }
        }
      },
      {
        "Topic": "Selection Sort",
        "Info": {
          "Definition": "Selection Sort is an in-place comparison sorting algorithm. It divides the input list into two parts: a sorted sublist of items which is built up from left to right at the front of the list, and a sublist of the remaining unsorted items that occupy the rest of the list. Initially, the sorted sublist is empty and the unsorted sublist is the entire input list. The algorithm proceeds by finding the smallest (or largest, depending on sorting order) element in the unsorted sublist, swapping it with the leftmost unsorted element, and moving the sublist boundaries one element to the right.",
          "Algorithms": {
            "Code": "Selection Sort is an in-place comparison sorting algorithm. It divides the input list into two parts: a sorted sublist of items which is built up from left to right at the front of the list, and a sublist of the remaining unsorted items that occupy the rest of the list. Initially, the sorted sublist is empty and the unsorted sublist is the entire input list. The algorithm proceeds by finding the smallest (or largest, depending on sorting order) element in the unsorted sublist, swapping it with the leftmost unsorted element, and moving the sublist boundaries one element to the right.\n\nvoid selectionSort(int arr[], int n) {\n  int i, j, min_idx;\n  for (i = 0; i < n-1; i++) {\n    min_idx = i;\n    for (j = i+1; j < n; j++)\n      if (arr[j] < arr[min_idx])\n        min_idx = j;\n    swap(arr[min_idx], arr[i]);\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": "Worst, Average, and Best Case: O(n^2), as it always runs O(n^2) operations regardless of the input.",
            "Space Complexity": "O(1) - Like bubble sort and insertion sort, selection sort also uses a constant amount of additional space."
          }
        }
      },
      {
        "Topic": "Singly Linked List",
        "Info": {
          "Definition": "A singly linked list is a type of linked list in which each node points to the next node in the list and the last node points to null. It allows for efficient insertion and removal of elements from any position in the sequence.",
          "Algorithm": {
            "Insertion at End": "Adds a new node with the specified data at the end of the list.\n\nvoid insertAtEnd(Node** head, int newData) {\n  Node* newNode = new Node();\n  Node* last = *head;\n  newNode->data = newData;\n  newNode->next = NULL;\n  if (*head == NULL) {\n    *head = newNode;\n    return;\n  }\n  while (last->next != NULL) {\n    last = last->next;\n  }\n  last->next = newNode;\n}"
          },
          "Complexities": {
            "Time Complexity": "Insertion at end: O(n), Search: O(n), Deletion: O(n)",
            "Space Complexity": "O(n) - Storing n elements."
          }
        }
      },
      {
        "Topic": "Doubly Linked List",
        "Info": {
          "Definition": "A double linked list is a type of linked list in which each node contains two links: one pointing to the next node and one to the previous node. This allows for efficient insertion and removal from both ends of the list.",
          "Algorithm": {
            "Insertion at End": "Adds a new node with the specified data at the end of the list.\n\nvoid insertAtEnd(DoubleNode** head, int newData) {\n  DoubleNode* newNode = new DoubleNode();\n  DoubleNode* last = *head;\n  newNode->data = newData;\n  newNode->next = NULL;\n  if (*head == NULL) {\n    newNode->prev = NULL;\n    *head = newNode;\n    return;\n  }\n  while (last->next != NULL) {\n    last = last->next;\n  }\n  last->next = newNode;\n  newNode->prev = last;\n}"
          },
          "Complexities": {
            "Time Complexity": "Insertion at end: O(n), Search: O(n), Deletion: O(n)",
            "Space Complexity": "O(n) - Storing n elements, but requires additional space for the previous link in each node."
          }
        }
      },
      {
        "Topic": "Circular Linked List",
        "Info": {
          "Definition": "A circular linked list is a type of linked list where all nodes are connected to form a circle. There is no NULL at the end. It can be implemented as a singly circular linked list or doubly circular linked list.",
          "Algorithm": {
            "Insertion at End": "Adds a new node with the specified data at the end of the list, forming a circle.\n\nvoid insertAtEnd(CircularNode** head, int newData) {\n  CircularNode* newNode = new CircularNode();\n  CircularNode* last = *head;\n  newNode->data = newData;\n  if (*head == NULL) {\n    newNode->next = newNode;\n    *head = newNode;\n    return;\n  }\n  while (last->next != *head) {\n    last = last->next;\n  }\n  last->next = newNode;\n  newNode->next = *head;\n}"
          },
          "Complexities": {
            "Time Complexity": "Insertion at end: O(n), Search: O(n), Deletion: O(n)",
            "Space Complexity": "O(n) - Storing n elements. Similar to singly or doubly linked lists but forms a circle."
          }
        }
      }
    ]
  },
  {
    "category": "Medium",
    "Problems": [
      {
        "Topic": "Priority Queue",
        "Info": {
          "Definition": "A priority queue is a special type of queue in which each element is associated with a priority value. And, elements are served on the basis of their priority. That is, higher priority elements are served first.However, if elements with the same priority occur, they are served according to their order in the queue.",
          "Algorithms": {
            "Insert Operation": "void insert(int priority, int data) {\n  if (isFull()) {\n    cout << \"Priority Queue is full\";\n    return;\n  }\n  Node* newNode = new Node(priority, data);\n  if (isEmpty() || priority > front->priority) {\n    newNode->next = front;\n    front = newNode;\n  } else {\n    Node* temp = front;\n    while (temp->next != NULL && temp->next->priority >= priority) {\n      temp = temp->next;\n    }\n    newNode->next = temp->next;\n    temp->next = newNode;\n  }\n  size++;\n}",
            "Delete Operation": "void delete() {\n  if (isEmpty()) {\n    cout << \"Priority Queue is empty\";\n    return;\n  }\n  Node* temp = front;\n  front = front->next;\n  delete temp;\n  size--;\n}",
            "isEmpty Operation": "bool isEmpty() {\n  return (front == NULL);\n}",
            "isFull Operation": "bool isFull() {\n  // This implementation might vary based on underlying data structure. For a linked list, it might be system memory dependent.\n}",
            "Peek Opeartion": "int peek() {\n  if (isEmpty()) {\n    cout << \"Priority Queue is empty\";\n    return INT_MIN;\n  }\n  return front->data;\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Insert": "O(n) - In the worst case, we traverse the entire list.",
              "Delete": "O(1) - Deletion always occurs at the front.",
              "Peek": "O(1) - Peeking only looks at the front element.",
              "isEmpty": "O(1)",
              "isFull": "Varies - For linked list implementations, it might depend on available system memory."
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Deque Data Structure",
        "Info": {
          "Definition": "Deque or Double Ended Queue is a type of queue in which insertion and removal of elements can either be performed from the front or the rear. Thus, it does not follow FIFO rule (First In First Out).\nTypes of Deque:\nInput Restricted Deque:  In this deque, input is restricted at a single end but allows deletion at both the ends.\nOutput Restricted Deque:  In this deque, output is restricted at a single end but allows insertion at both the ends.",
          "Algorithms": {
            "Insert Operation": "void insert(int priority, int data) {\n  if (isFull()) {\n    cout << \"Priority Queue is full\";\n    return;\n  }\n  Node* newNode = new Node(priority, data);\n  if (isEmpty() || priority > front->priority) {\n    newNode->next = front;\n    front = newNode;\n  } else {\n    Node* temp = front;\n    while (temp->next != NULL && temp->next->priority >= priority) {\n      temp = temp->next;\n    }\n    newNode->next = temp->next;\n    temp->next = newNode;\n  }\n  size++;\n}",
            "Delete Operation": "void delete() {\n  if (isEmpty()) {\n    cout << \"Priority Queue is empty\";\n    return;\n  }\n  Node* temp = front;\n  front = front->next;\n  delete temp;\n  size--;\n}",
            "isEmpty Operation": "bool isEmpty() {\n  return (front == NULL);\n}",
            "isFull Operation": "bool isFull() {\n  // This implementation might vary based on underlying data structure. For a linked list, it might be system memory dependent.\n}",
            "Peek Opeartion": "int peek() {\n  if (isEmpty()) {\n    cout << \"Priority Queue is empty\";\n    return INT_MIN;\n  }\n  return front->data;\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Insert": "O(n) - In the worst case, we traverse the entire list.",
              "Delete": "O(1) - Deletion always occurs at the front.",
              "Peek": "O(1) - Peeking only looks at the front element.",
              "isEmpty": "O(1)",
              "isFull": "Varies - For linked list implementations, it might depend on available system memory."
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Perfect Binary Tree",
        "Info": {
          "Definition": "A perfect binary tree is a type of binary tree in which every internal node has exactly two children and all leaf nodes are at the same level.",
          "Algorithms": {
            "Code": "Node* createPerfectBinaryTree(int depth) {\n  if (depth == 0) return NULL;\n  Node* node = new Node(0);\n  node->left = createPerfectBinaryTree(depth - 1);\n  node->right = createPerfectBinaryTree(depth - 1);\n  return node;\n}"
          },
          "Complexities": {
            "Time Complexity": "O(2^depth - 1) - Because it visits every node.",
            "Space Complexity": "O(2^depth - 1) - Due to storing all nodes."
          }
        }
      },
      {
        "Topic": "Full Binary Tree",
        "Info": {
          "Definition": "A full binary tree (sometimes proper binary tree or 2-tree) is a tree in which every node other than the leaves has two children.",
          "Algorithms":{"Code": "The creation or insertion in a full binary tree is context-specific and varies based on application. The complexity will depend on the method used for maintaining the fullness of the tree."},
          "Complexities": {
            "Time Complexity": "Varies - Depends on insertion method and tree structure.",
            "Space Complexity": "Varies - Depends on the number of nodes in the tree."
          }
        }
      },

      {
        "Topic": "Complete Binary Tree",
        "Info": {
          "Definition": "A complete binary tree is a binary tree in which every level, except possibly the last, is completely filled, and all nodes are as far left as possible.",
          "Algorithms": {"Code" :"void insertInCompleteBinaryTree(Node* &root, int value) {\n  queue<Node*> q;\n  q.push(root);\n  while (!q.empty()) {\n    Node* temp = q.front();\n    q.pop();\n    if (!temp->left) {\n      temp->left = new Node(value);\n      break;\n    } else q.push(temp->left);\n    if (!temp->right) {\n      temp->right = new Node(value);\n      break;\n    } else q.push(temp->right);\n  }\n}"},
          "Complexities": {
            "Time Complexity": "O(n) - Where n is the number of nodes. Insertion requires traversal to the first open position.",
            "Space Complexity": "O(n) - All nodes are stored, and O(w) for the queue, where w is the width of the tree."
          }
        }
      },
      {
        "Topic": "Balanced Binary Tree",
        "Info": {
          "Definition": "A balanced binary tree is a type of binary tree where the difference between heights of left and right subtrees of any node is not more than one. Balanced binary trees, such as AVL trees or Red-Black trees, automatically maintain height balance to ensure operation complexities.",
          "Algorithms": {"Code": "Pseudocode for inserting in a balanced binary tree (like AVL tree) involves performing standard BST insertion, updating the height of the node, getting the balance factor, and rotating appropriately to maintain balance."},
          "Complexities": {
            "Time Complexity": "O(log n) - For operations like insertion and deletion, due to height-balancing.",
            "Space Complexity": "O(n) - Space needed to store all nodes in the tree."
          }
        }
      },
      {
        "Topic": "Binary Search Tree",
        "Info": {
          "Definition": "A binary search tree (BST) is a binary tree where each node has a key greater than all keys in the node's left subtree and less than those in the right subtree.",
          "Algorithms": {"Code":"Node* insertBST(Node* node, int key) {\n  if (node == NULL) return new Node(key);\n  if (key < node->data) node->left = insertBST(node->left, key);\n  else if (key > node->data) node->right = insertBST(node->right, key);\n  return node;\n}"},
          "Complexities": {
            "Time Complexity": "O(n) in the worst case (unbalanced tree), O(log n) in the best case (balanced tree) - For operations like search, insertion, and deletion.",
            "Space Complexity": "O(n) - Space needed to store all nodes in the tree."
          }
        }
      },
      {
        "Topic": "AVL Tree",
        "Info": {
          "Definition": "An AVL tree is a self-balancing binary search tree, where the difference between heights of left and right subtrees cannot be more than one for all nodes.",
          "Algorithms": {
              "Code":"Node* insertAVL(Node* node, int key) {\n  // Perform the normal BST insert\n  if (node == NULL) return (new Node(key));\n  if (key < node->key) node->left = insertAVL(node->left, key);\n  else if (key > node->key) node->right = insertAVL(node->right, key);\n  // Update height, get balance factor, and balance the tree\n}"
          },
          "Complexities": {
            "Time Complexity": "O(log n) - For insertion, deletion, and lookup, due to the tree being balanced.",
            "Space Complexity": "O(n) - Space needed to store all nodes in the tree."
          }
        }
      },
      {
        "Topic": "Tree Traversal",
        "Info": {
          "Definition": "Traversing a tree means visiting every node in the tree. You might, for instance, want to add all the values in the tree or find the largest one. For all these operations, you will need to visit each node of the tree.Tree traversal algorithms are methods for visiting all the nodes in a tree data structure. There are several types of traversals, each visiting the nodes in a different order. The three fundamental depth-first search (DFS) traversals for binary trees are preorder, inorder, and postorder.\nPreorder Traversal : Visits the current node before its child nodes (Root, Left, Right). \n Inorder Traversal:  Visits the left child, then the current node, and finally the right child (Left, Root, Right). This traversal method is used especially for binary search trees where it returns nodes in non-decreasing order. \n PostOrder Traversal :Visits the current node after its child nodes (Left, Right, Root). This method is used to delete the tree or get the postfix expression of an expression tree.",
          "Algorithms": {
            "Preorder Traversal": "void preorderTraversal(Node* root) {\n  if (root == NULL) return;\n  cout << root->data << ' ';\n  preorderTraversal(root->left);\n  preorderTraversal(root->right);\n}",
            "Inorder Traversal": "void inorderTraversal(Node* root) {\n  if (root == NULL) return;\n  inorderTraversal(root->left);\n  cout << root->data << ' ';\n  inorderTraversal(root->right);\n}",
            "Postorder Traversal": "void postorderTraversal(Node* root) {\n  if (root == NULL) return;\n  postorderTraversal(root->left);\n  postorderTraversal(root->right);\n  cout << root->data << ' ';\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Preorder": "O(n)",
              "Inorder": "O(n)",
              "Postorder": "O(n)"
            },
            "Space Complexity": "O(h) - where h is the height of the tree. This space complexity accounts for the call stack during recursive calls."
          }
        }
      },
      {
        "Topic": "Merge Sort",
        "Info": {
          "Definition": "Merge Sort is a divide-and-conquer algorithm that divides the input array into two halves, calls itself for the two halves, and then merges the two sorted halves. It is known for its consistent performance and is often used in sorting libraries.",
          "Algorithms": {
            "Code":"void merge(int arr[], int l, int m, int r) {\n    int n1 = m - l + 1;\n    int n2 = r - m;\n\n    // Create temp arrays\n    int L[n1], R[n2];\n\n    // Copy data to temp arrays L[] and R[]\n    for (int i = 0; i < n1; i++)\n        L[i] = arr[l + i];\n    for (int j = 0; j < n2; j++)\n        R[j] = arr[m + 1 + j];\n\n    // Merge the temp arrays back into arr[l..r]\n    int i = 0; // Initial index of first subarray\n    int j = 0; // Initial index of second subarray\n    int k = l; // Initial index of merged subarray\n    while (i < n1 && j < n2) {\n        if (L[i] <= R[j]) {\n            arr[k] = L[i];\n            i++;\n        } else {\n            arr[k] = R[j];\n            j++;\n        }\n        k++;\n    }\n\n    // Copy the remaining elements of L[], if there are any\n    while (i < n1) {\n        arr[k] = L[i];\n        i++;\n        k++;\n    }\n\n    // Copy the remaining elements of R[], if there are any\n    while (j < n2) {\n        arr[k] = R[j];\n        j++;\n        k++;\n    }\n}\n\nvoid mergeSort(int arr[], int l, int r) {\n    if (l < r) {\n        // Find the middle point to divide the array into two halves\n        int m = l + (r-l)/2;\n\n        // Call mergeSort for first half\n        mergeSort(arr, l, m);\n\n        // Call mergeSort for second half\n        mergeSort(arr, m+1, r);\n\n        // Merge the sorted halves\n        merge(arr, l, m, r);\n    }\n}"
          },
          "Complexities": {
            "Time Complexity": "Worst, Average, and Best Case: O(n log n) - Merge sort always divides the array in half and takes linear time to merge two halves.",
            "Space Complexity": "O(n) - Requires additional space for the temporary arrays used in the merge process."
          }
        }
      },
      {
        "Topic": "Quick Sort",
        "Info": {
          "Definition": "Quick Sort is a highly efficient sorting algorithm and is based on partitioning of array of data into smaller arrays. A large array is partitioned into two arrays one of which holds values smaller than the specified value, say pivot, based on which the partition is made and another array holds values greater than the pivot value.",
          "Algorithms": {
            "Code":"void quickSort(int arr[], int low, int high) {\n  if (low < high) {\n    int pi = partition(arr, low, high);\n    quickSort(arr, low, pi - 1);\n    quickSort(arr, pi + 1, high);\n  }\n}\n\nint partition(int arr[], int low, int high) {\n  // This function takes last element as pivot, places the pivot element at its correct position in sorted array, and places all smaller to left of pivot and all greater elements to right of pivot.\n}"
          },
          "Complexities": {
            "Time Complexity": "Worst Case: O(n^2) when the pivot selection is poor. Average and Best Case: O(n log n) - The array is divided into subarrays that are processed recursively.",
            "Space Complexity": "O(log n) - The space complexity comes from the stack space used for recursion. The worst case is O(n), depending on the implementation."
          }
        }
      },
      {
        "Topic": "Heap Data Structure",
        "Info": {
          "Definition": "A Heap is a special Tree-based data structure that satisfies the heap property. In a max heap, for any given node C, if P is a parent node of C, then the key (the value) of P is greater than or equal to the key of C. The same property must be recursively true for all nodes in Binary Tree. Min heap is a heap where the value of parent nodes is less than or equal to that of child nodes.",
          "Algorithms": {
            "Insert (Heapify Up)": "Inserts a new element into the heap and re-arranges the heap to maintain the heap property.\n\nvoid insert(int key) {\n  heapSize++; // Assume heapSize is the current number of elements in the heap\n  int index = heapSize - 1;\n  heap[index] = key;\n  // Heapify up\n  while (index != 0 && heap[parent(index)] < heap[index]) {\n    swap(heap[index], heap[parent(index)]);\n    index = parent(index);\n  }\n}",
            "Delete (Heapify Down)": "Removes the root element from the heap and re-arranges it to maintain the heap property.\n\nvoid deleteRoot() {\n  if (heapSize <= 0) return;\n  heap[0] = heap[heapSize-1];\n  heapSize--;\n  heapifyDown(0);\n}",
            "Get Max or Min": "Retrieves the maximum element from a max heap or the minimum element from a min heap without removing it.\n\nint getPeak() {\n  return heap[0];\n}",
            "Build Heap (Heapify)": "Converts an unsorted array into a heap.\n\nvoid buildHeap(int arr[], int n) {\n  for (int i = (n / 2) - 1; i >= 0; i--) {\n    heapify(arr, n, i);\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Insert (Heapify Up)": "O(log n) - Because it may traverse from the node inserted at the very end up to the root node.",
              "Delete (Heapify Down)": "O(log n) - Due to the traversal down from the root to the leaf to maintain the heap property.",
              "Get Max or Min": "O(1) - The peak element is always at the root of the heap.",
              "Build Heap (Heapify)": "O(n) - Building the heap from an unsorted array takes linear time."
            },
            "Space Complexity": "O(n) - The space needed to store the heap structure."
          }
        }
      },

      {
        "Topic": "Heap Sort",
        "Info":{
          "Definition": "Heap Sort is a comparison-based sorting technique based on the Binary Heap data structure. It's similar to the selection sort where we first find the maximum element and place it at the end. The same process is repeated for the remaining elements, utilizing a heap to efficiently find the next maximum element.",
          "Algorithms":{
            "Code": "void heapify(int arr[], int n, int i) {\n    int largest = i; // Initialize largest as root\n    int l = 2 * i + 1; // left = 2*i + 1\n    int r = 2 * i + 2; // right = 2*i + 2\n\n    // If left child is larger than root\n    if (l < n && arr[l] > arr[largest])\n        largest = l;\n\n    // If right child is larger than largest so far\n    if (r < n && arr[r] > arr[largest])\n        largest = r;\n\n    // If largest is not root\n    if (largest != i) {\n        swap(arr[i], arr[largest]);\n\n        // Recursively heapify the affected sub-tree\n        heapify(arr, n, largest);\n    }\n}\n\nvoid heapSort(int arr[], int n) {\n    // Build heap (rearrange array)\n    for (int i = n / 2 - 1; i >= 0; i--)\n        heapify(arr, n, i);\n\n    // One by one extract an element from heap\n    for (int i = n - 1; i >= 0; i--) {\n        // Move current root to end\n        swap(arr[0], arr[i]);\n\n        // call max heapify on the reduced heap\n        heapify(arr, i, 0);\n    }\n}"
          },
        "Complexities":{
          "Time Complexity": {
            "Worst Case": "O(n log n)",
            "Average Case": "O(n log n)",
            "Best Case": "O(n log n)"
          },
          "Space Complexity": "O(1) - Heap sort is an in-place algorithm but may require a small stack for recursion during heapify."
        }
        
      }
        
      },
      {
        "Topic": "Dijkstra's Algorithm",
        "Info": {
          "Definition": "Dijkstra's Algorithm finds the shortest paths from a single source vertex to all other vertices in a weighted graph with non-negative edge weights.",
          "Algorithms": {
            "Code": "void dijkstra(const vector<vector<int>>& graph, int src) {\n  int V = graph.size();\n  vector<int> dist(V, INT_MAX);\n  dist[src] = 0;\n  vector<bool> sptSet(V, false);\n\n  for (int count = 0; count < V-1; count++) {\n    int u = -1;\n    for(int i = 0; i < V; i++)\n      if (!sptSet[i] && (u == -1 || dist[i] < dist[u]))\n        u = i;\n    sptSet[u] = true;\n    for (int v = 0; v < V; v++)\n      if (!sptSet[v] && graph[u][v] && dist[u] != INT_MAX && dist[u]+graph[u][v] < dist[v])\n        dist[v] = dist[u] + graph[u][v];\n  }\n}"
          },
          "Complexities": {
            "Time Complexity": "O(V^2) - For the implementation using adjacency matrix. With a priority queue, it can be reduced to O(V + E log V) where E is the number of edges.",
            "Space Complexity": "O(V) - Space needed for the distance array and the sptSet."
          }
        }
      },
      {
        "Topic": "Kruskal's Algorithm",
        "Info": {
          "Definition": "Kruskal's Algorithm finds a minimum spanning tree for a connected, undirected graph by adding increasing cost edges at each step, avoiding any cycles.",
          "Algorithms": {
            "Code": "struct Edge { int src, dest, weight; };\nstruct Graph { int V, E; vector<Edge> edges; };\nint find(vector<int>& parent, int i) {\n  if (parent[i] == i) return i;\n  return find(parent, parent[i]);\n}\nvoid kruskalMST(struct Graph& graph) {\n  sort(graph.edges.begin(), graph.edges.end(), [](Edge a, Edge b) { return a.weight < b.weight; });\n  vector<int> parent(graph.V);\n  for (int i = 0; i < graph.V; i++) parent[i] = i;\n  vector<Edge> mst;\n  for (Edge e : graph.edges) {\n    int x = find(parent, e.src);\n    int y = find(parent, e.dest);\n    if (x != y) {\n      mst.push_back(e);\n      parent[x] = y;\n    }\n  }\n  // mst contains the resulting minimum spanning tree\n}"
          },
          "Complexities": {
            "Time Complexity": "O(E log E) - Or O(E log V) because of the sorting of edges, where E is the number of edges in the graph.",
            "Space Complexity": "O(V + E) - For storing the graph and the minimum spanning tree."
          }
        }
      },
      {
        "Topic": "Recursion and Backtracking",
        "Info": {
          "Definition": "Recursion\nRecursion is a method of solving a problem where the solution depends on solutions to smaller instances of the same problem. A recursive function calls itself with a base case to stop the recursion.\nBacktracking\nBacktracking is an algorithmic-technique for solving problems recursively by trying to build a solution incrementally, one piece at a time, removing those solutions that fail to satisfy the constraints of the problem at any point of time.",
          
          "Algorithms": {
            
              "Recursion Example - Factorial": "int factorial(int n) {\n  if (n <= 1) return 1;\n  return n * factorial(n - 1);\n}",
              "Backtracking Example - N Queens Problem":"bool isSafe(int board[N][N], int row, int col) {\n  // Check this row on left side\n  // Check upper diagonal on left side\n  // Check lower diagonal on left side\n  // For simplification, these checks are omitted\n  return true;\n}\n\nbool solveNQUtil(int board[N][N], int col) {\n  if (col >= N) return true;\n  for (int i = 0; i < N; i++) {\n    if (isSafe(board, i, col)) {\n      board[i][col] = 1;\n      if (solveNQUtil(board, col + 1)) return true;\n      board[i][col] = 0; // BACKTRACK\n    }\n  }\n  return false;\n}"
            
          },
          "Complexities": {
            "Time Complexity": {
              "Recursion Example - Factorial": "O(n) - The time complexity is linear, as it makes a single call for each decrement of n until it reaches the base case.",
              "Backtracking Example - N Queens Problem": "O(N!) - The worst-case time complexity, as it tries every possible arrangement of queens."
            },
            "Space Complexity": {
              "Recursion Example - Factorial": "O(n) - Due to the call stack in recursion for each function call until the base case is reached.",
              "Backtracking Example - N Queens Problem": "O(N) - Mainly for the call stack in recursion. Additional space for the board is not considered here."
            }
          }
        }
      }   
    ]
  },
  {
    "category":"Hard",
    "Problems":[
      {
        "Topic": "Count Sort",
        "Info": {
          "Definition": "Count Sort is an integer sorting algorithm that operates by counting the number of occurrences of each distinct value in the input array. These counts are then used to compute the position of each element in the sorted array.",
          "Algorithms": {
            "Code": "void countSort(int arr[], int n) {\n    int output[n];\n    int count[256], i;\n    memset(count, 0, sizeof(count));\n\n    for(i = 0; arr[i]; ++i)\n        ++count[arr[i]];\n\n    for (i = 1; i <= 255; ++i)\n        count[i] += count[i-1];\n\n    for (i = 0; arr[i]; ++i) {\n        output[count[arr[i]]-1] = arr[i];\n        --count[arr[i]];\n    }\n\n    for (i = 0; arr[i]; ++i)\n        arr[i] = output[i];\n}"
          },
          "Complexities": {
            "Time Complexity": "O(n + k) - Where n is the number of elements and k is the range of the input.",
            "Space Complexity": "O(k) - The space used by the count array."
          }
        }
      },
      {
        "Topic": "Radix Sort",
        "Info": {
          "Definition": "Radix Sort is a non-comparative sorting algorithm that sorts integers by processing individual digits. Numbers are grouped by each digit, starting from the least significant digit to the most significant digit, using a stable algorithm like Count Sort as a subroutine.",
          "Algorithms": {
            "Code": "void countSort(int arr[], int n, int exp) {\n    vector<int> output(n);\n    int i, count[10] = {0};\n\n    for (i = 0; i < n; i++)\n        count[(arr[i] / exp) % 10]++;\n\n    for (i = 1; i < 10; i++)\n        count[i] += count[i - 1];\n\n    for (i = n - 1; i >= 0; i--) {\n        output[count[(arr[i] / exp) % 10] - 1] = arr[i];\n        count[(arr[i] / exp) % 10]--;\n    }\n\n    for (i = 0; i < n; i++)\n        arr[i] = output[i];\n}\n\nvoid radixSort(int arr[], int n) {\n    int m = getMax(arr, n);\n    for (int exp = 1; m / exp > 0; exp *= 10)\n        countSort(arr, n, exp);\n}"
          },
          "Complexities": {
            "Time Complexity": "O(nk) - Where n is the number of elements and k is the number of digits in the maximum number.",
            "Space Complexity": "O(n + k) - For the intermediate count sort operations."
          }
        }
      },
      {
        "Topic": "Bucket Sort",
        "Info": {
          "Definition": "Bucket Sort, or Bin Sort, operates by partitioning an array into a number of buckets. Each bucket is then sorted individually, either using a different sorting algorithm, or by recursively applying the bucket sort algorithm.",
          "Algorithms": {
            "Code": "void bucketSort(float arr[], int n) {\n    vector<float> b[n];\n    for (int i = 0; i < n; i++) {\n       int bi = n * arr[i]; // Index in bucket\n       b[bi].push_back(arr[i]);\n    }\n\n    for (int i = 0; i < n; i++)\n       sort(b[i].begin(), b[i].end());\n\n    int index = 0;\n    for (int i = 0; i < n; i++)\n       for (int j = 0; j < b[i].size(); j++)\n          arr[index++] = b[i][j];\n}"
          },
          "Complexities": {
            "Time Complexity": "Average Case: O(n + n^2/k + k), and Worst Case: O(n^2). Here, n is the number of elements, and k is the number of buckets.",
            "Space Complexity": "O(n*k) - For the buckets used during sorting."
          }
        }
      },
      {
        "Topic": "Fibonacci Sequence",
        "Info": {
          "Definition": "The Fibonacci sequence is a series of numbers where each number is the sum of the two preceding ones, usually starting with 0 and 1. It's a classic example demonstrating the power of Dynamic Programming in reducing the computational complexity of recursive algorithms.",
          "Algorithms": {
            "Code": "int fib(int n) {\n    if(n <= 1) return n;\n    vector<int> f(n+1, 0);\n    f[1] = 1;\n    for(int i = 2; i <= n; i++)\n        f[i] = f[i-1] + f[i-2];\n    return f[n];\n}"
          },
          "Complexities": {
            "Time Complexity": "O(n) - Linear, as it iterates once up to n.",
            "Space Complexity": "O(n) - For storing the Fibonacci sequence up to n."
          }
        }
      },
      {
        "Topic": "0/1 Knapsack Problem",
        "Info": {
          "Definition": "The 0/1 Knapsack Problem is a problem in combinatorial optimization where one has to maximize the total value of items in a knapsack without exceeding its capacity. Each item can either be included or excluded, hence the name 0/1.",
          "Algorithms": {
            "Code": "int knapSack(int W, int wt[], int val[], int n) {\n   vector<vector<int>> dp(n+1, vector<int>(W+1, 0));\n   for(int i = 1; i <= n; i++) {\n       for(int w = 1; w <= W; w++) {\n           if(wt[i-1] <= w)\n               dp[i][w] = max(val[i-1] + dp[i-1][w-wt[i-1]], dp[i-1][w]);\n           else\n               dp[i][w] = dp[i-1][w];\n       }\n   }\n   return dp[n][W];\n}"
          },
          "Complexities": {
            "Time Complexity": "O(nW) - Where n is the number of items and W is the capacity of the knapsack.",
            "Space Complexity": "O(nW) - For the DP table storing solutions for subproblems."
          }
        }
      },
      {
        "Topic": "Longest Common Subsequence",
        "Info": {
          "Definition": "The Longest Common Subsequence (LCS) problem involves finding the longest subsequence present in two sequences (not necessarily contiguous) such that the subsequence is common to both.",
          "Algorithms": {
            "Code": "int lcs(string &X, string &Y) {\n   int m = X.length(), n = Y.length();\n   vector<vector<int>> dp(m+1, vector<int>(n+1));\n   for(int i=1; i<=m; i++) {\n       for(int j=1; j<=n; j++) {\n           if(X[i-1] == Y[j-1])\n               dp[i][j] = dp[i-1][j-1] + 1;\n           else\n               dp[i][j] = max(dp[i-1][j], dp[i][j-1]);\n       }\n   }\n   return dp[m][n];\n}"
          },
          "Complexities": {
            "Time Complexity": "O(mn) - Where m and n are the lengths of the two sequences.",
            "Space Complexity": "O(mn) - For the DP table."
          }
        }
      },
      {
        "Topic": "Floyd-Warshall Algorithm",
        "Info": {
          "Definition": "The Floyd-Warshall Algorithm is a dynamic programming solution for finding the shortest paths between all pairs of vertices in a weighted graph. It can handle negative weight edges but not negative weight cycles.",
          "Algorithms": {
            "Code": "void floydWarshall(int graph[][V]) {\n    int dist[V][V], i, j, k;\n    for (i = 0; i < V; i++)\n        for (j = 0; j < V; j++)\n            dist[i][j] = graph[i][j];\n    for (k = 0; k < V; k++) {\n        for (i = 0; i < V; i++) {\n            for (j = 0; j < V; j++) {\n                if (dist[i][k] + dist[k][j] < dist[i][j])\n                    dist[i][j] = dist[i][k] + dist[k][j];\n            }\n        }\n    }\n}",
            "Complexities": {
              "Time Complexity": "O(V^3) - The algorithm runs three nested loops over the graph's vertices, where V is the number of vertices in the graph.",
              "Space Complexity": "O(V^2) - Space needed to store the distance matrix."
            }
          }
        }
      } 
    ]
  } 
]
