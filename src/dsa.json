[
  {
    "category": "Easy",
    "Problems": [
      {
        "Topic": "Array Concept",
        "Info": {
          "Definition": "An array is a data structure that contains a group of elements. Typically these elements are all of the same data type, such as an integer or string. Arrays are commonly used to organize data so that a related set of values can be easily sorted or searched.",
          "Algorithms": {
            "Traversal": "for(int i = 0; i < arr.length; i++) {\n  System.out.println(arr[i]);\n}",
            "Insertion": "for(int i = arr.length-1; i > position; i--) {\n  arr[i] = arr[i-1];\n}\narr[position] = newValue;",
            "Deletion": "for(int i = position; i < arr.length-1; i++) {\n  arr[i] = arr[i+1];\n}",
            "Search": "for(int i = 0; i < arr.length; i++) {\n  if(arr[i] == searchValue) {\n    return i;\n  }\n}\nreturn -1;",
            "Update": "arr[position] = newValue;"
          },
          "Complexities": {
            "Time Complexities": {
              "Traversal": "O(n)",
              "Insertion": "O(n)",
              "Deletion": "O(n)",
              "Search": "O(n)",
              "Update": "O(1)"
            },
            "Space Complexity": "O(1)"
          }
        }
      },  
      {
        "Topic": "Pointers",
        "Info": {
          "Definition": "A pointer is a variable that stores the memory address of another variable. Pointers are used for various purposes in programming, such as accessing array elements, dynamic memory allocation, and for referencing functions. Pointers are a powerful feature of languages like C and C++, offering both flexibility and complexity.",
          "Algorithms": {
            "Pointer Initialization": "int* ptr = &var;",
            "Pointer Dereferencing": "*ptr = 10;",
            "Pointer to Pointer": "int** ptr2 = &ptr;",
            "Dynamic Memory Allocation": "int* ptr = (int*)malloc(sizeof(int));",
            "Deallocation": "free(ptr);",
            "Array Access Through Pointers": "for(int i = 0; i < n; i++) {\n  printf(\"%d\\n\", *(arr + i));\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Pointer Initialization": "O(1)",
              "Pointer Dereferencing": "O(1)",
              "Pointer to Pointer": "O(1)",
              "Dynamic Memory Allocation": "O(1) for allocation and deallocation",
              "Array Access Through Pointers": "O(n)"
            },
            "Space Complexity": "O(1) for static allocation, varies for dynamic allocation"
          }
        }
      },
      {
        "Topic": "Dynamic Memory Allocation",
        "Info": {
          "Definition": "Dynamic memory allocation refers to the process of allocating memory at runtime, as opposed to static memory allocation where memory size must be specified at compile time. This allows for more flexible memory usage, enabling programs to use memory as needed during execution. Common operations include allocating, reallocating, and freeing memory.",
          "Algorithms": {
            "Allocation (malloc)": "void* ptr = malloc(size);",
            "Deallocation (free)": "free(ptr);",
            "Reallocation (realloc)": "ptr = realloc(ptr, newSize);",
            "Allocation for arrays (calloc)": "void* ptr = calloc(nItems, sizeOfEachItem);"
          },
          "Complexities": {
            "Time Complexities": {
              "Allocation (malloc)": "O(1), but depends on the system's memory manager",
              "Deallocation (free)": "O(1), but can vary based on implementation",
              "Reallocation (realloc)": "O(n), as it may involve copying memory if the new size cannot be accommodated at the current location",
              "Allocation for arrays (calloc)": "O(n), as it initializes all bits to zero"
            },
            "Space Complexity": "O(n), where n is the amount of requested memory"
          }
        }
      },     
      {
        "Topic": "Linear Search",
        "Info": {
          "Definition": "Linear Search is a searching algorithm that finds the position of a target value within an array. It sequentially checks each element of the array for the target value until a match is found or until all the elements have been searched.",
          "Algorithms": {
            "Basic Method": "for i = 0 to arr.length\nif arr[i] == x\n    return i\nreturn -1"
          },
          "Complexities": {
            "Time Complexities": {
              "Best case": "O(1)",
              "Average case": "O(n)",
              "Worst case": "O(n)"
            },
            "Space Complexity": "The space complexity of the linear search is O(1)."
          }
        }
      },            
      {
        "Topic": "Binary Search",
        "Info": {
          "Definition": "Binary Search is a searching algorithm for finding an element's position in a sorted array. In this approach, the element is always searched in the middle of a portion of an array. Binary search can be implemented only on a sorted list of items. If the elements are not sorted already, we need to sort them first.",
          "Algorithms": {
            "Iterative Method": "do until the pointers low and high meet each other.\nmid = (low + high)/2\nif (x == arr[mid])\n    return mid\nelse if (x > arr[mid]) // x is on the right side\n    low = mid + 1\nelse                       // x is on the left side\n    high = mid - 1",
            "Recursive Method": "binarySearch(arr, x, low, high)\nif low > high\n    return False \nelse\n    mid = (low + high) / 2 \n    if x == arr[mid]\n        return mid\n    else if x > arr[mid]        // x is on the right side\n        return binarySearch(arr, x, mid + 1, high)\n    else                               // x is on the left side\n        return binarySearch(arr, x, low, mid - 1)"
          },
          "Complexities": {
            "Time Complexities": {
              "Best case": "O(1)",
              "Average case": "O(log n)",
              "Worst case": "O(log n)"
            },
            "Space Complexity": "The space complexity of the binary search is O(1)."
          }
        }
      },
      {
        "Topic": "Stack Data Structure",
        "Info": {
          "Definition": "A stack is a linear data structure that follows the principle of Last In First Out (LIFO). This means the last element inserted inside the stack is removed first.You can think of the stack data structure as the pile of plates on top of another.LIFO Principle of Stack :In programming terms, putting an item on top of the stack is called push and removing an item is called pop.",
          "Algorithms": {
            "Push Operation": "void push(st *s, int newitem) {\n  if (isfull(s)) {\n    cout << \"STACK FULL\";\n  } else {\n    s->top++;\n    s->items[s->top] = newitem;\n  }\n  size++;\n}",
            "Pop Operation": "int pop(st *s) {\n  if (isEmpty(s)) {\n    cout << \"STACK EMPTY\";\n    return -1;\n  } else {\n    return s->items[s->top--];\n  }\n}",
            "isEmpty Operation": "bool isEmpty(st *s) {\n  return s->top == -1;\n}",
            "isFull Operation": "bool isFull(st *s) {\n  return s->top == s->capacity - 1;\n}",
            "Peek Opeartion": "int peek(st *s) {\n  if (isEmpty(s)) {\n    cout << \"STACK EMPTY\";\n    return -1;\n  } else {\n    return s->items[s->top];\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Push": "O(1)",
              "isEmpty": "O(1)",
              "isFull": "O(1)",
              "Pop": "O(1)",
              "Peek": "O(1)"
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Stack Implementations (Using Arrays & Linked Lists)",
        "Info": {
          "Definition": "A stack is a linear data structure that follows the Last In First Out (LIFO) principle. Elements are added to and removed from the top of the stack. Stack implementations can use arrays or linked lists. An array-based stack has a fixed size, which limits its capacity, while a linked list-based stack can grow dynamically, allowing for more flexibility.",
          "Algorithms": {
            "Array-Based Stack Push": "void push(int x) {\n  if(top >= n-1) {\n    cout << \"Stack Overflow\";\n  } else {\n    arr[++top] = x;\n  }\n}",
            "Array-Based Stack Pop": "int pop() {\n  if(top <= -1) {\n    cout << \"Stack Underflow\";\n    return 0;\n  } else {\n    int x = arr[top--];\n    return x;\n  }\n}",
            "Array-Based Stack Peek": "int peek() {\n  if(top < 0) {\n    cout << \"Stack is Empty\";\n    return 0;\n  } else {\n    return arr[top];\n  }\n}",
            "Array-Based Stack Is Empty": "bool isEmpty() {\n  return (top < 0);\n}",
            "Array-Based Stack Is Full": "bool isFull() {\n  return (top >= n-1);\n}",
            "Linked List-Based Stack Push": "void push(int x) {\n  Node* newNode = new Node();\n  if (!newNode) {\n    cout << \"Heap Overflow\";\n  } else {\n    newNode->data = x;\n    newNode->next = top;\n    top = newNode;\n  }\n}",
            "Linked List-Based Stack Pop": "int pop() {\n  if (top == nullptr) {\n    cout << \"Stack Underflow\";\n    return 0;\n  } else {\n    Node* temp = top;\n    top = top->next;\n    int popped = temp->data;\n    delete temp;\n    return popped;\n  }\n}",
            "Linked List-Based Stack Peek": "int peek() {\n  if (top == nullptr) {\n    cout << \"Stack is Empty\";\n    return 0;\n  } else {\n    return top->data;\n  }\n}",
            "Linked List-Based Stack Is Empty": "bool isEmpty() {\n  return (top == nullptr);\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Array-Based Stack Operations": "O(1) - For push, pop, peek, isEmpty, and isFull operations",
              "Linked List-Based Stack Operations": "O(1) - For push, pop, peek, and isEmpty operations"
            },
            "Space Complexity": "O(n) - For both array and linked list implementations, depending on the number of elements in the stack"
          }
        }
      },      
      {
        "Topic": "Stack Applications (Expression Evaluation)",
        "Info": {
          "Definition": "Expression evaluation is a key application of stacks, enabling the processing of arithmetic expressions in various notations including infix, prefix (Polish notation), and postfix (Reverse Polish notation). This involves scanning the expression, using stacks to manage operands and operators, and systematically applying operators following precedence rules. It simplifies managing complex arithmetic expressions' order of operations and handling of parentheses.",
          "Algorithms": {
            "Infix to Postfix Conversion": "stack<char> opStack; \nstring postfix = \"\"; \nfor(char& c : infix) { \n  if(isOperand(c)) postfix += c; \n  else if(c == '(') opStack.push(c); \n  else if(c == ')') { \n    while(opStack.top() != '(') { \n      postfix += opStack.top(); \n      opStack.pop(); \n    } \n    opStack.pop(); \n  } \n  else { \n    while(!opStack.empty() && precedence(opStack.top()) >= precedence(c)) { \n      postfix += opStack.top(); \n      opStack.pop(); \n    } \n    opStack.push(c); \n  } \n} \nwhile(!opStack.empty()) { \n  postfix += opStack.top(); \n  opStack.pop(); \n}",
            "Postfix Expression Evaluation": "stack<int> valStack; \nfor(char& c : postfix) { \n  if(isDigit(c)) valStack.push(c - '0'); \n  else { \n    int b = valStack.top(); \n    valStack.pop(); \n    int a = valStack.top(); \n    valStack.pop(); \n    valStack.push(applyOp(a, b, c)); \n  } \n}",
            "Infix Expression Evaluation": "stack<int> values; \nstack<char> ops; \nfor(char& c : infix) { \n  if(isdigit(c)) { \n    int val = 0; \n    while(isdigit(c)) { \n      val = (val*10) + (c-'0'); \n      c++; \n    } \n    values.push(val); \n  } \n  else if(c == '(') ops.push(c); \n  else if(c == ')') { \n    while(ops.top() != '(') { \n      int val2 = values.top(); \n      values.pop(); \n      int val1 = values.top(); \n      values.pop(); \n      char op = ops.top(); \n      ops.pop(); \n      values.push(applyOp(val1, val2, op)); \n    } \n    ops.pop(); \n  } \n  else if(isOperator(c)) { \n    while(!ops.empty() && precedence(ops.top()) >= precedence(c)) { \n      int val2 = values.top(); \n      values.pop(); \n      int val1 = values.top(); \n      values.pop(); \n      char op = ops.top(); \n      ops.pop(); \n      values.push(applyOp(val1, val2, op)); \n    } \n    ops.push(c); \n  } \n}",
            "Prefix to Postfix Conversion": "stack<string> s; \nfor(int i = prefix.length() - 1; i >= 0; i--) { \n  if(isOperand(prefix[i])) s.push(string(1, prefix[i])); \n  else { \n    string op1 = s.top(); \n    s.pop(); \n    string op2 = s.top(); \n    s.pop(); \n    s.push(op1 + op2 + prefix[i]); \n  } \n}",
            "Prefix to Infix Conversion": "stack<string> s; \nfor(int i = prefix.length() - 1; i >= 0; i--) { \n  if(isOperand(prefix[i])) s.push(string(1, prefix[i])); \n  else { \n    string op1 = s.top(); \n    s.pop(); \n    string op2 = s.top(); \n    s.pop(); \n    s.push('(' + op1 + prefix[i] + op2 + ')'); \n  } \n}",
            "Prefix Expression Evaluation": "stack<int> Stack; \nfor(int i = prefix.length() - 1; i >= 0; i--) { \n  if(isDigit(prefix[i])) Stack.push(prefix[i] - '0'); \n  else { \n    int op1 = Stack.top(); \n    Stack.pop(); \n    int op2 = Stack.top(); \n    Stack.pop(); \n    Stack.push(applyOp(prefix[i], op1, op2)); \n  } \n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Infix to Postfix Conversion": "O(n)",
              "Postfix Expression Evaluation": "O(n)",
              "Infix Expression Evaluation": "O(n)",
              "Prefix to Postfix Conversion": "O(n)",
              "Prefix to Infix Conversion": "O(n)",
              "Prefix Expression Evaluation": "O(n)"
            },
            "Space Complexity": "O(n) - Requires space proportional to the length of the expression for the stack(s)"
          }
        }
      },      
      {
        "Topic": "Queue Data Structure",
        "Info": {
          "Definition": "A queue is a useful data structure in programming. It is similar to the ticket queue outside a cinema hall, where the first person entering the queue is the first person who gets the ticket.Queue follows the First In First Out (FIFO) rule - the item that goes in first is the item that comes out first.",
          "Algorithms": {
            "Enqueue Operation": "void enqueue(int item) {\n  if (isFull()) {\n    cout << \"Queue is full\";\n  } else {\n    rear = (rear + 1) % capacity;\n    arr[rear] = item;\n    count++;\n  }\n}",
            "Dequeue Operation": "int dequeue() {\n  if (isEmpty()) {\n    cout << \"Queue is empty\";\n    return INT_MIN;\n  } else {\n    int item = arr[front];\n    front = (front + 1) % capacity;\n    count--;\n    return item;\n  }\n}",
            "isEmpty Operation": "bool isEmpty() {\n  return (count == 0);\n}",
            "isFull Operation": "bool isFull() {\n  return (count == capacity);\n}",
            "Peek Opeartion": "int peek() {\n  if (isEmpty()) {\n    cout << \"Queue is empty\";\n    return INT_MIN;\n  } else {\n    return arr[front];\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Enqueue": "O(1)",
              "Dequeue": "O(1)",
              "isEmpty": "O(1)",
              "isFull": "O(1)",
              "Peek": "O(1)"
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Queue Implementations (Using Arrays & Linked Lists)",
        "Info": {
          "Definition": "A queue is a linear data structure that follows the First In First Out (FIFO) principle. Elements are added at one end, known as the rear, and removed from the other end, known as the front. Queue implementations commonly use arrays or linked lists. Array-based queues have a fixed size, while linked list-based queues can grow dynamically.",
          "Algorithms": {
            "Array-Based Queue Enqueue": "if(rear < SIZE) { queue[rear++] = element; }",
            "Array-Based Queue Dequeue": "if(front < rear) { element = queue[front++]; for(int i = 0; i < rear - 1; i++) { queue[i] = queue[i + 1]; } rear--; }",
            "Array-Based Queue Is Full": "return rear == SIZE;",
            "Array-Based Queue Is Empty": "return rear == 0;",
            "Linked List-Based Queue Enqueue": "Node* newNode = new Node(element); if(front == nullptr) { front = rear = newNode; } else { rear->next = newNode; rear = newNode; }",
            "Linked List-Based Queue Dequeue": "if(front != nullptr) { Node* temp = front; front = front->next; delete temp; if(front == nullptr) { rear = nullptr; } }",
            "Linked List-Based Queue Is Empty": "return front == nullptr;"
          },
          "Complexities": {
            "Time Complexities": {
              "Array-Based Queue Enqueue": "O(1) - Amortized",
              "Array-Based Queue Dequeue": "O(n) - Due to shifting elements",
              "Array-Based Queue Is Full": "O(1)",
              "Array-Based Queue Is Empty": "O(1)",
              "Linked List-Based Queue Enqueue": "O(1)",
              "Linked List-Based Queue Dequeue": "O(1)",
              "Linked List-Based Queue Is Empty": "O(1)"
            },
            "Space Complexity": {
              "Array-Based Queue": "O(n) - Fixed size based on initial allocation",
              "Linked List-Based Queue": "O(n) - Dynamic, depends on the number of elements"
            }
          }
        }
      },      
      {
        "Topic": "Circular Queue",
        "Info": {
          "Definition": "A circular queue is the extended version of a regular queue where the last element is connected to the first element. Thus forming a circle-like structure.The circular queue solves the major limitation of the normal queue. In a normal queue, after a bit of insertion and deletion, there will be non-usable empty space.",
          "Algorithms": {
            "Enqueue Operation": "void enqueue(int item) {\n  if (isFull()) {\n    cout << \"Queue is full\";\n  } else {\n    rear = (rear + 1) % capacity;\n    arr[rear] = item;\n    count++;\n  }\n}",
            "Dequeue Operation": "int dequeue() {\n  if (isEmpty()) {\n    cout << \"Queue is empty\";\n    return INT_MIN;\n  } else {\n    int item = arr[front];\n    front = (front + 1) % capacity;\n    count--;\n    return item;\n  }\n}",
            "isEmpty Operation": "bool isEmpty() {\n  return (count == 0);\n}",
            "isFull Operation": "bool isFull() {\n  return (count == capacity);\n}",
            "Peek Opeartion": "int peek() {\n  if (isEmpty()) {\n    cout << \"Queue is empty\";\n    return INT_MIN;\n  }\n  return arr[front];\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Enqueue": "O(1)",
              "Dequeue": "O(1)",
              "isEmpty": "O(1)",
              "isFull": "O(1)",
              "Peek": "O(1)"
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Bubble Sort",
        "Info": {
          "Definition": "Bubble Sort is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order. The pass through the list is repeated until the list is sorted.",
          "Algorithms": {
            "Code": "Bubble Sort is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order. The pass through the list is repeated until the list is sorted.\n\nvoid bubbleSort(int arr[], int n) {\n  for (int i = 0; i < n-1; i++)\n    for (int j = 0; j < n-i-1; j++)\n      if (arr[j] > arr[j+1])\n        swap(arr[j], arr[j+1]);\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Worst and Average Case": "O(n^2)",
              "Best Case": "O(n) when the array is already sorted"
            },
            "Space Complexity": "O(1) - Only requires a constant amount of additional space."
          }
        }
      },
      {
        "Topic": "Insertion Sort",
        "Info": {
          "Definition": "Insertion Sort is a simple sorting algorithm that builds the final sorted array one item at a time. It is much less efficient on large lists than more advanced algorithms such as quicksort, heapsort, or merge sort.",
          "Algorithms": {
            "Code": "Insertion Sort is a simple sorting algorithm that builds the final sorted array one item at a time. It is much less efficient on large lists than more advanced algorithms such as quicksort, heapsort, or merge sort.\n\nvoid insertionSort(int arr[], int n) {\n  int i, key, j;\n  for (i = 1; i < n; i++) {\n    key = arr[i];\n    j = i - 1;\n    while (j >= 0 && arr[j] > key) {\n      arr[j + 1] = arr[j];\n      j = j - 1;\n    }\n    arr[j + 1] = key;\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Worst and Average Case": "O(n^2)",
              "Best Case": "O(n) when the array is already sorted"
            },
            "Space Complexity": "O(1) - It is an in-place sorting algorithm."
          }
        }
      },
      {
        "Topic": "Selection Sort",
        "Info": {
          "Definition": "Selection Sort is an in-place comparison sorting algorithm. It divides the input list into two parts: a sorted sublist of items which is built up from left to right at the front of the list, and a sublist of the remaining unsorted items that occupy the rest of the list. Initially, the sorted sublist is empty and the unsorted sublist is the entire input list. The algorithm proceeds by finding the smallest (or largest, depending on sorting order) element in the unsorted sublist, swapping it with the leftmost unsorted element, and moving the sublist boundaries one element to the right.",
          "Algorithms": {
            "Code": "Selection Sort is an in-place comparison sorting algorithm. It divides the input list into two parts: a sorted sublist of items which is built up from left to right at the front of the list, and a sublist of the remaining unsorted items that occupy the rest of the list. Initially, the sorted sublist is empty and the unsorted sublist is the entire input list. The algorithm proceeds by finding the smallest (or largest, depending on sorting order) element in the unsorted sublist, swapping it with the leftmost unsorted element, and moving the sublist boundaries one element to the right.\n\nvoid selectionSort(int arr[], int n) {\n  int i, j, min_idx;\n  for (i = 0; i < n-1; i++) {\n    min_idx = i;\n    for (j = i+1; j < n; j++)\n      if (arr[j] < arr[min_idx])\n        min_idx = j;\n    swap(arr[min_idx], arr[i]);\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": "Worst, Average, and Best Case: O(n^2), as it always runs O(n^2) operations regardless of the input.",
            "Space Complexity": "O(1) - Like bubble sort and insertion sort, selection sort also uses a constant amount of additional space."
          }
        }
      },
      {
        "Topic": "Fibonacci Sequence",
        "Info": {
          "Definition": "The Fibonacci sequence is a series of numbers where each number is the sum of the two preceding ones, usually starting with 0 and 1. It's a classic example demonstrating the power of Dynamic Programming in reducing the computational complexity of recursive algorithms.",
          "Algorithms": {
            "Code": "int fib(int n) {\n    if(n <= 1) return n;\n    vector<int> f(n+1, 0);\n    f[1] = 1;\n    for(int i = 2; i <= n; i++)\n        f[i] = f[i-1] + f[i-2];\n    return f[n];\n}"
          },
          "Complexities": {
            "Time Complexity": "O(n) - Linear, as it iterates once up to n.",
            "Space Complexity": "O(n) - For storing the Fibonacci sequence up to n."
          }
        }
      },
      {
        "Topic": "Singly Linked List",
        "Info": {
          "Definition": "A singly linked list is a type of linked list in which each node points to the next node in the list and the last node points to null. It allows for efficient insertion and removal of elements from any position in the sequence.",
          "Algorithm": {
            "Insertion at End": "Adds a new node with the specified data at the end of the list.\n\nvoid insertAtEnd(Node** head, int newData) {\n  Node* newNode = new Node();\n  Node* last = *head;\n  newNode->data = newData;\n  newNode->next = NULL;\n  if (*head == NULL) {\n    *head = newNode;\n    return;\n  }\n  while (last->next != NULL) {\n    last = last->next;\n  }\n  last->next = newNode;\n}"
          },
          "Complexities": {
            "Time Complexity": "Insertion at end: O(n), Search: O(n), Deletion: O(n)",
            "Space Complexity": "O(n) - Storing n elements."
          }
        }
      },
      {
        "Topic": "Doubly Linked List",
        "Info": {
          "Definition": "A double linked list is a type of linked list in which each node contains two links: one pointing to the next node and one to the previous node. This allows for efficient insertion and removal from both ends of the list.",
          "Algorithm": {
            "Insertion at End": "Adds a new node with the specified data at the end of the list.\n\nvoid insertAtEnd(DoubleNode** head, int newData) {\n  DoubleNode* newNode = new DoubleNode();\n  DoubleNode* last = *head;\n  newNode->data = newData;\n  newNode->next = NULL;\n  if (*head == NULL) {\n    newNode->prev = NULL;\n    *head = newNode;\n    return;\n  }\n  while (last->next != NULL) {\n    last = last->next;\n  }\n  last->next = newNode;\n  newNode->prev = last;\n}"
          },
          "Complexities": {
            "Time Complexity": "Insertion at end: O(n), Search: O(n), Deletion: O(n)",
            "Space Complexity": "O(n) - Storing n elements, but requires additional space for the previous link in each node."
          }
        }
      },
      {
        "Topic": "Circular Linked List",
        "Info": {
          "Definition": "A circular linked list is a type of linked list where all nodes are connected to form a circle. There is no NULL at the end. It can be implemented as a singly circular linked list or doubly circular linked list.",
          "Algorithm": {
            "Insertion at End": "Adds a new node with the specified data at the end of the list, forming a circle.\n\nvoid insertAtEnd(CircularNode** head, int newData) {\n  CircularNode* newNode = new CircularNode();\n  CircularNode* last = *head;\n  newNode->data = newData;\n  if (*head == NULL) {\n    newNode->next = newNode;\n    *head = newNode;\n    return;\n  }\n  while (last->next != *head) {\n    last = last->next;\n  }\n  last->next = newNode;\n  newNode->next = *head;\n}"
          },
          "Complexities": {
            "Time Complexity": "Insertion at end: O(n), Search: O(n), Deletion: O(n)",
            "Space Complexity": "O(n) - Storing n elements. Similar to singly or doubly linked lists but forms a circle."
          }
        }
      },
      {
        "Topic": "Breadth-First Search (BFS) Algorithm",
        "Info": {
          "Definition": "Breadth-First Search (BFS) is an algorithm for traversing or searching tree or graph data structures. It starts at a selected node and explores all of the neighbor nodes at the present depth prior to moving on to the nodes at the next depth level.",
          "Algorithms": {
            "Code": "void bfs(int s, vector<int>& adj, vector<bool>& visited) {\n  queue<int> queue;\n  visited[s] = true;\n  queue.push(s);\n  while(!queue.empty()) {\n    int s = queue.front(); queue.pop();\n    cout << s << ' ';\n    for(auto u : adj[s]) {\n      if(!visited[u]) {\n        visited[u] = true;\n        queue.push(u);\n      }\n    }\n  }\n}"
          },
          "imageLink":"https://drive.google.com/uc?export=view&id=1gqD0hT_5ybCbXB9DJMba870MTttqK4ym",
          "Complexities": {
            "Time Complexity": "O(V+E) - Where V is the number of vertices and E is the number of edges.",
            "Space Complexity": "O(V) - Due to the storage of vertices in the queue."
          }
        }
      },
      {
        "Topic": "Depth-First Search (DFS) Algorithm",
        "Info": {
          "Definition": "Depth-First Search (DFS) is an algorithm for traversing or searching tree or graph data structures. The algorithm starts at the root node and explores as far as possible along each branch before backtracking.",
          "Algorithms": {
            "Code": "void dfs(int v, vector<int>& adj, vector<bool>& visited) {\n  visited[v] = true;\n  cout << v << ' ';\n  for(int u : adj[v]) {\n    if(!visited[u]) {\n      dfs(u, adj, visited);\n    }\n  }\n}"
          },
          "Complexities": {
            "Time Complexity": "O(V+E) - Where V is the number of vertices and E is the number of edges.",
            "Space Complexity": "O(V) - Due to the usage of the call stack in recursion."
          }
        }
      },
      {
        "Topic": "Bit Manipulation",
        "Info": {
          "Definition": "Bit manipulation involves the use of bitwise operations to directly manipulate individual bits of a binary number. This technique is useful for tasks such as setting, clearing, toggling, and testing bits, and is often utilized for optimization, as it can be more efficient than arithmetic operations.",
          "Algorithms": {
            "Set a Bit": "number |= 1 << x;",
            "Clear a Bit": "number &= ~(1 << x);",
            "Toggle a Bit": "number ^= 1 << x;",
            "Check a Bit": "(number & (1 << x)) != 0;",
            "Count Set Bits": "int countSetBits(int n) {\n  int count = 0;\n  while (n) {\n    count += n & 1;\n    n >>= 1;\n  }\n  return count;\n}",
            "Find the Rightmost Set Bit": "int rsb = n & -n;",
            "Turn Off the Rightmost Set Bit": "n = n & (n - 1);"
          },
          "Complexities": {
            "Time Complexities": {
              "Set a Bit": "O(1)",
              "Clear a Bit": "O(1)",
              "Toggle a Bit": "O(1)",
              "Check a Bit": "O(1)",
              "Count Set Bits": "O(log n)",
              "Find the Rightmost Set Bit": "O(1)",
              "Turn Off the Rightmost Set Bit": "O(1)"
            },
            "Space Complexity": "O(1)"
          }
        }
      },
      {
        "Topic": "Two Pointer Technique",
        "Info": {
          "Definition": "The two-pointer technique involves using two pointers to traverse an array, usually in a single pass, to solve problems such as finding a pair that sums up to a target value or identifying whether a sequence is a palindrome. This technique can significantly reduce the time complexity from O(n^2) to O(n) for certain problems by eliminating the need for nested loops.",
          "Algorithms": {
            "Find a Pair with a Given Sum": "while(left < right) {\n  int currentSum = arr[left] + arr[right];\n  if(currentSum == targetSum) {\n    return [left, right];\n  } else if(currentSum < targetSum) {\n    left++;\n  } else {\n    right--;\n  }\n}",
            "Check for Palindrome": "while(left < right) {\n  if(arr[left] != arr[right]) {\n    return false;\n  }\n  left++;\n  right--;\n}\nreturn true;",
            "Remove Duplicates from Sorted Array": "int i = 0;\nfor (int j = 1; j < n; j++) {\n  if (arr[j] != arr[i]) {\n    i++;\n    arr[i] = arr[j];\n  }\n}\nreturn i + 1;",
            "Reverse Array": "int start = 0, end = n - 1;\nwhile(start < end) {\n  int temp = arr[start];\n  arr[start] = arr[end];\n  arr[end] = temp;\n  start++;\n  end--;\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Find a Pair with a Given Sum": "O(n)",
              "Check for Palindrome": "O(n)",
              "Remove Duplicates from Sorted Array": "O(n)",
              "Reverse Array": "O(n)"
            },
            "Space Complexity": "O(1) - no additional space required apart from the input array"
          }
        }
      },
      {
        "Topic": "Sliding Window Technique",
        "Info": {
          "Definition": "The sliding window technique involves creating a window that slides over the data structure (such as an array or a string) to consider subarrays/substrings of varying sizes. This technique is particularly useful for finding the longest or shortest subarray/substring that meets certain criteria, and it can significantly improve efficiency by reducing the time complexity from O(n^2) to O(n) for many problems.",
          "Algorithms": {
            "Maximum Sum Subarray of Size K": "int maxSum = 0, windowSum = 0;\nint windowStart = 0;\nfor(int windowEnd = 0; windowEnd < arr.length; windowEnd++) {\n  windowSum += arr[windowEnd];\n  if(windowEnd >= K - 1) {\n    maxSum = Math.max(maxSum, windowSum);\n    windowSum -= arr[windowStart];\n    windowStart++;\n  }\n}",
            "Longest Substring Without Repeating Characters": "int start = 0, maxLength = 0;\nMap<Character, Integer> charIndexMap = new HashMap<>();\nfor(int end = 0; end < s.length(); end++) {\n  char rightChar = s.charAt(end);\n  if(charIndexMap.containsKey(rightChar)) {\n    start = Math.max(start, charIndexMap.get(rightChar) + 1);\n  }\n  charIndexMap.put(rightChar, end);\n  maxLength = Math.max(maxLength, end - start + 1);\n}",
            "Minimum Size Subarray Sum": "int start = 0, minLength = Integer.MAX_VALUE, windowSum = 0;\nfor(int end = 0; end < arr.length; end++) {\n  windowSum += arr[end];\n  while(windowSum >= targetSum) {\n    minLength = Math.min(minLength, end - start + 1);\n    windowSum -= arr[start];\n    start++;\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Maximum Sum Subarray of Size K": "O(n)",
              "Longest Substring Without Repeating Characters": "O(n)",
              "Minimum Size Subarray Sum": "O(n)"
            },
            "Space Complexity": {
              "Maximum Sum Subarray of Size K": "O(1)",
              "Longest Substring Without Repeating Characters": "O(min(m, n)) - where m is the size of the character set",
              "Minimum Size Subarray Sum": "O(1)"
            }
          }
        }
      },
      {
        "Topic": "String Manipulation",
        "Info": {
          "Definition": "String manipulation involves altering, parsing, or analyzing strings, which are sequences of characters. In C++, common operations include concatenation, comparison, searching for substrings, converting between uppercase and lowercase, trimming whitespace, and splitting strings into arrays of substrings. Efficient string manipulation is key in areas like data parsing, user input processing, and software development.",
          "Algorithms": {
            "Concatenation": "string result = string1 + string2;",
            "Find Substring": "size_t index = string.find(substring);",
            "Convert to Uppercase": "std::transform(string.begin(), string.end(), string.begin(), ::toupper);",
            "Convert to Lowercase": "std::transform(string.begin(), string.end(), string.begin(), ::tolower);",
            "Trim Whitespace": "string.erase(0, string.find_first_not_of(' '));\nstring.erase(string.find_last_not_of(' ') + 1);",
            "Split String": "vector<std::string> tokens;\nstringstream check1(string);\nstring intermediate;\nwhile(getline(check1, intermediate, ' ')) {\n  tokens.push_back(intermediate);\n}",
            "Replace Characters": "replace( string.begin(), string.end(), oldChar, newChar);",
            "Reverse String": "reverse(string.begin(), string.end());"
          },
          "Complexities": {
            "Time Complexities": {
              "Concatenation": "O(n) - Depends on the length of the strings",
              "Find Substring": "O(n*m) - n is string length, m is substring length",
              "Convert to Uppercase/Lowercase": "O(n) - n is the length of the string",
              "Trim Whitespace": "O(n) - n is the length of the string",
              "Split String": "O(n) - n is the length of the string, assuming fixed delimiter length",
              "Replace Characters": "O(n) - n is the length of the string",
              "Reverse String": "O(n) - n is the length of the string"
            },
            "Space Complexity": {
              "General": "O(n) - Additional space may be needed depending on the operation"
            }
          }
        }
      },
      {
        "Topic": "Matrix Operations",
        "Info": {
          "Definition": "Matrix operations include a variety of arithmetic and algebraic operations performed on matrices, which are rectangular arrays of numbers, symbols, or expressions arranged in rows and columns. Common operations include addition, subtraction, multiplication, transposition, and finding the determinant and inverse of a matrix. These operations are fundamental in linear algebra and are widely applied in scientific computing, engineering, and computer graphics.",
          "Algorithms": {
            "Matrix Addition": "for(int i = 0; i < rows; i++) {\n  for(int j = 0; j < cols; j++) {\n    result[i][j] = matA[i][j] + matB[i][j];\n  }\n}",
            "Matrix Subtraction": "for(int i = 0; i < rows; i++) {\n  for(int j = 0; j < cols; j++) {\n    result[i][j] = matA[i][j] - matB[i][j];\n  }\n}",
            "Matrix Multiplication": "for(int i = 0; i < rowsA; i++) {\n  for(int j = 0; j < colsB; j++) {\n    for(int k = 0; k < colsA; k++) {\n      result[i][j] += matA[i][k] * matB[k][j];\n    }\n  }\n}",
            "Matrix Transpose": "for(int i = 0; i < rows; i++) {\n  for(int j = 0; j < cols; j++) {\n    transpose[j][i] = matrix[i][j];\n  }\n}",
            "Determinant of a Matrix": "float determinant(float matrix[][], int n) {\n  // Implementation depends on the matrix size and method chosen, such as Laplace's formula or LU decomposition.\n}",
            "Inverse of a Matrix": "void inverse(float matrix[][], int n) {\n  // Implementation can vary widely; often involves finding the adjoint and determinant.\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Matrix Addition/Subtraction": "O(n*m) - where n and m are the dimensions of the matrices",
              "Matrix Multiplication": "O(n^3) using the standard algorithm, but can be reduced with more advanced algorithms like Strassen's algorithm",
              "Matrix Transpose": "O(n*m) - where n and m are the dimensions of the matrix",
              "Determinant of a Matrix": "O(n!) for a naive approach, but more efficient methods exist",
              "Inverse of a Matrix": "O(n^3) - typically involves Gaussian elimination or other methods"
            },
            "Space Complexity": {
              "General": "O(n*m) - Additional space needed for the resulting matrix, where n and m are the dimensions of the input matrices"
            }
          }
        }
      }          
    ]
  },
  {
    "category": "Medium",
    "Problems": [
      {
        "Topic": "Adjacency Matrix Representation",
        "Info": {
          "Definition": "An adjacency matrix is a square matrix used to represent a finite graph. The elements of the matrix indicate whether pairs of vertices are adjacent or not in the graph.",
          "Algorithms": {
            "Code": "int graph[V][V]; // V is the number of vertices\n// Initialize your matrix to 0\nfor(int i = 0; i < V; i++)\n  for(int j = 0; j < V; j++)\n    graph[i][j] = 0;\n// For every edge (u, v), set the value to 1 or the weight of the edge\ngraph[u][v] = 1; // For unweighted graph\ngraph[u][v] = w; // For weighted graph, where w is the weight"
          },
          "Complexities": {
            "Time Complexity": "O(1) for adding or checking the existence of an edge. O(V^2) for initializing the graph.",
            "Space Complexity": "O(V^2) - As it needs to store information for every possible edge."
          }
        }
      },
      {
        "Topic": "Adjacency List Representation",
        "Info": {
          "Definition": "An adjacency list represents a graph as an array of linked lists. The index of the array represents a vertex and each element in its linked list represents the other vertices that form an edge with the vertex.",
          "Algorithms": {
            "Code": "vector<int> adj[V]; // V is the number of vertices\n// For every edge (u, v), add v to the adjacency list of u\nadj[u].push_back(v); // For directed graph\nadj[v].push_back(u); // For undirected graph, do this as well"
          },
          "Complexities": {
            "Time Complexity": "O(V+E) for initializing the graph. O(deg(v)) for querying all adjacent vertices of a vertex v.",
            "Space Complexity": "O(V+E) - As it needs to store information for every vertex and edge."
          }
        }
      },
      {
        "Topic": "Priority Queue",
        "Info": {
          "Definition": "A priority queue is a special type of queue in which each element is associated with a priority value. And, elements are served on the basis of their priority. That is, higher priority elements are served first.However, if elements with the same priority occur, they are served according to their order in the queue.",
          "Algorithms": {
            "Insert Operation": "void insert(int priority, int data) {\n  if (isFull()) {\n    cout << \"Priority Queue is full\";\n    return;\n  }\n  Node* newNode = new Node(priority, data);\n  if (isEmpty() || priority > front->priority) {\n    newNode->next = front;\n    front = newNode;\n  } else {\n    Node* temp = front;\n    while (temp->next != NULL && temp->next->priority >= priority) {\n      temp = temp->next;\n    }\n    newNode->next = temp->next;\n    temp->next = newNode;\n  }\n  size++;\n}",
            "Delete Operation": "void delete() {\n  if (isEmpty()) {\n    cout << \"Priority Queue is empty\";\n    return;\n  }\n  Node* temp = front;\n  front = front->next;\n  delete temp;\n  size--;\n}",
            "isEmpty Operation": "bool isEmpty() {\n  return (front == NULL);\n}",
            "isFull Operation": "bool isFull() {\n  // This implementation might vary based on underlying data structure. For a linked list, it might be system memory dependent.\n}",
            "Peek Opeartion": "int peek() {\n  if (isEmpty()) {\n    cout << \"Priority Queue is empty\";\n    return INT_MIN;\n  }\n  return front->data;\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Insert": "O(n) - In the worst case, we traverse the entire list.",
              "Delete": "O(1) - Deletion always occurs at the front.",
              "Peek": "O(1) - Peeking only looks at the front element.",
              "isEmpty": "O(1)",
              "isFull": "Varies - For linked list implementations, it might depend on available system memory."
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Deque Data Structure",
        "Info": {
          "Definition": "Deque or Double Ended Queue is a type of queue in which insertion and removal of elements can either be performed from the front or the rear. Thus, it does not follow FIFO rule (First In First Out).\nTypes of Deque:\nInput Restricted Deque:  In this deque, input is restricted at a single end but allows deletion at both the ends.\nOutput Restricted Deque:  In this deque, output is restricted at a single end but allows insertion at both the ends.",
          "Algorithms": {
            "Insert Operation": "void insert(int priority, int data) {\n  if (isFull()) {\n    cout << \"Priority Queue is full\";\n    return;\n  }\n  Node* newNode = new Node(priority, data);\n  if (isEmpty() || priority > front->priority) {\n    newNode->next = front;\n    front = newNode;\n  } else {\n    Node* temp = front;\n    while (temp->next != NULL && temp->next->priority >= priority) {\n      temp = temp->next;\n    }\n    newNode->next = temp->next;\n    temp->next = newNode;\n  }\n  size++;\n}",
            "Delete Operation": "void delete() {\n  if (isEmpty()) {\n    cout << \"Priority Queue is empty\";\n    return;\n  }\n  Node* temp = front;\n  front = front->next;\n  delete temp;\n  size--;\n}",
            "isEmpty Operation": "bool isEmpty() {\n  return (front == NULL);\n}",
            "isFull Operation": "bool isFull() {\n  // This implementation might vary based on underlying data structure. For a linked list, it might be system memory dependent.\n}",
            "Peek Opeartion": "int peek() {\n  if (isEmpty()) {\n    cout << \"Priority Queue is empty\";\n    return INT_MIN;\n  }\n  return front->data;\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Insert": "O(n) - In the worst case, we traverse the entire list.",
              "Delete": "O(1) - Deletion always occurs at the front.",
              "Peek": "O(1) - Peeking only looks at the front element.",
              "isEmpty": "O(1)",
              "isFull": "Varies - For linked list implementations, it might depend on available system memory."
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Perfect Binary Tree",
        "Info": {
          "Definition": "A perfect binary tree is a type of binary tree in which every internal node has exactly two children and all leaf nodes are at the same level.",
          "Algorithms": {
            "Code": "Node* createPerfectBinaryTree(int depth) {\n  if (depth == 0) return NULL;\n  Node* node = new Node(0);\n  node->left = createPerfectBinaryTree(depth - 1);\n  node->right = createPerfectBinaryTree(depth - 1);\n  return node;\n}"
          },
          "imageLink":"/Perfect Binary Tree.png",
          "Complexities": {
            "Time Complexity": "O(2^depth - 1) - Because it visits every node.",
            "Space Complexity": "O(2^depth - 1) - Due to storing all nodes."
          }
        }
      },
      {
        "Topic": "Full Binary Tree",
        "Info": {
          "Definition": "A full binary tree (sometimes proper binary tree or 2-tree) is a tree in which every node other than the leaves has two children.",
          "Algorithms": {
            "Code": "class TreeNode {\npublic:\n  int value;\n  TreeNode *left, *right;\n\n  TreeNode(int val) : value(val), left(NULL), right(NULL) {}\n};\n\nclass FullBinaryTree {\npublic:\n  TreeNode *root;\n\n  FullBinaryTree() : root(NULL) {}\n\n  TreeNode* insert(TreeNode* node, int value) {\n    if (node == NULL) return new TreeNode(value);\n    std::queue<TreeNode*> q;\n    q.push(node);\n    while (!q.empty()) {\n      TreeNode* temp = q.front();\n      q.pop();\n      if (!temp->left) {\n        temp->left = new TreeNode(value);\n        return root;\n      } else q.push(temp->left);\n      if (!temp->right) {\n        temp->right = new TreeNode(value);\n        return root;\n      } else q.push(temp->right);\n    }\n    return root;\n  }\n\n  // Pseudocode for deletion is omitted as maintaining a full binary tree upon arbitrary deletions requires complex restructuring or specific context\n};\n\n// Example usage:\n// FullBinaryTree tree;\n// tree.root = tree.insert(tree.root, 10);\n// tree.root = tree.insert(tree.root, 20);"
          },
          "Complexities": {
            "Time Complexity": "O(N) - Level-order traversal may need to visit each node to find the insertion spot.",
            "Space Complexity": "O(N) - In the worst case, the queue used for level-order traversal may hold all nodes at the tree's deepest level."
          }
        }
      },
      {
        "Topic": "Complete Binary Tree",
        "Info": {
          "Definition": "A complete binary tree is a binary tree in which all levels are fully filled except possibly the last, which is filled from left to right.",
          "Algorithms": {
            "Insertion": "void insert(Node* root, int key) {\n  if (root == NULL) root = new Node(key);\n  else {\n    queue<Node*> q;\n    q.push(root);\n    while (!q.empty()) {\n      Node* temp = q.front();\n      q.pop();\n      if (!temp->left) {\n        temp->left = new Node(key);\n        break;\n      } else q.push(temp->left);\n      if (!temp->right) {\n        temp->right = new Node(key);\n        break;\n      } else q.push(temp->right);\n    }\n  }\n}",
            "Deletion": "void deleteDeepest(Node* root, Node* d_node) {\n  queue<Node*> q;\n  q.push(root);\n  Node* temp;\n  while(!q.empty()) {\n    temp = q.front();\n    q.pop();\n    if (temp == d_node) {\n      temp = NULL;\n      delete(d_node);\n      return;\n    }\n    if (temp->right) {\n      if (temp->right == d_node) {\n        temp->right = NULL;\n        delete(d_node);\n        return;\n      } else q.push(temp->right);\n    }\n    if (temp->left) {\n      if (temp->left == d_node) {\n        temp->left = NULL;\n        delete(d_node);\n        return;\n      } else q.push(temp->left);\n    }\n  }\n}\n\n// Function to delete given node\n// Function to call deleteDeepest"
          },
          "Complexities": {
            "Time Complexity": "O(n) for both insertion and deletion due to potential full traversal.",
            "Space Complexity": "O(n) for the queue used in traversal."
          }
        }
      },
      {
        "Topic": "Balanced Binary Tree",
        "Info": {
          "Definition": "A balanced binary tree is a type of binary tree where the difference between heights of left and right subtrees of any node is not more than one. Balanced binary trees, such as AVL trees or Red-Black trees, automatically maintain height balance to ensure operation complexities.",
          "Algorithms": {
            "Insertion":"Node* insert(Node* node, int key) {\n  if (node == NULL) return(new Node(key));\n  if (key < node->key) node->left = insert(node->left, key);\n  else if (key > node->key) node->right = insert(node->right, key);\n  else return node;\n  node->height = 1 + max(height(node->left), height(node->right));\n  int balance = getBalance(node);\n  if (balance > 1 && key < node->left->key) return rightRotate(node);\n  if (balance < -1 && key > node->right->key) return leftRotate(node);\n  if (balance > 1 && key > node->left->key) {\n    node->left = leftRotate(node->left);\n    return rightRotate(node);\n  }\n  if (balance < -1 && key < node->right->key) {\n    node->right = rightRotate(node->right);\n    return leftRotate(node);\n  }\n  return node;\n}",
            "Deletion": "Node* deleteNode(Node* root, int key) {\n  if (root == NULL) return root;\n  if ( key < root->key ) root->left = deleteNode(root->left, key);\n  else if( key > root->key ) root->right = deleteNode(root->right, key);\n  else {\n    if( (root->left == NULL) || (root->right == NULL) ) {\n      Node *temp = root->left ? root->left : root->right;\n      if (temp == NULL) {\n        temp = root;\n        root = NULL;\n      } else *root = *temp;\n      free(temp);\n    } else {\n      Node* temp = minValueNode(root->right);\n      root->key = temp->key;\n      root->right = deleteNode(root->right, temp->key);\n    }\n  }\n  if (root == NULL) return root;\n  root->height = max(height(root->left), height(root->right)) + 1;\n  int balance = getBalance(root);\n  if (balance > 1 && getBalance(root->left) >= 0) return rightRotate(root);\n  if (balance > 1 && getBalance(root->left) < 0) {\n    root->left = leftRotate(root->left);\n    return rightRotate(root);\n  }\n  if (balance < -1 && getBalance(root->right) <= 0) return leftRotate(root);\n  if (balance < -1 && getBalance(root->right) > 0) {\n    root->right = rightRotate(root->right);\n    return leftRotate(root);\n  }\n  return root;\n}"
           
          },
          "Complexities": {
            "Time Complexity": "O(log n) - For operations like insertion and deletion, due to height-balancing. This ensures that the tree remains balanced, thereby maintaining a logarithmic height.",
            "Space Complexity": "O(n) - Space needed to store all nodes in the tree."
          }
        }
      },
      {
        "Topic": "Binary Search Tree",
        "Info": {
          "Definition": "A binary search tree (BST) is a binary tree where each node has a key greater than all keys in the node's left subtree and less than those in the right subtree.",
          "Algorithms": {
            "Insertion":"Node* insertBST(Node* node, int key) {\n  if (node == NULL) return new Node(key);\n  if (key < node->data) node->left = insertBST(node->left, key);\n  else if (key > node->data) node->right = insertBST(node->right, key);\n  return node;\n}",
            "Deletion":"Node* deleteBST(Node* root, int key) {\n  if (root == NULL) return root;\n  if (key < root->data) root->left = deleteBST(root->left, key);\n  else if (key > root->data) root->right = deleteBST(root->right, key);\n  else {\n    if (root->left == NULL) {\n      Node *temp = root->right;\n      delete root;\n      return temp;\n    } else if (root->right == NULL) {\n      Node *temp = root->left;\n      delete root;\n      return temp;\n    }\n    Node* temp = minValueNode(root->right);\n    root->data = temp->data;\n    root->right = deleteBST(root->right, temp->data);\n  }\n  return root;\n}"
          },
          "Complexities": {
            "Time Complexity": "O(n) in the worst case (unbalanced tree), O(log n) in the best case (balanced tree) - For operations like search, insertion, and deletion.",
            "Space Complexity": "O(n) - Space needed to store all nodes in the tree."
          }
        }
      },
      {
        "Topic": "AVL Tree",
        "Info": {
          "Definition": "An AVL tree is a self-balancing binary search tree, where the difference between heights of left and right subtrees cannot be more than one for all nodes.",
          "Algorithms": {
            "Insertion": "Node* insertAVL(Node* node, int key) {\n  // Perform the normal BST insert\n  if (node == NULL) return (new Node(key));\n  if (key < node->key) node->left = insertAVL(node->left, key);\n  else if (key > node->key) node->right = insertAVL(node->right, key);\n  else return node; // Duplicate keys not allowed\n  // Update height of this ancestor node\n  // Calculate balance factor\n  // Rotate if unbalanced\n  return node;\n}",
            "Deletion": "Node* deleteAVL(Node* root, int key) {\n  // Perform standard BST delete\n  if (root == NULL) return root;\n  if (key < root->key) root->left = deleteAVL(root->left, key);\n  else if(key > root->key) root->right = deleteAVL(root->right, key);\n  else {\n    // Node with only one child or no child\n    if((root->left == NULL) || (root->right == NULL)) {\n      Node *temp = root->left ? root->left : root->right;\n      if (temp == NULL) {\n        temp = root;\n        root = NULL;\n      } else *root = *temp; // Copy the contents of the non-empty child\n      delete temp;\n    } else {\n      // Node with two children: Get the inorder successor\n      Node* temp = minValueNode(root->right);\n      root->key = temp->key;\n      root->right = deleteAVL(root->right, temp->key);\n    }\n  }\n  // If the tree had only one node then return\n  if (root == NULL) return root;\n  // Update height of the current node\n  // Get the balance factor\n  // Rotate if unbalanced\n  return root;\n}"
            
          },
          "Complexities": {
            "Time Complexity": "O(log n) - For insertion, deletion, and lookup, due to the tree being balanced.",
            "Space Complexity": "O(n) - Space needed to store all nodes in the tree."
          }
        }
      },
      {
        "Topic": "Red-Black Tree",
        "Info": {
          "Definition": "A Red-Black Tree is a kind of self-balancing binary search tree where each node has an extra bit for denoting the color of the node, either red or black. A Red-Black Tree ensures that the tree remains balanced, and operations like insertion, deletion, and search can be performed in logarithmic time complexity.",
          "Algorithms": {
            "Insertion Code": "void insert(Node *&root, int data) {\n    // Perform normal BST insert\n    // Color the new node as RED\n    // Fix Red Black Tree violations\n}",
            "Deletion Code": "void deleteNode(Node *&root, int data) {\n    // Perform standard BST delete\n    // Fix Red Black Tree violations\n}"
          },
          "Complexities": {
            "Time Complexity": {
              "Search": "O(log n)",
              "Insert": "O(log n)",
              "Delete": "O(log n)"
            },
            "Space Complexity": "O(n), where n is the number of nodes in the tree."
          }
        }
      },
      {
        "Topic": "Spanning Tree",
        "Info": {
          "Definition": "A spanning tree of an undirected graph is a subgraph that includes all the vertices of the graph and is a tree. A single graph can have many different spanning trees.",
          "Algorithms": {
            "Code": "Prim's or Kruskal's algorithms are commonly used to find the minimum spanning tree of a graph. Refer to specific implementations for these algorithms."
          },
          "Complexities": {
            "Time Complexity": "Depends on the algorithm used (e.g., O(E log V) for Prim's algorithm using a binary heap).",
            "Space Complexity": "O(V+E) - As it stores the tree structure."
          }
        }
      },
      {
        "Topic": "Segment Trees",
        "Info": {
          "Definition": "A segment tree is a tree data structure used for storing information about intervals, or segments. It allows querying which of the stored segments contain a given point. Essentially, it is a binary tree used for storing the intervals or segments of an array. Segment trees support operations like finding the minimum, maximum, sum, and greatest common divisor of intervals with update and query times logarithmic to the number of intervals.",
          "Algorithms": {
            "Build Tree": "void buildTree(int* arr, int* segTree, int start, int end, int treeNode) {\n  if(start == end) {\n    segTree[treeNode] = arr[start];\n    return;\n  }\n  int mid = (start + end) / 2;\n  buildTree(arr, segTree, start, mid, 2*treeNode);\n  buildTree(arr, segTree, mid+1, end, 2*treeNode+1);\n  segTree[treeNode] = min(segTree[2*treeNode], segTree[2*treeNode+1]);\n}",
            "Update Tree": "void updateTree(int* arr, int* segTree, int start, int end, int treeNode, int idx, int value) {\n  if(start == end) {\n    arr[idx] = value;\n    segTree[treeNode] = value;\n    return;\n  }\n  int mid = (start + end) / 2;\n  if(idx > mid) {\n    updateTree(arr, segTree, mid+1, end, 2*treeNode+1, idx, value);\n  } else {\n    updateTree(arr, segTree, start, mid, 2*treeNode, idx, value);\n  }\n  segTree[treeNode] = min(segTree[2*treeNode], segTree[2*treeNode+1]);\n}",
            "Query Tree": "int queryTree(int* segTree, int start, int end, int treeNode, int left, int right) {\n  if(start > right || end < left) {\n    return INT_MAX;\n  }\n  if(start >= left && end <= right) {\n    return segTree[treeNode];\n  }\n  int mid = (start + end) / 2;\n  int ans1 = queryTree(segTree, start, mid, 2*treeNode, left, right);\n  int ans2 = queryTree(segTree, mid+1, end, 2*treeNode+1, left, right);\n  return min(ans1, ans2);\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Build Tree": "O(n), where n is the number of elements in the array",
              "Update Tree": "O(log n), where n is the number of elements in the array",
              "Query Tree": "O(log n), for querying a range of elements"
            },
            "Space Complexity": {
              "Build Tree": "O(4*n), due to the storage of 4 times the number of elements in the segment tree array",
              "Update Tree": "O(4*n), does not change the overall space requirement of the segment tree",
              "Query Tree": "O(log n), for the recursion stack, not counting the space for the segment tree itself"
            }
          }
        }
      },       
      {
        "Topic": "Tree Traversals",
        "Info": {
          "Definition": "Traversing a tree means visiting every node in the tree. You might, for instance, want to add all the values in the tree or find the largest one. For all these operations, you will need to visit each node of the tree.Tree traversal algorithms are methods for visiting all the nodes in a tree data structure. There are several types of traversals, each visiting the nodes in a different order. The three fundamental depth-first search (DFS) traversals for binary trees are preorder, inorder, and postorder.\nPreorder Traversal : Visits the current node before its child nodes (Root, Left, Right). \n Inorder Traversal:  Visits the left child, then the current node, and finally the right child (Left, Root, Right). This traversal method is used especially for binary search trees where it returns nodes in non-decreasing order. \n PostOrder Traversal :Visits the current node after its child nodes (Left, Right, Root). This method is used to delete the tree or get the postfix expression of an expression tree.",
          "Algorithms": {
            "Preorder Traversal": "void preorderTraversal(Node* root) {\n  if (root == NULL) return;\n  cout << root->data << ' ';\n  preorderTraversal(root->left);\n  preorderTraversal(root->right);\n}",
            "Inorder Traversal": "void inorderTraversal(Node* root) {\n  if (root == NULL) return;\n  inorderTraversal(root->left);\n  cout << root->data << ' ';\n  inorderTraversal(root->right);\n}",
            "Postorder Traversal": "void postorderTraversal(Node* root) {\n  if (root == NULL) return;\n  postorderTraversal(root->left);\n  postorderTraversal(root->right);\n  cout << root->data << ' ';\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Preorder": "O(n)",
              "Inorder": "O(n)",
              "Postorder": "O(n)"
            },
            "Space Complexity": "O(h) - where h is the height of the tree. This space complexity accounts for the call stack during recursive calls."
          }
        }
      },
      {
        "Topic": "B-Tree",
        "Info": {
          "Definition": "A B-Tree is a self-balancing tree data structure that maintains sorted data and allows searches, sequential access, insertions, and deletions in logarithmic time. It generalizes the binary search tree, allowing for nodes with more than two children.",
          "Algorithms": {
            "Insertion Code": "void insert(Node* &root, int key) {\n    // Check if the tree is empty\n    if (root == nullptr) {\n        root = createNode(key);\n        return;\n    }\n\n    // Recursive insert function\n    // Insert logic for B-Tree insertion\n}",
            "Deletion Code": "void deleteKey(Node* &root, int key) {\n    // Deletion logic for B-Tree\n    // Handle cases: leaf and internal nodes\n}"
          },
          "Complexities": {
            "Time Complexity": {
              "Search": "O(log n)",
              "Insert": "O(log n)",
              "Delete": "O(log n)"
            },
            "Space Complexity": "O(n), where n is the number of keys in the tree."
          }
        }
      },
      {
        "Topic": "B+ Tree",
        "Info": {
          "Definition": "A B+ Tree is a type of B-Tree used in databases and filesystems to store data for efficient retrieval. It differs from a B-Tree by storing all data in leaf nodes and using internal nodes as a means to provide a pathway to these leaf nodes.",
          "Algorithms": {
            "Insertion Code": "void BPlusTreeInsertion(Node* &root, int key) {\n    // Insert logic for B+ Tree\n    // Ensures that all data is in the leaf nodes\n}",
            "Deletion Code": "void BPlusTreeDeletion(Node* &root, int key) {\n    // Deletion logic for B+ Tree\n    // Adjusts tree to maintain properties after deletion\n}"
          },
          "Complexities": {
            "Time Complexity": {
              "Search": "O(log n)",
              "Insert": "O(log n)",
              "Delete": "O(log n)"
            },
            "Space Complexity": "O(n), where n is the number of keys."
          }
        }
      },      
      {
        "Topic": "Merge Sort",
        "Info": {
          "Definition": "Merge Sort is a divide-and-conquer algorithm that divides the input array into two halves, calls itself for the two halves, and then merges the two sorted halves. It is known for its consistent performance and is often used in sorting libraries.",
          "Algorithms": {
            "Code":"void merge(int arr[], int l, int m, int r) {\n    int n1 = m - l + 1;\n    int n2 = r - m;\n\n    // Create temp arrays\n    int L[n1], R[n2];\n\n    // Copy data to temp arrays L[] and R[]\n    for (int i = 0; i < n1; i++)\n        L[i] = arr[l + i];\n    for (int j = 0; j < n2; j++)\n        R[j] = arr[m + 1 + j];\n\n    // Merge the temp arrays back into arr[l..r]\n    int i = 0; // Initial index of first subarray\n    int j = 0; // Initial index of second subarray\n    int k = l; // Initial index of merged subarray\n    while (i < n1 && j < n2) {\n        if (L[i] <= R[j]) {\n            arr[k] = L[i];\n            i++;\n        } else {\n            arr[k] = R[j];\n            j++;\n        }\n        k++;\n    }\n\n    // Copy the remaining elements of L[], if there are any\n    while (i < n1) {\n        arr[k] = L[i];\n        i++;\n        k++;\n    }\n\n    // Copy the remaining elements of R[], if there are any\n    while (j < n2) {\n        arr[k] = R[j];\n        j++;\n        k++;\n    }\n}\n\nvoid mergeSort(int arr[], int l, int r) {\n    if (l < r) {\n        // Find the middle point to divide the array into two halves\n        int m = l + (r-l)/2;\n\n        // Call mergeSort for first half\n        mergeSort(arr, l, m);\n\n        // Call mergeSort for second half\n        mergeSort(arr, m+1, r);\n\n        // Merge the sorted halves\n        merge(arr, l, m, r);\n    }\n}"
          },
          "Complexities": {
            "Time Complexity": "Worst, Average, and Best Case: O(n log n) - Merge sort always divides the array in half and takes linear time to merge two halves.",
            "Space Complexity": "O(n) - Requires additional space for the temporary arrays used in the merge process."
          }
        }
      },
      {
        "Topic": "Quick Sort",
        "Info": {
          "Definition": "Quick Sort is a highly efficient sorting algorithm and is based on partitioning of array of data into smaller arrays. A large array is partitioned into two arrays one of which holds values smaller than the specified value, say pivot, based on which the partition is made and another array holds values greater than the pivot value.",
          "Algorithms": {
            "Code":"void quickSort(int arr[], int low, int high) {\n  if (low < high) {\n    int pi = partition(arr, low, high);\n    quickSort(arr, low, pi - 1);\n    quickSort(arr, pi + 1, high);\n  }\n}\n\nint partition(int arr[], int low, int high) {\n  // This function takes last element as pivot, places the pivot element at its correct position in sorted array, and places all smaller to left of pivot and all greater elements to right of pivot.\n}"
          },
          "Complexities": {
            "Time Complexity": "Worst Case: O(n^2) when the pivot selection is poor. Average and Best Case: O(n log n) - The array is divided into subarrays that are processed recursively.",
            "Space Complexity": "O(log n) - The space complexity comes from the stack space used for recursion. The worst case is O(n), depending on the implementation."
          }
        }
      },
      {
        "Topic": "Heap Data Structure",
        "Info": {
          "Definition": "A Heap is a special Tree-based data structure that satisfies the heap property. In a max heap, for any given node C, if P is a parent node of C, then the key (the value) of P is greater than or equal to the key of C. The same property must be recursively true for all nodes in Binary Tree. Min heap is a heap where the value of parent nodes is less than or equal to that of child nodes.",
          "Algorithms": {
            "Insert (Heapify Up)": "Inserts a new element into the heap and re-arranges the heap to maintain the heap property.\n\nvoid insert(int key) {\n  heapSize++; // Assume heapSize is the current number of elements in the heap\n  int index = heapSize - 1;\n  heap[index] = key;\n  // Heapify up\n  while (index != 0 && heap[parent(index)] < heap[index]) {\n    swap(heap[index], heap[parent(index)]);\n    index = parent(index);\n  }\n}",
            "Delete (Heapify Down)": "Removes the root element from the heap and re-arranges it to maintain the heap property.\n\nvoid deleteRoot() {\n  if (heapSize <= 0) return;\n  heap[0] = heap[heapSize-1];\n  heapSize--;\n  heapifyDown(0);\n}",
            "Get Max or Min": "Retrieves the maximum element from a max heap or the minimum element from a min heap without removing it.\n\nint getPeak() {\n  return heap[0];\n}",
            "Build Heap (Heapify)": "Converts an unsorted array into a heap.\n\nvoid buildHeap(int arr[], int n) {\n  for (int i = (n / 2) - 1; i >= 0; i--) {\n    heapify(arr, n, i);\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Insert (Heapify Up)": "O(log n) - Because it may traverse from the node inserted at the very end up to the root node.",
              "Delete (Heapify Down)": "O(log n) - Due to the traversal down from the root to the leaf to maintain the heap property.",
              "Get Max or Min": "O(1) - The peak element is always at the root of the heap.",
              "Build Heap (Heapify)": "O(n) - Building the heap from an unsorted array takes linear time."
            },
            "Space Complexity": "O(n) - The space needed to store the heap structure."
          }
        }
      },
      {
        "Topic": "Heap Sort",
        "Info":{
          "Definition": "Heap Sort is a comparison-based sorting technique based on the Binary Heap data structure. It's similar to the selection sort where we first find the maximum element and place it at the end. The same process is repeated for the remaining elements, utilizing a heap to efficiently find the next maximum element.",
          "Algorithms":{
            "Code": "void heapify(int arr[], int n, int i) {\n    int largest = i; // Initialize largest as root\n    int l = 2 * i + 1; // left = 2*i + 1\n    int r = 2 * i + 2; // right = 2*i + 2\n\n    // If left child is larger than root\n    if (l < n && arr[l] > arr[largest])\n        largest = l;\n\n    // If right child is larger than largest so far\n    if (r < n && arr[r] > arr[largest])\n        largest = r;\n\n    // If largest is not root\n    if (largest != i) {\n        swap(arr[i], arr[largest]);\n\n        // Recursively heapify the affected sub-tree\n        heapify(arr, n, largest);\n    }\n}\n\nvoid heapSort(int arr[], int n) {\n    // Build heap (rearrange array)\n    for (int i = n / 2 - 1; i >= 0; i--)\n        heapify(arr, n, i);\n\n    // One by one extract an element from heap\n    for (int i = n - 1; i >= 0; i--) {\n        // Move current root to end\n        swap(arr[0], arr[i]);\n\n        // call max heapify on the reduced heap\n        heapify(arr, i, 0);\n    }\n}"
          },
        "Complexities":{
          "Time Complexity": {
            "Worst Case": "O(n log n)",
            "Average Case": "O(n log n)",
            "Best Case": "O(n log n)"
          },
          "Space Complexity": "O(1) - Heap sort is an in-place algorithm but may require a small stack for recursion during heapify."
        }
        
        }   
      },
      {
        "Topic": "Count Sort",
        "Info": {
          "Definition": "Count Sort is an integer sorting algorithm that operates by counting the number of occurrences of each distinct value in the input array. These counts are then used to compute the position of each element in the sorted array.",
          "Algorithms": {
            "Code": "void countSort(int arr[], int n) {\n    int output[n];\n    int count[256], i;\n    memset(count, 0, sizeof(count));\n\n    for(i = 0; arr[i]; ++i)\n        ++count[arr[i]];\n\n    for (i = 1; i <= 255; ++i)\n        count[i] += count[i-1];\n\n    for (i = 0; arr[i]; ++i) {\n        output[count[arr[i]]-1] = arr[i];\n        --count[arr[i]];\n    }\n\n    for (i = 0; arr[i]; ++i)\n        arr[i] = output[i];\n}"
          },
          "Complexities": {
            "Time Complexity": "O(n + k) - Where n is the number of elements and k is the range of the input.",
            "Space Complexity": "O(k) - The space used by the count array."
          }
        }
      },
      {
        "Topic": "Radix Sort",
        "Info": {
          "Definition": "Radix Sort is a non-comparative sorting algorithm that sorts integers by processing individual digits. Numbers are grouped by each digit, starting from the least significant digit to the most significant digit, using a stable algorithm like Count Sort as a subroutine.",
          "Algorithms": {
            "Code": "void countSort(int arr[], int n, int exp) {\n    vector<int> output(n);\n    int i, count[10] = {0};\n\n    for (i = 0; i < n; i++)\n        count[(arr[i] / exp) % 10]++;\n\n    for (i = 1; i < 10; i++)\n        count[i] += count[i - 1];\n\n    for (i = n - 1; i >= 0; i--) {\n        output[count[(arr[i] / exp) % 10] - 1] = arr[i];\n        count[(arr[i] / exp) % 10]--;\n    }\n\n    for (i = 0; i < n; i++)\n        arr[i] = output[i];\n}\n\nvoid radixSort(int arr[], int n) {\n    int m = getMax(arr, n);\n    for (int exp = 1; m / exp > 0; exp *= 10)\n        countSort(arr, n, exp);\n}"
          },
          "Complexities": {
            "Time Complexity": "O(nk) - Where n is the number of elements and k is the number of digits in the maximum number.",
            "Space Complexity": "O(n + k) - For the intermediate count sort operations."
          }
        }
      },
      {
        "Topic": "Bucket Sort",
        "Info": {
          "Definition": "Bucket Sort, or Bin Sort, operates by partitioning an array into a number of buckets. Each bucket is then sorted individually, either using a different sorting algorithm, or by recursively applying the bucket sort algorithm.",
          "Algorithms": {
            "Code": "void bucketSort(float arr[], int n) {\n    vector<float> b[n];\n    for (int i = 0; i < n; i++) {\n       int bi = n * arr[i]; // Index in bucket\n       b[bi].push_back(arr[i]);\n    }\n\n    for (int i = 0; i < n; i++)\n       sort(b[i].begin(), b[i].end());\n\n    int index = 0;\n    for (int i = 0; i < n; i++)\n       for (int j = 0; j < b[i].size(); j++)\n          arr[index++] = b[i][j];\n}"
          },
          "Complexities": {
            "Time Complexity": "Average Case: O(n + n^2/k + k), and Worst Case: O(n^2). Here, n is the number of elements, and k is the number of buckets.",
            "Space Complexity": "O(n*k) - For the buckets used during sorting."
          }
        }
      },
      {
        "Topic": "Dijkstra's Algorithm",
        "Info": {
          "Definition": "Dijkstra's Algorithm finds the shortest paths from a single source vertex to all other vertices in a weighted graph with non-negative edge weights.",
          "Algorithms": {
            "Code": "void dijkstra(const vector<vector<int>>& graph, int src) {\n  int V = graph.size();\n  vector<int> dist(V, INT_MAX);\n  dist[src] = 0;\n  vector<bool> sptSet(V, false);\n\n  for (int count = 0; count < V-1; count++) {\n    int u = -1;\n    for(int i = 0; i < V; i++)\n      if (!sptSet[i] && (u == -1 || dist[i] < dist[u]))\n        u = i;\n    sptSet[u] = true;\n    for (int v = 0; v < V; v++)\n      if (!sptSet[v] && graph[u][v] && dist[u] != INT_MAX && dist[u]+graph[u][v] < dist[v])\n        dist[v] = dist[u] + graph[u][v];\n  }\n}"
          },
          "Complexities": {
            "Time Complexity": "O(V^2) - For the implementation using adjacency matrix. With a priority queue, it can be reduced to O(V + E log V) where E is the number of edges.",
            "Space Complexity": "O(V) - Space needed for the distance array and the sptSet."
          }
        }
      },
      {
        "Topic": "Minimal Spanning Tree",
        "Info": {
          "Definition": "A Minimal Spanning Tree (MST) of a connected, undirected graph is a tree formed from graph edges that connects all the vertices together, without any cycles and with the minimum possible total edge weight. Finding a MST is a key problem in network design, such as designing the least expensive network, road, electrical grid, or in any application where a problem can be represented as a weighted graph. The two most famous algorithms for finding a MST are Kruskal's algorithm and Prim's algorithm.",
          "Algorithms": {
            "Kruskal's Algorithm Implementation": "struct Edge { int src, dest, weight; };\nvector<int> parent, rank;\nint find(int i) {\n  if (parent[i] != i)\n    parent[i] = find(parent[i]);\n  return parent[i];\n}\nvoid unionSet(int x, int y) {\n  x = find(x);\n  y = find(y);\n  if (rank[x] > rank[y])\n    parent[y] = x;\n  else\n    parent[x] = y;\n  if (rank[x] == rank[y])\n    rank[y]++;\n}\nvoid KruskalMST(vector<Edge>& edges, int V) {\n  sort(edges.begin(), edges.end(), [](Edge a, Edge b) { return a.weight < b.weight; });\n  parent.resize(V);\n  rank.resize(V, 0);\n  for (int i = 0; i < V; i++)\n    parent[i] = i;\n  vector<Edge> mst;\n  for (Edge e : edges) {\n    if (find(e.src) != find(e.dest)) {\n      unionSet(e.src, e.dest);\n      mst.push_back(e);\n    }\n  }\n}",
            "Prim's Algorithm Implementation": "int minKey(vector<int>& key, vector<bool>& mstSet, int V) {\n  int min = INT_MAX, min_index;\n  for (int v = 0; v < V; v++)\n    if (mstSet[v] == false && key[v] < min)\n      min = key[v], min_index = v;\n  return min_index;\n}\nvoid primMST(vector<vector<int>>& graph, int V) {\n  vector<int> parent(V);\n  vector<int> key(V, INT_MAX);\n  vector<bool> mstSet(V, false);\n  key[0] = 0;\n  parent[0] = -1;\n  for (int count = 0; count < V-1; count++) {\n    int u = minKey(key, mstSet, V);\n    mstSet[u] = true;\n    for (int v = 0; v < V; v++)\n      if (graph[u][v] && mstSet[v] == false && graph[u][v] < key[v])\n        parent[v] = u, key[v] = graph[u][v];\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Kruskal's Algorithm": "O(E log E) or O(E log V), where E is the number of edges and V is the number of vertices.",
              "Prim's Algorithm": "O(E log V) using a binary heap and adjacency list, where E is the number of edges and V is the number of vertices."
            },
            "Space Complexity": {
              "Kruskal's Algorithm": "O(E + V), for storing the edge list and the disjoint set data structure.",
              "Prim's Algorithm": "O(V), for storing the keys, parents, and priority queue or heap."
            }
          }
        }
      },      
      {
        "Topic": "Kruskal's Algorithm",
        "Info": {
          "Definition": "Kruskal's Algorithm finds a minimum spanning tree for a connected, undirected graph by adding increasing cost edges at each step, avoiding any cycles.",
          "Algorithms": {
            "Code": "struct Edge { int src, dest, weight; };\nstruct Graph { int V, E; vector<Edge> edges; };\nint find(vector<int>& parent, int i) {\n  if (parent[i] == i) return i;\n  return find(parent, parent[i]);\n}\nvoid kruskalMST(struct Graph& graph) {\n  sort(graph.edges.begin(), graph.edges.end(), [](Edge a, Edge b) { return a.weight < b.weight; });\n  vector<int> parent(graph.V);\n  for (int i = 0; i < graph.V; i++) parent[i] = i;\n  vector<Edge> mst;\n  for (Edge e : graph.edges) {\n    int x = find(parent, e.src);\n    int y = find(parent, e.dest);\n    if (x != y) {\n      mst.push_back(e);\n      parent[x] = y;\n    }\n  }\n  // mst contains the resulting minimum spanning tree\n}"
          },
          "Complexities": {
            "Time Complexity": "O(E log E) - Or O(E log V) because of the sorting of edges, where E is the number of edges in the graph.",
            "Space Complexity": "O(V + E) - For storing the graph and the minimum spanning tree."
          }
        }
      },
      {
        "Topic": "Prim's Algorithm",
        "Info": {
          "Definition": "Prim's Algorithm is a greedy algorithm that finds the minimum spanning tree for a weighted undirected graph, ensuring that every vertex is connected without any cycles and with the minimum possible total edge weight.",
          "Algorithms": {
            "Code": "void primMST(int graph[V][V]) {\n    int parent[V];\n    int key[V];\n    bool mstSet[V];\n    for (int i = 0; i < V; i++)\n        key[i] = INT_MAX, mstSet[i] = false;\n    key[0] = 0;\n    parent[0] = -1;\n    for (int count = 0; count < V-1; count++) {\n        int u = minKey(key, mstSet);\n        mstSet[u] = true;\n        for (int v = 0; v < V; v++)\n            if (graph[u][v] && !mstSet[v] && graph[u][v] < key[v])\n                parent[v] = u, key[v] = graph[u][v];\n    }\n    printMST(parent, V, graph);\n}"
          },
          "Complexities": {
            "Time Complexity": "O(V^2) - For a graph represented using adjacency matrix. Can be improved to O(E log V) with adjacency list and priority queue.",
            "Space Complexity": "O(V) - To store the keys, MST set, and parent array."
          }
        }
      },
      {
        "Topic": "Recursion and Backtracking",
        "Info": {
          "Definition": "Recursion\nRecursion is a method of solving a problem where the solution depends on solutions to smaller instances of the same problem. A recursive function calls itself with a base case to stop the recursion.\nBacktracking\nBacktracking is an algorithmic-technique for solving problems recursively by trying to build a solution incrementally, one piece at a time, removing those solutions that fail to satisfy the constraints of the problem at any point of time.",
          
          "Algorithms": {
            
              "Recursion Example - Factorial": "int factorial(int n) {\n  if (n <= 1) return 1;\n  return n * factorial(n - 1);\n}",
              "Backtracking Example - N Queens Problem":"bool isSafe(int board[N][N], int row, int col) {\n  // Check this row on left side\n  // Check upper diagonal on left side\n  // Check lower diagonal on left side\n  // For simplification, these checks are omitted\n  return true;\n}\n\nbool solveNQUtil(int board[N][N], int col) {\n  if (col >= N) return true;\n  for (int i = 0; i < N; i++) {\n    if (isSafe(board, i, col)) {\n      board[i][col] = 1;\n      if (solveNQUtil(board, col + 1)) return true;\n      board[i][col] = 0; // BACKTRACK\n    }\n  }\n  return false;\n}"
            
          },
          "Complexities": {
            "Time Complexity": {
              "Recursion Example - Factorial": "O(n) - The time complexity is linear, as it makes a single call for each decrement of n until it reaches the base case.",
              "Backtracking Example - N Queens Problem": "O(N!) - The worst-case time complexity, as it tries every possible arrangement of queens."
            },
            "Space Complexity": {
              "Recursion Example - Factorial": "O(n) - Due to the call stack in recursion for each function call until the base case is reached.",
              "Backtracking Example - N Queens Problem": "O(N) - Mainly for the call stack in recursion. Additional space for the board is not considered here."
            }
          }
        }
      },
      {
        "Topic": "Backtracking Applications",
        "Info": {
          "Definition": "Backtracking is an algorithmic technique for solving problems recursively by trying to build a solution incrementally, one piece at a time, and removing those solutions that fail to satisfy the constraints of the problem at any point of time. It is particularly useful for traversal problems, constraint satisfaction problems like Sudoku solver, N queens problem, and graph coloring.",
          "Algorithms": {
            "Sudoku Solver": "void solveSudoku(vector<vector<int>>& board) {\n  if(solve(board)) {\n    print(board);\n  }\n}\nbool solve(vector<vector<int>>& board) {\n  for(int i = 0; i < board.size(); i++) {\n    for(int j = 0; j < board[0].size(); j++) {\n      if(board[i][j] == 0) {\n        for(int c = 1; c <= 9; c++) {\n          if(isValid(board, i, j, c)) {\n            board[i][j] = c;\n            if(solve(board))\n              return true;\n            else\n              board[i][j] = 0;\n          }\n        }\n        return false;\n      }\n    }\n  }\n  return true;\n}",
            "N Queens Problem": "bool solveNQ(vector<vector<int>>& board, int col) {\n  if(col >= N) return true;\n  for(int i = 0; i < N; i++) {\n    if(isSafe(board, i, col)) {\n      board[i][col] = 1;\n      if(solveNQ(board, col + 1)) return true;\n      board[i][col] = 0; // backtrack\n    }\n  }\n  return false;\n}",
            "Graph Coloring": "bool graphColoring(vector<int> graph[], int m, int V) {\n  vector<int> color(V, 0);\n  if(!graphColoringUtil(graph, m, color, 0, V)) {\n    return false;\n  }\n  return true;\n}\nbool graphColoringUtil(vector<int> graph[], int m, vector<int>& color, int v, int V) {\n  if(v == V) return true;\n  for(int c = 1; c <= m; c++) {\n    if(isSafe(v, graph, color, c, V)) {\n      color[v] = c;\n      if(graphColoringUtil(graph, m, color, v+1, V)) return true;\n      color[v] = 0; // backtrack\n    }\n  }\n  return false;\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Sudoku Solver": "O(9^(n^2)), where n is the number of rows/columns of the board (typically 9)",
              "N Queens Problem": "O(N!), where N is the number of queens",
              "Graph Coloring": "O(m^V), where m is the number of colors and V is the number of vertices"
            },
            "Space Complexity": {
              "Sudoku Solver": "O(n^2), for storing the board",
              "N Queens Problem": "O(N), for the recursion call stack",
              "Graph Coloring": "O(V), for storing colors assigned to vertices"
            }
          }
        }
      },      
      {
        "Topic": "Disjoint Set Union (Union Find)",
        "Info": {
          "Definition": "Disjoint Set Union (DSU), also known as Union Find, is a data structure that keeps track of a set of elements partitioned into a number of disjoint (non-overlapping) subsets. It supports two key operations: 'find', which identifies the subset to which an element belongs; and 'union', which merges two subsets. It's particularly useful for graph-based algorithms, such as finding cycles and building minimum spanning trees.",
          "Algorithms": {
            "Union Find Implementation": "class UnionFind {\nprivate:\n  vector<int> parent, rank;\npublic:\n  UnionFind(int N) {\n    parent.resize(N);\n    rank.resize(N, 0);\n    for(int i = 0; i < N; ++i) parent[i] = i;\n  }\n  int find(int x) {\n    if (parent[x] != x) {\n      parent[x] = find(parent[x]); // Path compression\n    }\n    return parent[x];\n  }\n  void unionSet(int x, int y) {\n    int xRoot = find(x), yRoot = find(y);\n    if (xRoot != yRoot) {\n      if (rank[xRoot] < rank[yRoot]) {\n        parent[xRoot] = yRoot;\n      } else if (rank[xRoot] > rank[yRoot]) {\n        parent[yRoot] = xRoot;\n      } else {\n        parent[yRoot] = xRoot;\n        rank[xRoot] = rank[xRoot] + 1;\n      }\n    }\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Find": "Amortized O(α(n)), where α(n) is the inverse Ackermann function. Practically, it's almost constant.",
              "Union": "Amortized O(α(n)), as it includes the cost of two find operations plus the cost of the union."
            },
            "Space Complexity": {
              "Union Find": "O(n), where n is the number of elements, for storing the parent and rank arrays."
            }
          }
        }
      },
      {
        "Topic": "Fractional Knapsack",
        "Info": {
          "Definition": "The Fractional Knapsack problem is a problem in combinatorial optimization. Given a set of items, each with a weight and a value, determine the amount of each item to include in a collection so that the total weight is less than or equal to a given limit and the total value is as large as possible. Unlike the 0/1 Knapsack problem, items may be broken into smaller pieces, hence 'fractional'. The solution is found using a greedy approach.",
          "Algorithms": {
            "Fractional Knapsack Algorithm": "struct Item {\n  int value, weight;\n};\nbool cmp(Item a, Item b) {\n  double r1 = (double)a.value / a.weight;\n  double r2 = (double)b.value / b.weight;\n  return r1 > r2;\n}\ndouble fractionalKnapsack(int W, Item arr[], int n) {\n  sort(arr, arr + n, cmp);\n  int curWeight = 0;\n  double finalvalue = 0.0;\n  for (int i = 0; i < n; i++) {\n    if (curWeight + arr[i].weight <= W) {\n      curWeight += arr[i].weight;\n      finalvalue += arr[i].value;\n    } else {\n      int remain = W - curWeight;\n      finalvalue += arr[i].value * ((double) remain / arr[i].weight);\n      break;\n    }\n  }\n  return finalvalue;\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Fractional Knapsack Algorithm": "O(n log n) for sorting the items based on their value/weight ratio, followed by O(n) for computing the final value."
            },
            "Space Complexity": {
              "Fractional Knapsack Algorithm": "O(1), not including the input space, as no additional space is needed beyond variables for calculation."
            }
          }
        }
      },
      {
        "Topic": "Job Scheduling in Greedy Algorithm",
        "Info": {
          "Definition": "Job scheduling is a common problem in computer science, where jobs with different deadlines and profits need to be scheduled in a way that maximizes total profit. The greedy approach to this problem involves sorting the jobs based on a specific criterion, such as profit or deadline, and then scheduling the jobs in a way that maximizes profit while meeting deadlines.",
          "Algorithms": {
            "Job Scheduling Algorithm": "struct Job {\n  char id;\n  int deadline, profit;\n};\nbool comparison(Job a, Job b) {\n  return (a.profit > b.profit);\n}\nvoid printJobScheduling(vector<Job> arr, int n) {\n  sort(arr.begin(), arr.end(), comparison);\n  vector<int> result(n, -1);\n  vector<bool> slot(n, false);\n  for (int i = 0; i < n; i++) {\n    for (int j = min(n, arr[i].deadline) - 1; j >= 0; j--) {\n      if (slot[j] == false) {\n        result[j] = i;\n        slot[j] = true;\n        break;\n      }\n    }\n  }\n  for (int i = 0; i < n; i++)\n    if (slot[i])\n      cout << arr[result[i]].id << ' ';\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Job Scheduling Algorithm": "O(n log n) for sorting the jobs by profit, followed by O(n^2) for scheduling jobs where n is the number of jobs."
            },
            "Space Complexity": {
              "Job Scheduling Algorithm": "O(n) for storing the result and slot arrays."
            }
          }
        }
      },
      {
        "Topic": "Memoization & Tabulation in Dynamic Programming",
        "Info": {
          "Definition": "Memoization and Tabulation are optimization techniques used in dynamic programming to reduce the computation time of recursive algorithms by storing results of expensive function calls. Memoization is a top-down approach, where results are stored in a table as they are computed from the recursive calls. Tabulation is a bottom-up approach, where the table is filled in order systematically, ensuring that all sub-problems are solved before solving the larger problem.",
          "Algorithms": {
            "Memoization Example (Fibonacci)": "int fib(int n, vector<int>& memo) {\n  if (n <= 1) return n;\n  if (memo[n] != -1) return memo[n];\n  memo[n] = fib(n-1, memo) + fib(n-2, memo);\n  return memo[n];\n}",
            "Tabulation Example (Fibonacci)": "int fib(int n) {\n  vector<int> table(n+1, 0);\n  table[1] = 1;\n  for(int i = 2; i <= n; i++) {\n    table[i] = table[i-1] + table[i-2];\n  }\n  return table[n];\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Memoization Example": "O(n), as it ensures that each problem is solved only once",
              "Tabulation Example": "O(n), similar efficiency but fills in a table from the bottom up"
            },
            "Space Complexity": {
              "Memoization Example": "O(n), for storing the memoization table plus the recursion call stack",
              "Tabulation Example": "O(n), for storing the tabulation table without additional space for recursion"
            }
          }
        }
      }
                   
    ]
  },
  {
    "category":"Hard",
    "Problems":[  
      {
        "Topic": "Hash Table",
        "Info": {
          "Definition": "A hash table, also known as a hash map, is a data structure that implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index into an array of buckets or slots, from which the desired value can be found.",
          "Algorithms": {
            "Code": "class HashTable {\nprivate:\n  int BUCKET;\n  list<int> *table;\npublic:\n  HashTable(int V);\n  void insertItem(int key, int value);\n  void deleteItem(int key);\n  int hashFunction(int x) {\n    return (x % BUCKET);\n  }\n};\n\nHashTable::HashTable(int b) {\n  this->BUCKET = b;\n  table = new list<int>[BUCKET];\n}\n\nvoid HashTable::insertItem(int key, int value) {\n  int index = hashFunction(key);\n  table[index].push_back(value);\n}\n\nvoid HashTable::deleteItem(int key) {\n  int index = hashFunction(key);\n  list<int>::iterator i;\n  for (i = table[index].begin(); i != table[index].end(); i++) {\n    if (*i == key)\n      break;\n  }\n  if (i != table[index].end())\n    table[index].erase(i);\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Average case (insert/search/delete)": "O(1)",
              "Worst case (insert/search/delete)": "O(n) - Occurs when all keys are mapped to a single bucket"
            },
            "Space Complexity": "O(n) - Where n is the number of keys stored in the hash table."
          }
        }
      },
      {
        "Topic": "Hashing Techniques",
        "Info": {
          "Definition": "Hashing techniques are methods used to store and retrieve data efficiently by converting the key into a unique hash index where the value is stored. This process allows for fast data access. Common hashing techniques include Chaining and Open Addressing, which address collisions - when two keys hash to the same index - in different ways.",
          "Algorithms": {
            "Chaining": "Chaining involves using an array of linked lists. The hash function assigns an index to each key, and the key-value pair is then added to the linked list at that index. This allows multiple values to exist at the same index, effectively handling collisions.",
            "Open Addressing": "Open Addressing resolves collisions by finding another empty slot or bucket within the array for the key-value pair. Common methods include Linear Probing, where the next empty slot is found in a linear sequence; Quadratic Probing, which searches for an empty slot based on a quadratic formula; and Double Hashing, which uses a second hash function to find an empty slot.",
            "Linear Probing": "void insert(key, value) { int index = hashFunction(key); while(array[index] is not empty) { index = (index + 1) % array_size; } array[index] = value; }",
            "Quadratic Probing": "void insert(key, value) { int index = hashFunction(key); int i = 0; while(array[(index + i*i) % array_size] is not empty) { i++; } array[(index + i*i) % array_size] = value; }",
            "Double Hashing": "void insert(key, value) { int index1 = hashFunction1(key); int index2 = hashFunction2(key); int i = 0; while(array[(index1 + i*index2) % array_size] is not empty) { i++; } array[(index1 + i*index2) % array_size] = value; }"
          },
          "Complexities": {
            "Time Complexities": {
              "Chaining": "Average: O(1), Worst: O(n), where n is the number of keys",
              "Open Addressing": "Average: O(1), Worst: O(n), although performance degrades with increased loading factor",
              "Linear Probing": "Average: O(1), Worst: O(n)",
              "Quadratic Probing": "Average: O(1), Worst: O(n)",
              "Double Hashing": "Average: O(1), Worst: O(n)"
            },
            "Space Complexity": {
              "Chaining": "O(n), where n is the number of keys, potentially more due to linked list overhead",
              "Open Addressing": "O(n), where n is the size of the array. Typically requires a larger array size than chaining to maintain performance",
              "Linear Probing": "O(n), where n is the size of the array",
              "Quadratic Probing": "O(n), where n is the size of the array",
              "Double Hashing": "O(n), where n is the size of the array"
            }
          }
        }
      },
      {
        "Topic": "Trie Data Structure",
        "Info": {
          "Definition": "A trie, also known as a prefix tree or digital tree, is a type of search tree used to store a dynamic set or associative array where the keys are usually strings. Unlike a binary search tree, no node in the trie stores the key associated with that node; instead, its position in the tree defines the key with which it is associated. All the descendants of a node have a common prefix of the string associated with that node, and the root is associated with the empty string.",
          "Algorithms": {
            "Insertion": "void insert(string key) {\n  TrieNode* node = root;\n  for (char ch : key) {\n    if (!node->children[ch - 'a'])\n      node->children[ch - 'a'] = new TrieNode();\n    node = node->children[ch - 'a'];\n  }\n  node->isEndOfWord = true;\n}",
            "Search": "bool search(string key) {\n  TrieNode* node = root;\n  for (char ch : key) {\n    if (!node->children[ch - 'a'])\n      return false;\n    node = node->children[ch - 'a'];\n  }\n  return node != nullptr && node->isEndOfWord;\n}",
            "StartsWith": "bool startsWith(string prefix) {\n  TrieNode* node = root;\n  for (char ch : prefix) {\n    if (!node->children[ch - 'a'])\n      return false;\n    node = node->children[ch - 'a'];\n  }\n  return true;\n}",
            "Deletion": "bool deleteWord(TrieNode* node, string key, int depth = 0) {\n  if (node) {\n    if (depth == key.size()) {\n      if (node->isEndOfWord) {\n        node->isEndOfWord = false;\n        return isEmpty(node);\n      }\n    } else {\n      int index = key[depth] - 'a';\n      if (deleteWord(node->children[index], key, depth + 1) && !node->isEndOfWord) {\n        delete node->children[index];\n        node->children[index] = nullptr;\n        return isEmpty(node);\n      }\n    }\n  }\n  return false;\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Insertion": "O(m), where m is the key length",
              "Search": "O(m), where m is the key length",
              "StartsWith": "O(m), where m is the prefix length",
              "Deletion": "O(m), where m is the key length"
            },
            "Space Complexity": {
              "Insertion": "O(m), for inserting a key of length m",
              "Search": "O(1), does not require additional space",
              "StartsWith": "O(1), does not require additional space",
              "Deletion": "O(m), in the worst case, for deleting a key of length m"
            }
          }
        }
      },                 
      {
        "Topic": "0/1 Knapsack Problem",
        "Info": {
          "Definition": "The 0/1 Knapsack Problem is a problem in combinatorial optimization where one has to maximize the total value of items in a knapsack without exceeding its capacity. Each item can either be included or excluded, hence the name 0/1.",
          "Algorithms": {
            "Code": "int knapSack(int W, int wt[], int val[], int n) {\n   vector<vector<int>> dp(n+1, vector<int>(W+1, 0));\n   for(int i = 1; i <= n; i++) {\n       for(int w = 1; w <= W; w++) {\n           if(wt[i-1] <= w)\n               dp[i][w] = max(val[i-1] + dp[i-1][w-wt[i-1]], dp[i-1][w]);\n           else\n               dp[i][w] = dp[i-1][w];\n       }\n   }\n   return dp[n][W];\n}"
          },
          "Complexities": {
            "Time Complexity": "O(nW) - Where n is the number of items and W is the capacity of the knapsack.",
            "Space Complexity": "O(nW) - For the DP table storing solutions for subproblems."
          }
        }
      },
      {
        "Topic": "Longest Common Subsequence",
        "Info": {
          "Definition": "The Longest Common Subsequence (LCS) problem involves finding the longest subsequence present in two sequences (not necessarily contiguous) such that the subsequence is common to both.",
          "Algorithms": {
            "Code": "int lcs(string &X, string &Y) {\n   int m = X.length(), n = Y.length();\n   vector<vector<int>> dp(m+1, vector<int>(n+1));\n   for(int i=1; i<=m; i++) {\n       for(int j=1; j<=n; j++) {\n           if(X[i-1] == Y[j-1])\n               dp[i][j] = dp[i-1][j-1] + 1;\n           else\n               dp[i][j] = max(dp[i-1][j], dp[i][j-1]);\n       }\n   }\n   return dp[m][n];\n}"
          },
          "Complexities": {
            "Time Complexity": "O(mn) - Where m and n are the lengths of the two sequences.",
            "Space Complexity": "O(mn) - For the DP table."
          }
        }
      },
      {
        "Topic": "Matrix Chain Multiplication",
        "Info": {
          "Definition": "Matrix Chain Multiplication is a dynamic programming problem that aims to determine the most efficient way to multiply a given sequence of matrices together. The goal is to find the optimal parenthesization of the matrices such that the number of scalar multiplications is minimized. The problem does not involve actually multiplying the matrices, but rather determining the order in which to perform the multiplications.",
          "Algorithms": {
            "Recursive Solution": "int MatrixChainOrder(int p[], int i, int j) {\n  if(i == j)\n    return 0;\n  int min = INT_MAX;\n  for (int k = i; k < j; k++) {\n    int count = MatrixChainOrder(p, i, k) +\n                MatrixChainOrder(p, k+1, j) +\n                p[i-1]*p[k]*p[j];\n    if (count < min)\n      min = count;\n  }\n  return min;\n}",
            "Dynamic Programming Solution": "int MatrixChainOrder(int p[], int n) {\n  int m[n][n];\n  for (int i=1; i<n; i++)\n    m[i][i] = 0;\n  for (int L=2; L<n; L++) {\n    for (int i=1; i<n-L+1; i++) {\n      int j = i+L-1;\n      m[i][j] = INT_MAX;\n      for (int k=i; k<=j-1; k++) {\n        int q = m[i][k] + m[k+1][j] + p[i-1]*p[k]*p[j];\n        if (q < m[i][j])\n          m[i][j] = q;\n      }\n    }\n  }\n  return m[1][n-1];\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Recursive Solution": "O(2^n), where n is the number of matrices. This approach has exponential time complexity due to the recomputation of subproblems.",
              "Dynamic Programming Solution": "O(n^3), where n is the number of matrices. This approach optimizes the recursive solution by solving each subproblem only once."
            },
            "Space Complexity": {
              "Recursive Solution": "O(n), for the recursion call stack, where n is the depth of the recursion tree.",
              "Dynamic Programming Solution": "O(n^2), for storing the results of subproblems in a 2D array."
            }
          }
        }
      },      
      {
        "Topic": "Floyd-Warshall Algorithm",
        "Info": {
          "Definition": "The Floyd-Warshall Algorithm is a dynamic programming solution for finding the shortest paths between all pairs of vertices in a weighted graph. It can handle negative weight edges but not negative weight cycles.",
          "Algorithms": {
            "Code": "void floydWarshall(int graph[][V]) {\n    int dist[V][V], i, j, k;\n    for (i = 0; i < V; i++)\n        for (j = 0; j < V; j++)\n            dist[i][j] = graph[i][j];\n    for (k = 0; k < V; k++) {\n        for (i = 0; i < V; i++) {\n            for (j = 0; j < V; j++) {\n                if (dist[i][k] + dist[k][j] < dist[i][j])\n                    dist[i][j] = dist[i][k] + dist[k][j];\n            }\n        }\n    }\n}" 
          },
          "Complexities": {
            "Time Complexity": "O(V^3) - The algorithm runs three nested loops over the graph's vertices, where V is the number of vertices in the graph.",
            "Space Complexity": "O(V^2) - Space needed to store the distance matrix."
          }
        }
      },
      {
        "Topic": "Transitive Closure",
        "Info": {
          "Definition": "The transitive closure of a graph is a measure of which vertices are reachable from other vertices through a path in the graph. In more formal terms, if there exists a path from vertex u to vertex v, then v is considered reachable from u. The transitive closure of a graph can be represented as a matrix, where the element at the ith row and jth column is 1 if there is a path from vertex i to vertex j, and 0 otherwise. The Floyd-Warshall algorithm is a common method used to compute the transitive closure of a graph.",
          "Algorithms": {
            "Floyd-Warshall Algorithm for Transitive Closure": "void transitiveClosure(vector<vector<int>>& graph) {\n  int V = graph.size();\n  vector<vector<int>> tc(V, vector<int>(V));\n  for (int i = 0; i < V; i++)\n    for (int j = 0; j < V; j++)\n      tc[i][j] = graph[i][j];\n  for (int k = 0; k < V; k++) {\n    for (int i = 0; i < V; i++) {\n      for (int j = 0; j < V; j++) {\n        if (tc[i][k] + tc[k][j] < tc[i][j])\n          tc[i][j] = tc[i][k] + tc[k][j];\n      }\n    }\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Floyd-Warshall Algorithm": "O(V^3), where V is the number of vertices in the graph."
            },
            "Space Complexity": {
              "Floyd-Warshall Algorithm": "O(V^2), for storing the transitive closure matrix."
            }
          }
        }
      },      
      {
        "Topic": "Huffman Coding",
        "Info": {
          "Definition": "Huffman Coding is a widely used method of lossless data compression, which assigns variable-length codes to input characters, with shorter codes for more frequent characters. This algorithm uses a greedy technique to build a prefix-free binary tree called Huffman Tree.",
          "Algorithms": {
            "Code": "void buildHuffmanTree(vector<char>& data, vector<int>& freq, int size) {\n    priority_queue<HuffmanNode*, vector<HuffmanNode*>, compare> minHeap;\n    for (int i = 0; i < size; ++i)\n        minHeap.push(new HuffmanNode(data[i], freq[i]));\n    while (minHeap.size() != 1) {\n        HuffmanNode* left = minHeap.top(); minHeap.pop();\n        HuffmanNode* right = minHeap.top(); minHeap.pop();\n        HuffmanNode* top = new HuffmanNode('$', left->freq + right->freq);\n        top->left = left;\n        top->right = right;\n        minHeap.push(top);\n    }\n    printCodes(minHeap.top(), \"\");\n}"
          },
          "Complexities": {
            "Time Complexity": "O(n log n) - Where n is the number of unique characters. If there are N nodes, there will be N-1 merge operations and each operation involves a heap operation of O(log n).",
            "Space Complexity": "O(n) - To store the tree."
          }
        }
      },
      {
        "Topic": "Shell Sort",
        "Info": {
          "Definition": "Shell Sort is an in-place comparison sort which generalizes insertion sort to allow the exchange of items that are far apart. The idea is to arrange the list of elements so that, starting anywhere, taking every hth element produces a sorted list.",
          "Algorithms": {
            "Code": "void shellSort(int arr[], int n) {\n    for (int gap = n/2; gap > 0; gap /= 2) {\n        for (int i = gap; i < n; i += 1) {\n            int temp = arr[i];\n            int j;\n            for (j = i; j >= gap && arr[j - gap] > temp; j -= gap)\n                arr[j] = arr[j - gap];\n            arr[j] = temp;\n        }\n    }\n}"
          },
          "Complexities": {
            "Time Complexity": "Worst-case time complexity is O(n^2), but it can perform better on partially sorted arrays. The best case is O(n log n).",
            "Space Complexity": "O(1) - It is an in-place sorting algorithm."
          }
        }
      },
      {
        "Topic": "Graph Cycle Detection (in Directed and Undirected Graphs)",
        "Info": {
          "Definition": "Cycle detection in graphs is a fundamental algorithmic problem that involves finding whether a graph contains a cycle. A cycle occurs when a path exists in the graph that starts and ends at the same vertex. The approach to cycle detection varies between directed and undirected graphs due to the nature of the edges.",
          "Algorithms": {
            "DFS for Undirected Graphs": "bool isCyclicUtil(int v, bool visited[], int parent, vector<int> adj[]) {\n  visited[v] = true;\n  for (auto i = adj[v].begin(); i != adj[v].end(); ++i) {\n    if (!visited[*i]) {\n      if (isCyclicUtil(*i, visited, v, adj))\n        return true;\n    } else if (*i != parent)\n      return true;\n  }\n  return false;\n}",
            "DFS for Directed Graphs": "bool isCyclicUtil(int v, bool visited[], bool *recStack, vector<int> adj[]) {\n  if(visited[v] == false) {\n    visited[v] = true;\n    recStack[v] = true;\n    for(auto i = adj[v].begin(); i != adj[v].end(); ++i) {\n      if (!visited[*i] && isCyclicUtil(*i, visited, recStack, adj))\n        return true;\n      else if (recStack[*i])\n        return true;\n    }\n  }\n  recStack[v] = false;\n  return false;\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "DFS for Undirected Graphs": "O(V+E), where V is the number of vertices and E is the number of edges",
              "DFS for Directed Graphs": "O(V+E), similar to undirected graphs but takes into account the direction of edges"
            },
            "Space Complexity": {
              "DFS for Undirected Graphs": "O(V), for storing visited information and recursion stack",
              "DFS for Directed Graphs": "O(V), additionally requires space for the recursion stack and to maintain the recursive call stack for directed graphs"
            }
          }
        }
      },
      {
        "Topic": "Topological sorting in DAG",
        "Info": {
          "Definition": "Topological sorting of a Directed Acyclic Graph (DAG) is a linear ordering of vertices such that for every directed edge uv, vertex u comes before v in the ordering. Topological Sorting for a graph is not possible if the graph is not a DAG. This sorting is useful for scheduling tasks, resolving symbol dependencies in compilers, and more.",
          "Algorithms": {
            "Kahn's Algorithm": "vector<int> in_degree(V, 0);\nfor (int u = 0; u < V; u++) {\n  for (int v : adj[u])\n    in_degree[v]++;\n}\nqueue<int> q;\nfor (int i = 0; i < V; i++)\n  if (in_degree[i] == 0)\n    q.push(i);\nint cnt = 0;\nvector<int> top_order;\nwhile (!q.empty()) {\n  int u = q.front();\n  q.pop();\n  top_order.push_back(u);\n  for (int v : adj[u])\n    if (--in_degree[v] == 0)\n      q.push(v);\n  cnt++;\n}\nif (cnt != V) {\n  cout << \"There exists a cycle in the graph\\n\";\n  return;\n}",
            "DFS Based Algorithm": "void dfs(int v, vector<bool> &visited, stack<int> &Stack, vector<int> adj[]) {\n  visited[v] = true;\n  for (int i : adj[v])\n    if (!visited[i])\n      dfs(i, visited, Stack, adj);\n  Stack.push(v);\n}\nvoid topologicalSort(vector<int> adj[], int V) {\n  stack<int> Stack;\n  vector<bool> visited(V, false);\n  for (int i = 0; i < V; i++)\n    if (!visited[i])\n      dfs(i, visited, Stack, adj);\n  while (!Stack.empty()) {\n    cout << Stack.top() << \" \";\n    Stack.pop();\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Kahn's Algorithm": "O(V+E) - Where V is the number of vertices and E is the number of edges in the graph",
              "DFS Based Algorithm": "O(V+E) - Similar as above, considering the graph traversal for all vertices and their adjacent vertices"
            },
            "Space Complexity": "O(V) - Additional space for data structures like in-degree array, stack, or queue, depending on the algorithm"
          }
        }
      },            
      {
        "Topic": "Ford-Fulkerson Algorithm",
        "Info": {
          "Definition": "The Ford-Fulkerson algorithm computes the maximum flow in a flow network. It initializes the flow to 0 and repeatedly increases it by finding augmenting paths from the source to the sink. The process continues until no augmenting paths are left.",
          "Algorithms": {
            "Code": "int fordFulkerson(int graph[V][V], int s, int t) {\n    int u, v;\n    int rGraph[V][V];\n    for (u = 0; u < V; u++)\n        for (v = 0; v < V; v++)\n             rGraph[u][v] = graph[u][v];\n    int parent[V];\n    int max_flow = 0;\n    while (bfs(rGraph, s, t, parent)) {\n        int path_flow = INT_MAX;\n        for (v = t; v != s; v = parent[v]) {\n            u = parent[v];\n            path_flow = min(path_flow, rGraph[u][v]);\n        }\n        for (v = t; v != s; v = parent[v]) {\n            u = parent[v];\n            rGraph[u][v] -= path_flow;\n            rGraph[v][u] += path_flow;\n        }\n        max_flow += path_flow;\n    }\n    return max_flow;\n}"
          },
          "Complexities": {
            "Time Complexity": "O(max_flow * E), where E is the number of edges. The algorithm runs while there are augmenting paths, and each path can add at most 'max_flow' amount of flow.",
            "Space Complexity": "O(V^2), as it requires storing the residual graph."
          }
        }
      },
      {
        "Topic": "Rabin-Karp Algorithm",
        "Info": {
          "Definition": "The Rabin-Karp Algorithm is a string-searching algorithm that uses hashing to find any one of a set of pattern strings in a text. It is particularly useful for detecting multiple patterns in a text in a single pass. The algorithm matches the hash value of the pattern with the hash value of current substring of the text, and if the hash values match, it then checks for individual character matches.",
          "Algorithms": {
            "Code": "void rabinKarp(string const& s, string const& t) {\n    const int p = 31;\n    const int m = 1e9 + 9;\n    int S = s.size(), T = t.size();\n\n    vector<long long> p_pow(max(S, T));\n    p_pow[0] = 1;\n    for (int i = 1; i < (int)p_pow.size(); i++)\n        p_pow[i] = (p_pow[i-1] * p) % m;\n\n    vector<long long> h(T + 1, 0);\n    for (int i = 0; i < T; i++)\n        h[i+1] = (h[i] + (t[i] - 'a' + 1) * p_pow[i]) % m;\n\n    long long h_s = 0;\n    for (int i = 0; i < S; i++)\n        h_s = (h_s + (s[i] - 'a' + 1) * p_pow[i]) % m;\n\n    for (int i = 0; i + S - 1 < T; i++) { \n        long long cur_h = (h[i+S] + m - h[i]) % m; \n        if (cur_h == h_s * p_pow[i] % m)\n            cout << \"Pattern found at index: \" << i << endl;\n    }\n}"
          },
          "Complexities": {
            "Time Complexity": "Average and best case is O(n+m), where n is the length of text and m is the length of the pattern, but its worst case is O(nm), which occurs when all characters of the pattern and text are same as the hash value of all the substrings of the text will be same.",
            "Space Complexity": "O(n), where n is the length of the text, to store the hash values of all possible substrings of the text."
          }
        }
      },
      {
        "Topic": "Fibonacci Heap",
        "Info": {
          "Definition": "A Fibonacci Heap is a data structure for priority queue operations, consisting of a collection of heap-ordered trees. It has a better amortized running time than many other priority queue data structures including the binary heap and binomial heap.",
          "Algorithms": {
            "Code": "struct Node {\n    int key;\n    Node *prev, *next;\n    Node *child, *parent;\n    int degree;\n    bool marked;\n};\n\n// Initial creation of a Fibonacci heap\nNode* createHeap() {\n    Node* np = nullptr;\n    return np;\n}\n\n// Insertion operation in a Fibonacci heap\nvoid insert(Node* &heap, Node* node) {\n    // Implementation details\n}\n\n// Decrease key operation in a Fibonacci heap\nvoid decreaseKey(Node* &heap, Node* node, int new_val) {\n    // Implementation details\n}\n\n// Delete node operation from a Fibonacci heap\nvoid deleteNode(Node* &heap, Node* node) {\n    // Implementation details\n}"
          },
          "Complexities": {
            "Time Complexity": {
              "Insert": "O(1)",
              "Decrease Key": "O(1) amortized",
              "Delete Node": "O(log n) amortized"
            },
            "Space Complexity": "O(n), where n is the number of elements in the heap."
          }
        }
      },
      {
        "Topic": "Decrease Key and Delete Node from Fibonacci Heap",
        "Info": {
          "Definition": "In a Fibonacci Heap, the decrease key operation decreases the value of a given node, potentially breaking the heap property and requiring a cut and cascading cut operations. The delete node operation involves decreasing the value of the node to negative infinity (or a value lower than any heap element), thus moving it to the root list, and then performing a delete minimum operation.",
          "Algorithms": {
            "DecreaseKey Code": "void decreaseKey(Node* &heap, Node* node, int new_val) {\n    if (heap == nullptr || node == nullptr) return;\n    if (node->key < new_val) {\n        cout << \"New key is greater than current key\";\n        return;\n    }\n    node->key = new_val;\n    Node* parent = node->parent;\n    if (parent != nullptr && node->key < parent->key) {\n        cut(heap, node, parent);\n        cascadingCut(heap, parent);\n    }\n    if (node->key < heap->key) {\n        heap = node;\n    }\n}",
            "DeleteNode Code": "void deleteNode(Node* &heap, Node* node) {\n    decreaseKey(heap, node, INT_MIN);\n    Node* min = removeMin(heap);\n    // Assuming removeMin removes and returns the minimum element from the heap\n}"
          },
          "Complexities": {
            "Time Complexity": "Decrease Key: O(1) amortized, Delete Node: O(log n) amortized",
            "Space Complexity": "O(1), assuming no additional space is required apart from the input."
          }
        }
      },
      {
        "Topic": "Bellman-Ford Algorithm",
        "Info": {
          "Definition": "The Bellman-Ford algorithm computes shortest paths from a single source vertex to all of the other vertices in a weighted graph. It is capable of handling graphs in which some of the edge weights are negative.",
          "Algorithms": {
            "Code": "int V, E; // V is the number of vertices and E is the number of edges\nstruct Edge { int u, v, w; };\nvector<Edge> edges;\n// Initialization\nvector<int> dist(V, INT_MAX);\ndist[src] = 0;\n// Relaxation\nfor(int i = 0; i < V-1; i++)\n  for(auto &edge : edges)\n    if(dist[edge.u] + edge.w < dist[edge.v])\n      dist[edge.v] = dist[edge.u] + edge.w;\n// Check for negative-weight cycles\nfor(auto &edge : edges)\n  if(dist[edge.u] + edge.w < dist[edge.v])\n    throw \"Graph contains a negative-weight cycle\";"
          },
          "Complexities": {
            "Time Complexity": "O(VE) - As it relaxes all edges V-1 times.",
            "Space Complexity": "O(V) - For storing distance and predecessor arrays."
          }
        }
      },
      {
        "Topic": "Strongly Connected Components (SCC)",
        "Info": {
          "Definition": "In a directed graph, a strongly connected component is a maximal set of vertices such that each pair of vertices is reachable from the other, i.e., each vertex in the set is reachable from every other vertex in the set.",
          "Algorithms": {
            "Code": "class Graph {\npublic:\n    int V; // Vertices\n    list<int> *adj; // Adjacency list\n    Graph(int V) { this->V = V; adj = new list<int>[V]; }\n    void addEdge(int v, int w) { adj[v].push_back(w); }\n    void fillOrder(int v, bool visited[], stack<int> &Stack);\n    void DFSUtil(int v, bool visited[]);\n    void printSCCs();\n    Graph getTranspose();\n};\n\nvoid Graph::DFSUtil(int v, bool visited[]) {\n    visited[v] = true;\n    list<int>::iterator i;\n    for(i = adj[v].begin(); i != adj[v].end(); ++i)\n        if(!visited[*i])\n            DFSUtil(*i, visited);\n}\n\nGraph Graph::getTranspose() {\n    Graph g(V);\n    for(int v = 0; v < V; v++)\n        for(list<int>::iterator i = adj[v].begin(); i != adj[v].end(); ++i)\n            g.adj[*i].push_back(v);\n    return g;\n}\n\n// Methods fillOrder and printSCCs to be implemented as per Kosaraju's algorithm steps."
          },
          "Complexities": {
            "Time Complexity": "O(V+E) for both Tarjan's and Kosaraju's algorithms. This is because each edge and vertex in the graph is visited once during the depth-first search process.",
            "Space Complexity": "O(V) for Tarjan's algorithm due to the stack and O(V+E) for Kosaraju's due to the need to store the transpose graph. Additionally, both algorithms require O(V) space for the visited array."
          }
        }
      }  
    ]
  } 
]