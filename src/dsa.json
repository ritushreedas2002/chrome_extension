[
  {
    "category": "Easy",
    "Problems": [
      {
        "Topic": "Array Concept",
        "Info": {
          "Definition": "An array is a data structure that contains a group of elements. Typically these elements are all of the same data type, such as an integer or string. Arrays are commonly used to organize data so that a related set of values can be easily sorted or searched.",
          "Algorithms": {
            "Traversal": "for(int i = 0; i < arr.length; i++) {\n  System.out.println(arr[i]);\n}",
            "Insertion": "for(int i = arr.length-1; i > position; i--) {\n  arr[i] = arr[i-1];\n}\narr[position] = newValue;",
            "Deletion": "for(int i = position; i < arr.length-1; i++) {\n  arr[i] = arr[i+1];\n}",
            "Search": "for(int i = 0; i < arr.length; i++) {\n  if(arr[i] == searchValue) {\n    return i;\n  }\n}\nreturn -1;",
            "Update": "arr[position] = newValue;"
          },
          "Complexities": {
            "Time Complexities": {
              "Traversal": "O(n)",
              "Insertion": "O(n)",
              "Deletion": "O(n)",
              "Search": "O(n)",
              "Update": "O(1)"
            },
            "Space Complexity": "O(1)"
          }
        }
      },
      {
        "Topic": "Linear Search",
        "Info": {
          "Definition": "Linear Search is a searching algorithm that finds the position of a target value within an array. It sequentially checks each element of the array for the target value until a match is found or until all the elements have been searched.",
          "Algorithms": {
            "Basic Method": "for i = 0 to arr.length\nif arr[i] == x\n    return i\nreturn -1"
          },
          "Complexities": {
            "Time Complexities": {
              "Best case": "O(1)",
              "Average case": "O(n)",
              "Worst case": "O(n)"
            },
            "Space Complexity": "The space complexity of the linear search is O(1)."
          }
        }
      },
      {
        "Topic": "Binary Search",
        "Info": {
          "Definition": "Binary Search is a searching algorithm for finding an element's position in a sorted array. In this approach, the element is always searched in the middle of a portion of an array. Binary search can be implemented only on a sorted list of items. If the elements are not sorted already, we need to sort them first.",
          "Algorithms": {
            "Iterative Method": "do until the pointers low and high meet each other.\nmid = (low + high)/2\nif (x == arr[mid])\n    return mid\nelse if (x > arr[mid]) // x is on the right side\n    low = mid + 1\nelse                       // x is on the left side\n    high = mid - 1",
            "Recursive Method": "binarySearch(arr, x, low, high)\nif low > high\n    return False \nelse\n    mid = (low + high) / 2 \n    if x == arr[mid]\n        return mid\n    else if x > arr[mid]        // x is on the right side\n        return binarySearch(arr, x, mid + 1, high)\n    else                               // x is on the left side\n        return binarySearch(arr, x, low, mid - 1)"
          },
          "Complexities": {
            "Time Complexities": {
              "Best case": "O(1)",
              "Average case": "O(log n)",
              "Worst case": "O(log n)"
            },
            "Space Complexity": "The space complexity of the binary search is O(1)."
          }
        }
      },
      {
        "Topic": "Stack Data Structure",
        "Info": {
          "Definition": "A stack is a linear data structure that follows the principle of Last In First Out (LIFO). This means the last element inserted inside the stack is removed first.You can think of the stack data structure as the pile of plates on top of another.LIFO Principle of Stack :In programming terms, putting an item on top of the stack is called push and removing an item is called pop.",
          "Algorithms": {
            "Push Operation": "void push(st *s, int newitem) {\n  if (isfull(s)) {\n    cout << \"STACK FULL\";\n  } else {\n    s->top++;\n    s->items[s->top] = newitem;\n  }\n  size++;\n}",
            "Pop Operation": "int pop(st *s) {\n  if (isEmpty(s)) {\n    cout << \"STACK EMPTY\";\n    return -1;\n  } else {\n    return s->items[s->top--];\n  }\n}",
            "isEmpty Operation": "bool isEmpty(st *s) {\n  return s->top == -1;\n}",
            "isFull Operation": "bool isFull(st *s) {\n  return s->top == s->capacity - 1;\n}",
            "Peek Opeartion": "int peek(st *s) {\n  if (isEmpty(s)) {\n    cout << \"STACK EMPTY\";\n    return -1;\n  } else {\n    return s->items[s->top];\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Push": "O(1)",
              "isEmpty": "O(1)",
              "isFull": "O(1)",
              "Pop": "O(1)",
              "Peek": "O(1)"
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Queue Data Structure",
        "Info": {
          "Definition": "A queue is a useful data structure in programming. It is similar to the ticket queue outside a cinema hall, where the first person entering the queue is the first person who gets the ticket.Queue follows the First In First Out (FIFO) rule - the item that goes in first is the item that comes out first.",
          "Algorithms": {
            "Enqueue Operation": "void enqueue(int item) {\n  if (isFull()) {\n    cout << \"Queue is full\";\n  } else {\n    rear = (rear + 1) % capacity;\n    arr[rear] = item;\n    count++;\n  }\n}",
            "Dequeue Operation": "int dequeue() {\n  if (isEmpty()) {\n    cout << \"Queue is empty\";\n    return INT_MIN;\n  } else {\n    int item = arr[front];\n    front = (front + 1) % capacity;\n    count--;\n    return item;\n  }\n}",
            "isEmpty Operation": "bool isEmpty() {\n  return (count == 0);\n}",
            "isFull Operation": "bool isFull() {\n  return (count == capacity);\n}",
            "Peek Opeartion": "int peek() {\n  if (isEmpty()) {\n    cout << \"Queue is empty\";\n    return INT_MIN;\n  } else {\n    return arr[front];\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Enqueue": "O(1)",
              "Dequeue": "O(1)",
              "isEmpty": "O(1)",
              "isFull": "O(1)",
              "Peek": "O(1)"
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Circular Queue",
        "Info": {
          "Definition": "A circular queue is the extended version of a regular queue where the last element is connected to the first element. Thus forming a circle-like structure.The circular queue solves the major limitation of the normal queue. In a normal queue, after a bit of insertion and deletion, there will be non-usable empty space.",
          "Algorithms": {
            "Enqueue Operation": "void enqueue(int item) {\n  if (isFull()) {\n    cout << \"Queue is full\";\n  } else {\n    rear = (rear + 1) % capacity;\n    arr[rear] = item;\n    count++;\n  }\n}",
            "Dequeue Operation": "int dequeue() {\n  if (isEmpty()) {\n    cout << \"Queue is empty\";\n    return INT_MIN;\n  } else {\n    int item = arr[front];\n    front = (front + 1) % capacity;\n    count--;\n    return item;\n  }\n}",
            "isEmpty Operation": "bool isEmpty() {\n  return (count == 0);\n}",
            "isFull Operation": "bool isFull() {\n  return (count == capacity);\n}",
            "Peek Opeartion": "int peek() {\n  if (isEmpty()) {\n    cout << \"Queue is empty\";\n    return INT_MIN;\n  }\n  return arr[front];\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Enqueue": "O(1)",
              "Dequeue": "O(1)",
              "isEmpty": "O(1)",
              "isFull": "O(1)",
              "Peek": "O(1)"
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Bubble Sort",
        "Info": {
          "Definition": "Bubble Sort is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order. The pass through the list is repeated until the list is sorted.",
          "Algorithms": {
            "Code": "Bubble Sort is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order. The pass through the list is repeated until the list is sorted.\n\nvoid bubbleSort(int arr[], int n) {\n  for (int i = 0; i < n-1; i++)\n    for (int j = 0; j < n-i-1; j++)\n      if (arr[j] > arr[j+1])\n        swap(arr[j], arr[j+1]);\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Worst and Average Case": "O(n^2)",
              "Best Case": "O(n) when the array is already sorted"
            },
            "Space Complexity": "O(1) - Only requires a constant amount of additional space."
          }
        }
      },
      {
        "Topic": "Insertion Sort",
        "Info": {
          "Definition": "Insertion Sort is a simple sorting algorithm that builds the final sorted array one item at a time. It is much less efficient on large lists than more advanced algorithms such as quicksort, heapsort, or merge sort.",
          "Algorithms": {
            "Code": "Insertion Sort is a simple sorting algorithm that builds the final sorted array one item at a time. It is much less efficient on large lists than more advanced algorithms such as quicksort, heapsort, or merge sort.\n\nvoid insertionSort(int arr[], int n) {\n  int i, key, j;\n  for (i = 1; i < n; i++) {\n    key = arr[i];\n    j = i - 1;\n    while (j >= 0 && arr[j] > key) {\n      arr[j + 1] = arr[j];\n      j = j - 1;\n    }\n    arr[j + 1] = key;\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Worst and Average Case": "O(n^2)",
              "Best Case": "O(n) when the array is already sorted"
            },
            "Space Complexity": "O(1) - It is an in-place sorting algorithm."
          }
        }
      },
      {
        "Topic": "Selection Sort",
        "Info": {
          "Definition": "Selection Sort is an in-place comparison sorting algorithm. It divides the input list into two parts: a sorted sublist of items which is built up from left to right at the front of the list, and a sublist of the remaining unsorted items that occupy the rest of the list. Initially, the sorted sublist is empty and the unsorted sublist is the entire input list. The algorithm proceeds by finding the smallest (or largest, depending on sorting order) element in the unsorted sublist, swapping it with the leftmost unsorted element, and moving the sublist boundaries one element to the right.",
          "Algorithms": {
            "Code": "Selection Sort is an in-place comparison sorting algorithm. It divides the input list into two parts: a sorted sublist of items which is built up from left to right at the front of the list, and a sublist of the remaining unsorted items that occupy the rest of the list. Initially, the sorted sublist is empty and the unsorted sublist is the entire input list. The algorithm proceeds by finding the smallest (or largest, depending on sorting order) element in the unsorted sublist, swapping it with the leftmost unsorted element, and moving the sublist boundaries one element to the right.\n\nvoid selectionSort(int arr[], int n) {\n  int i, j, min_idx;\n  for (i = 0; i < n-1; i++) {\n    min_idx = i;\n    for (j = i+1; j < n; j++)\n      if (arr[j] < arr[min_idx])\n        min_idx = j;\n    swap(arr[min_idx], arr[i]);\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": "Worst, Average, and Best Case: O(n^2), as it always runs O(n^2) operations regardless of the input.",
            "Space Complexity": "O(1) - Like bubble sort and insertion sort, selection sort also uses a constant amount of additional space."
          }
        }
      },
      {
        "Topic": "Fibonacci Sequence",
        "Info": {
          "Definition": "The Fibonacci sequence is a series of numbers where each number is the sum of the two preceding ones, usually starting with 0 and 1. It's a classic example demonstrating the power of Dynamic Programming in reducing the computational complexity of recursive algorithms.",
          "Algorithms": {
            "Code": "int fib(int n) {\n    if(n <= 1) return n;\n    vector<int> f(n+1, 0);\n    f[1] = 1;\n    for(int i = 2; i <= n; i++)\n        f[i] = f[i-1] + f[i-2];\n    return f[n];\n}"
          },
          "Complexities": {
            "Time Complexity": "O(n) - Linear, as it iterates once up to n.",
            "Space Complexity": "O(n) - For storing the Fibonacci sequence up to n."
          }
        }
      },
      {
        "Topic": "Singly Linked List",
        "Info": {
          "Definition": "A singly linked list is a type of linked list in which each node points to the next node in the list and the last node points to null. It allows for efficient insertion and removal of elements from any position in the sequence.",
          "Algorithm": {
            "Insertion at End": "Adds a new node with the specified data at the end of the list.\n\nvoid insertAtEnd(Node** head, int newData) {\n  Node* newNode = new Node();\n  Node* last = *head;\n  newNode->data = newData;\n  newNode->next = NULL;\n  if (*head == NULL) {\n    *head = newNode;\n    return;\n  }\n  while (last->next != NULL) {\n    last = last->next;\n  }\n  last->next = newNode;\n}"
          },
          "Complexities": {
            "Time Complexity": "Insertion at end: O(n), Search: O(n), Deletion: O(n)",
            "Space Complexity": "O(n) - Storing n elements."
          }
        }
      },
      {
        "Topic": "Doubly Linked List",
        "Info": {
          "Definition": "A double linked list is a type of linked list in which each node contains two links: one pointing to the next node and one to the previous node. This allows for efficient insertion and removal from both ends of the list.",
          "Algorithm": {
            "Insertion at End": "Adds a new node with the specified data at the end of the list.\n\nvoid insertAtEnd(DoubleNode** head, int newData) {\n  DoubleNode* newNode = new DoubleNode();\n  DoubleNode* last = *head;\n  newNode->data = newData;\n  newNode->next = NULL;\n  if (*head == NULL) {\n    newNode->prev = NULL;\n    *head = newNode;\n    return;\n  }\n  while (last->next != NULL) {\n    last = last->next;\n  }\n  last->next = newNode;\n  newNode->prev = last;\n}"
          },
          "Complexities": {
            "Time Complexity": "Insertion at end: O(n), Search: O(n), Deletion: O(n)",
            "Space Complexity": "O(n) - Storing n elements, but requires additional space for the previous link in each node."
          }
        }
      },
      {
        "Topic": "Circular Linked List",
        "Info": {
          "Definition": "A circular linked list is a type of linked list where all nodes are connected to form a circle. There is no NULL at the end. It can be implemented as a singly circular linked list or doubly circular linked list.",
          "Algorithm": {
            "Insertion at End": "Adds a new node with the specified data at the end of the list, forming a circle.\n\nvoid insertAtEnd(CircularNode** head, int newData) {\n  CircularNode* newNode = new CircularNode();\n  CircularNode* last = *head;\n  newNode->data = newData;\n  if (*head == NULL) {\n    newNode->next = newNode;\n    *head = newNode;\n    return;\n  }\n  while (last->next != *head) {\n    last = last->next;\n  }\n  last->next = newNode;\n  newNode->next = *head;\n}"
          },
          "Complexities": {
            "Time Complexity": "Insertion at end: O(n), Search: O(n), Deletion: O(n)",
            "Space Complexity": "O(n) - Storing n elements. Similar to singly or doubly linked lists but forms a circle."
          }
        }
      },
      {
        "Topic": "Breadth-First Search (BFS) Algorithm",
        "Info": {
          "Definition": "Breadth-First Search (BFS) is an algorithm for traversing or searching tree or graph data structures. It starts at a selected node and explores all of the neighbor nodes at the present depth prior to moving on to the nodes at the next depth level.",
          "Algorithms": {
            "Code": "void bfs(int s, vector<int>& adj, vector<bool>& visited) {\n  queue<int> queue;\n  visited[s] = true;\n  queue.push(s);\n  while(!queue.empty()) {\n    int s = queue.front(); queue.pop();\n    cout << s << ' ';\n    for(auto u : adj[s]) {\n      if(!visited[u]) {\n        visited[u] = true;\n        queue.push(u);\n      }\n    }\n  }\n}"
          },
          "Complexities": {
            "Time Complexity": "O(V+E) - Where V is the number of vertices and E is the number of edges.",
            "Space Complexity": "O(V) - Due to the storage of vertices in the queue."
          }
        }
      },
      {
        "Topic": "Depth-First Search (DFS) Algorithm",
        "Info": {
          "Definition": "Depth-First Search (DFS) is an algorithm for traversing or searching tree or graph data structures. The algorithm starts at the root node and explores as far as possible along each branch before backtracking.",
          "Algorithms": {
            "Code": "void dfs(int v, vector<int>& adj, vector<bool>& visited) {\n  visited[v] = true;\n  cout << v << ' ';\n  for(int u : adj[v]) {\n    if(!visited[u]) {\n      dfs(u, adj, visited);\n    }\n  }\n}"
          },
          "Complexities": {
            "Time Complexity": "O(V+E) - Where V is the number of vertices and E is the number of edges.",
            "Space Complexity": "O(V) - Due to the usage of the call stack in recursion."
          }
        }
      }
    ]
  },
  {
    "category": "Medium",
    "Problems": [
      {
        "Topic": "Adjacency Matrix Representation",
        "Info": {
          "Definition": "An adjacency matrix is a square matrix used to represent a finite graph. The elements of the matrix indicate whether pairs of vertices are adjacent or not in the graph.",
          "Algorithms": {
            "Code": "int graph[V][V]; // V is the number of vertices\n// Initialize your matrix to 0\nfor(int i = 0; i < V; i++)\n  for(int j = 0; j < V; j++)\n    graph[i][j] = 0;\n// For every edge (u, v), set the value to 1 or the weight of the edge\ngraph[u][v] = 1; // For unweighted graph\ngraph[u][v] = w; // For weighted graph, where w is the weight"
          },
          "Complexities": {
            "Time Complexity": "O(1) for adding or checking the existence of an edge. O(V^2) for initializing the graph.",
            "Space Complexity": "O(V^2) - As it needs to store information for every possible edge."
          }
        }
      },
      {
        "Topic": "Adjacency List Representation",
        "Info": {
          "Definition": "An adjacency list represents a graph as an array of linked lists. The index of the array represents a vertex and each element in its linked list represents the other vertices that form an edge with the vertex.",
          "Algorithms": {
            "Code": "vector<int> adj[V]; // V is the number of vertices\n// For every edge (u, v), add v to the adjacency list of u\nadj[u].push_back(v); // For directed graph\nadj[v].push_back(u); // For undirected graph, do this as well"
          },
          "Complexities": {
            "Time Complexity": "O(V+E) for initializing the graph. O(deg(v)) for querying all adjacent vertices of a vertex v.",
            "Space Complexity": "O(V+E) - As it needs to store information for every vertex and edge."
          }
        }
      },
      {
        "Topic": "Priority Queue",
        "Info": {
          "Definition": "A priority queue is a special type of queue in which each element is associated with a priority value. And, elements are served on the basis of their priority. That is, higher priority elements are served first.However, if elements with the same priority occur, they are served according to their order in the queue.",
          "Algorithms": {
            "Insert Operation": "void insert(int priority, int data) {\n  if (isFull()) {\n    cout << \"Priority Queue is full\";\n    return;\n  }\n  Node* newNode = new Node(priority, data);\n  if (isEmpty() || priority > front->priority) {\n    newNode->next = front;\n    front = newNode;\n  } else {\n    Node* temp = front;\n    while (temp->next != NULL && temp->next->priority >= priority) {\n      temp = temp->next;\n    }\n    newNode->next = temp->next;\n    temp->next = newNode;\n  }\n  size++;\n}",
            "Delete Operation": "void delete() {\n  if (isEmpty()) {\n    cout << \"Priority Queue is empty\";\n    return;\n  }\n  Node* temp = front;\n  front = front->next;\n  delete temp;\n  size--;\n}",
            "isEmpty Operation": "bool isEmpty() {\n  return (front == NULL);\n}",
            "isFull Operation": "bool isFull() {\n  // This implementation might vary based on underlying data structure. For a linked list, it might be system memory dependent.\n}",
            "Peek Opeartion": "int peek() {\n  if (isEmpty()) {\n    cout << \"Priority Queue is empty\";\n    return INT_MIN;\n  }\n  return front->data;\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Insert": "O(n) - In the worst case, we traverse the entire list.",
              "Delete": "O(1) - Deletion always occurs at the front.",
              "Peek": "O(1) - Peeking only looks at the front element.",
              "isEmpty": "O(1)",
              "isFull": "Varies - For linked list implementations, it might depend on available system memory."
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Deque Data Structure",
        "Info": {
          "Definition": "Deque or Double Ended Queue is a type of queue in which insertion and removal of elements can either be performed from the front or the rear. Thus, it does not follow FIFO rule (First In First Out).\nTypes of Deque:\nInput Restricted Deque:  In this deque, input is restricted at a single end but allows deletion at both the ends.\nOutput Restricted Deque:  In this deque, output is restricted at a single end but allows insertion at both the ends.",
          "Algorithms": {
            "Insert Operation": "void insert(int priority, int data) {\n  if (isFull()) {\n    cout << \"Priority Queue is full\";\n    return;\n  }\n  Node* newNode = new Node(priority, data);\n  if (isEmpty() || priority > front->priority) {\n    newNode->next = front;\n    front = newNode;\n  } else {\n    Node* temp = front;\n    while (temp->next != NULL && temp->next->priority >= priority) {\n      temp = temp->next;\n    }\n    newNode->next = temp->next;\n    temp->next = newNode;\n  }\n  size++;\n}",
            "Delete Operation": "void delete() {\n  if (isEmpty()) {\n    cout << \"Priority Queue is empty\";\n    return;\n  }\n  Node* temp = front;\n  front = front->next;\n  delete temp;\n  size--;\n}",
            "isEmpty Operation": "bool isEmpty() {\n  return (front == NULL);\n}",
            "isFull Operation": "bool isFull() {\n  // This implementation might vary based on underlying data structure. For a linked list, it might be system memory dependent.\n}",
            "Peek Opeartion": "int peek() {\n  if (isEmpty()) {\n    cout << \"Priority Queue is empty\";\n    return INT_MIN;\n  }\n  return front->data;\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Insert": "O(n) - In the worst case, we traverse the entire list.",
              "Delete": "O(1) - Deletion always occurs at the front.",
              "Peek": "O(1) - Peeking only looks at the front element.",
              "isEmpty": "O(1)",
              "isFull": "Varies - For linked list implementations, it might depend on available system memory."
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Perfect Binary Tree",
        "Info": {
          "Definition": "A perfect binary tree is a type of binary tree in which every internal node has exactly two children and all leaf nodes are at the same level.",
          "Algorithms": {
            "Code": "Node* createPerfectBinaryTree(int depth) {\n  if (depth == 0) return NULL;\n  Node* node = new Node(0);\n  node->left = createPerfectBinaryTree(depth - 1);\n  node->right = createPerfectBinaryTree(depth - 1);\n  return node;\n}"
          },
          "Complexities": {
            "Time Complexity": "O(2^depth - 1) - Because it visits every node.",
            "Space Complexity": "O(2^depth - 1) - Due to storing all nodes."
          }
        }
      },
      {
        "Topic": "Full Binary Tree",
        "Info": {
          "Definition": "A full binary tree (sometimes proper binary tree or 2-tree) is a tree in which every node other than the leaves has two children.",
          "Algorithms": {
            "Code": "class TreeNode {\npublic:\n  int value;\n  TreeNode *left, *right;\n\n  TreeNode(int val) : value(val), left(NULL), right(NULL) {}\n};\n\nclass FullBinaryTree {\npublic:\n  TreeNode *root;\n\n  FullBinaryTree() : root(NULL) {}\n\n  TreeNode* insert(TreeNode* node, int value) {\n    if (node == NULL) return new TreeNode(value);\n    std::queue<TreeNode*> q;\n    q.push(node);\n    while (!q.empty()) {\n      TreeNode* temp = q.front();\n      q.pop();\n      if (!temp->left) {\n        temp->left = new TreeNode(value);\n        return root;\n      } else q.push(temp->left);\n      if (!temp->right) {\n        temp->right = new TreeNode(value);\n        return root;\n      } else q.push(temp->right);\n    }\n    return root;\n  }\n\n  // Pseudocode for deletion is omitted as maintaining a full binary tree upon arbitrary deletions requires complex restructuring or specific context\n};\n\n// Example usage:\n// FullBinaryTree tree;\n// tree.root = tree.insert(tree.root, 10);\n// tree.root = tree.insert(tree.root, 20);"
          },
          "Complexities": {
            "Time Complexity": "O(N) - Level-order traversal may need to visit each node to find the insertion spot.",
            "Space Complexity": "O(N) - In the worst case, the queue used for level-order traversal may hold all nodes at the tree's deepest level."
          }
        }
      },
      

      {
        "Topic": "Complete Binary Tree",
        "Info": {
          "Definition": "A complete binary tree is a binary tree in which all levels are fully filled except possibly the last, which is filled from left to right.",
          "Algorithms": {
            "Insertion": "void insert(Node* root, int key) {\n  if (root == NULL) root = new Node(key);\n  else {\n    queue<Node*> q;\n    q.push(root);\n    while (!q.empty()) {\n      Node* temp = q.front();\n      q.pop();\n      if (!temp->left) {\n        temp->left = new Node(key);\n        break;\n      } else q.push(temp->left);\n      if (!temp->right) {\n        temp->right = new Node(key);\n        break;\n      } else q.push(temp->right);\n    }\n  }\n}",
            "Deletion": "void deleteDeepest(Node* root, Node* d_node) {\n  queue<Node*> q;\n  q.push(root);\n  Node* temp;\n  while(!q.empty()) {\n    temp = q.front();\n    q.pop();\n    if (temp == d_node) {\n      temp = NULL;\n      delete(d_node);\n      return;\n    }\n    if (temp->right) {\n      if (temp->right == d_node) {\n        temp->right = NULL;\n        delete(d_node);\n        return;\n      } else q.push(temp->right);\n    }\n    if (temp->left) {\n      if (temp->left == d_node) {\n        temp->left = NULL;\n        delete(d_node);\n        return;\n      } else q.push(temp->left);\n    }\n  }\n}\n\n// Function to delete given node\n// Function to call deleteDeepest"
          },
          "Complexities": {
            "Time Complexity": "O(n) for both insertion and deletion due to potential full traversal.",
            "Space Complexity": "O(n) for the queue used in traversal."
          }
        }
      },
      {
        "Topic": "Balanced Binary Tree",
        "Info": {
          "Definition": "A balanced binary tree is a type of binary tree where the difference between heights of left and right subtrees of any node is not more than one. Balanced binary trees, such as AVL trees or Red-Black trees, automatically maintain height balance to ensure operation complexities.",
          "Algorithms": {
            "Insertion":"Node* insert(Node* node, int key) {\n  if (node == NULL) return(new Node(key));\n  if (key < node->key) node->left = insert(node->left, key);\n  else if (key > node->key) node->right = insert(node->right, key);\n  else return node;\n  node->height = 1 + max(height(node->left), height(node->right));\n  int balance = getBalance(node);\n  if (balance > 1 && key < node->left->key) return rightRotate(node);\n  if (balance < -1 && key > node->right->key) return leftRotate(node);\n  if (balance > 1 && key > node->left->key) {\n    node->left = leftRotate(node->left);\n    return rightRotate(node);\n  }\n  if (balance < -1 && key < node->right->key) {\n    node->right = rightRotate(node->right);\n    return leftRotate(node);\n  }\n  return node;\n}",
            "Deletion": "Node* deleteNode(Node* root, int key) {\n  if (root == NULL) return root;\n  if ( key < root->key ) root->left = deleteNode(root->left, key);\n  else if( key > root->key ) root->right = deleteNode(root->right, key);\n  else {\n    if( (root->left == NULL) || (root->right == NULL) ) {\n      Node *temp = root->left ? root->left : root->right;\n      if (temp == NULL) {\n        temp = root;\n        root = NULL;\n      } else *root = *temp;\n      free(temp);\n    } else {\n      Node* temp = minValueNode(root->right);\n      root->key = temp->key;\n      root->right = deleteNode(root->right, temp->key);\n    }\n  }\n  if (root == NULL) return root;\n  root->height = max(height(root->left), height(root->right)) + 1;\n  int balance = getBalance(root);\n  if (balance > 1 && getBalance(root->left) >= 0) return rightRotate(root);\n  if (balance > 1 && getBalance(root->left) < 0) {\n    root->left = leftRotate(root->left);\n    return rightRotate(root);\n  }\n  if (balance < -1 && getBalance(root->right) <= 0) return leftRotate(root);\n  if (balance < -1 && getBalance(root->right) > 0) {\n    root->right = rightRotate(root->right);\n    return leftRotate(root);\n  }\n  return root;\n}"
           
          },
          "Complexities": {
            "Time Complexity": "O(log n) - For operations like insertion and deletion, due to height-balancing. This ensures that the tree remains balanced, thereby maintaining a logarithmic height.",
            "Space Complexity": "O(n) - Space needed to store all nodes in the tree."
          }
        }
      },
      {
        "Topic": "Binary Search Tree",
        "Info": {
          "Definition": "A binary search tree (BST) is a binary tree where each node has a key greater than all keys in the node's left subtree and less than those in the right subtree.",
          "Algorithms": {
            "Insertion":"Node* insertBST(Node* node, int key) {\n  if (node == NULL) return new Node(key);\n  if (key < node->data) node->left = insertBST(node->left, key);\n  else if (key > node->data) node->right = insertBST(node->right, key);\n  return node;\n}",
            "Deletion":"Node* deleteBST(Node* root, int key) {\n  if (root == NULL) return root;\n  if (key < root->data) root->left = deleteBST(root->left, key);\n  else if (key > root->data) root->right = deleteBST(root->right, key);\n  else {\n    if (root->left == NULL) {\n      Node *temp = root->right;\n      delete root;\n      return temp;\n    } else if (root->right == NULL) {\n      Node *temp = root->left;\n      delete root;\n      return temp;\n    }\n    Node* temp = minValueNode(root->right);\n    root->data = temp->data;\n    root->right = deleteBST(root->right, temp->data);\n  }\n  return root;\n}"
          },
          "Complexities": {
            "Time Complexity": "O(n) in the worst case (unbalanced tree), O(log n) in the best case (balanced tree) - For operations like search, insertion, and deletion.",
            "Space Complexity": "O(n) - Space needed to store all nodes in the tree."
          }
        }
      }
      ,
      {
        "Topic": "AVL Tree",
        "Info": {
          "Definition": "An AVL tree is a self-balancing binary search tree, where the difference between heights of left and right subtrees cannot be more than one for all nodes.",
          "Algorithms": {
            "Insertion": "Node* insertAVL(Node* node, int key) {\n  // Perform the normal BST insert\n  if (node == NULL) return (new Node(key));\n  if (key < node->key) node->left = insertAVL(node->left, key);\n  else if (key > node->key) node->right = insertAVL(node->right, key);\n  else return node; // Duplicate keys not allowed\n  // Update height of this ancestor node\n  // Calculate balance factor\n  // Rotate if unbalanced\n  return node;\n}",
            "Deletion": "Node* deleteAVL(Node* root, int key) {\n  // Perform standard BST delete\n  if (root == NULL) return root;\n  if (key < root->key) root->left = deleteAVL(root->left, key);\n  else if(key > root->key) root->right = deleteAVL(root->right, key);\n  else {\n    // Node with only one child or no child\n    if((root->left == NULL) || (root->right == NULL)) {\n      Node *temp = root->left ? root->left : root->right;\n      if (temp == NULL) {\n        temp = root;\n        root = NULL;\n      } else *root = *temp; // Copy the contents of the non-empty child\n      delete temp;\n    } else {\n      // Node with two children: Get the inorder successor\n      Node* temp = minValueNode(root->right);\n      root->key = temp->key;\n      root->right = deleteAVL(root->right, temp->key);\n    }\n  }\n  // If the tree had only one node then return\n  if (root == NULL) return root;\n  // Update height of the current node\n  // Get the balance factor\n  // Rotate if unbalanced\n  return root;\n}"
            
          },
          "Complexities": {
            "Time Complexity": "O(log n) - For insertion, deletion, and lookup, due to the tree being balanced.",
            "Space Complexity": "O(n) - Space needed to store all nodes in the tree."
          }
        }
      }
      ,
      {
        "Topic": "Tree Traversal",
        "Info": {
          "Definition": "Traversing a tree means visiting every node in the tree. You might, for instance, want to add all the values in the tree or find the largest one. For all these operations, you will need to visit each node of the tree.Tree traversal algorithms are methods for visiting all the nodes in a tree data structure. There are several types of traversals, each visiting the nodes in a different order. The three fundamental depth-first search (DFS) traversals for binary trees are preorder, inorder, and postorder.\nPreorder Traversal : Visits the current node before its child nodes (Root, Left, Right). \n Inorder Traversal:  Visits the left child, then the current node, and finally the right child (Left, Root, Right). This traversal method is used especially for binary search trees where it returns nodes in non-decreasing order. \n PostOrder Traversal :Visits the current node after its child nodes (Left, Right, Root). This method is used to delete the tree or get the postfix expression of an expression tree.",
          "Algorithms": {
            "Preorder Traversal": "void preorderTraversal(Node* root) {\n  if (root == NULL) return;\n  cout << root->data << ' ';\n  preorderTraversal(root->left);\n  preorderTraversal(root->right);\n}",
            "Inorder Traversal": "void inorderTraversal(Node* root) {\n  if (root == NULL) return;\n  inorderTraversal(root->left);\n  cout << root->data << ' ';\n  inorderTraversal(root->right);\n}",
            "Postorder Traversal": "void postorderTraversal(Node* root) {\n  if (root == NULL) return;\n  postorderTraversal(root->left);\n  postorderTraversal(root->right);\n  cout << root->data << ' ';\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Preorder": "O(n)",
              "Inorder": "O(n)",
              "Postorder": "O(n)"
            },
            "Space Complexity": "O(h) - where h is the height of the tree. This space complexity accounts for the call stack during recursive calls."
          }
        }
      },
      {
        "Topic": "B-Tree",
        "Info": {
          "Definition": "A B-Tree is a self-balancing tree data structure that maintains sorted data and allows searches, sequential access, insertions, and deletions in logarithmic time. It generalizes the binary search tree, allowing for nodes with more than two children.",
          "Algorithms": {
            "Insertion Code": "void insert(Node* &root, int key) {\n    // Check if the tree is empty\n    if (root == nullptr) {\n        root = createNode(key);\n        return;\n    }\n\n    // Recursive insert function\n    // Insert logic for B-Tree insertion\n}",
            "Deletion Code": "void deleteKey(Node* &root, int key) {\n    // Deletion logic for B-Tree\n    // Handle cases: leaf and internal nodes\n}"
          },
          "Complexities": {
            "Time Complexity": {
              "Search": "O(log n)",
              "Insert": "O(log n)",
              "Delete": "O(log n)"
            },
            "Space Complexity": "O(n), where n is the number of keys in the tree."
          }
        }
      },
      {
        "Topic": "B+ Tree",
        "Info": {
          "Definition": "A B+ Tree is a type of B-Tree used in databases and filesystems to store data for efficient retrieval. It differs from a B-Tree by storing all data in leaf nodes and using internal nodes as a means to provide a pathway to these leaf nodes.",
          "Algorithms": {
            "Insertion Code": "void BPlusTreeInsertion(Node* &root, int key) {\n    // Insert logic for B+ Tree\n    // Ensures that all data is in the leaf nodes\n}",
            "Deletion Code": "void BPlusTreeDeletion(Node* &root, int key) {\n    // Deletion logic for B+ Tree\n    // Adjusts tree to maintain properties after deletion\n}"
          },
          "Complexities": {
            "Time Complexity": {
              "Search": "O(log n)",
              "Insert": "O(log n)",
              "Delete": "O(log n)"
            },
            "Space Complexity": "O(n), where n is the number of keys."
          }
        }
      },
      
      {
        "Topic": "Merge Sort",
        "Info": {
          "Definition": "Merge Sort is a divide-and-conquer algorithm that divides the input array into two halves, calls itself for the two halves, and then merges the two sorted halves. It is known for its consistent performance and is often used in sorting libraries.",
          "Algorithms": {
            "Code":"void merge(int arr[], int l, int m, int r) {\n    int n1 = m - l + 1;\n    int n2 = r - m;\n\n    // Create temp arrays\n    int L[n1], R[n2];\n\n    // Copy data to temp arrays L[] and R[]\n    for (int i = 0; i < n1; i++)\n        L[i] = arr[l + i];\n    for (int j = 0; j < n2; j++)\n        R[j] = arr[m + 1 + j];\n\n    // Merge the temp arrays back into arr[l..r]\n    int i = 0; // Initial index of first subarray\n    int j = 0; // Initial index of second subarray\n    int k = l; // Initial index of merged subarray\n    while (i < n1 && j < n2) {\n        if (L[i] <= R[j]) {\n            arr[k] = L[i];\n            i++;\n        } else {\n            arr[k] = R[j];\n            j++;\n        }\n        k++;\n    }\n\n    // Copy the remaining elements of L[], if there are any\n    while (i < n1) {\n        arr[k] = L[i];\n        i++;\n        k++;\n    }\n\n    // Copy the remaining elements of R[], if there are any\n    while (j < n2) {\n        arr[k] = R[j];\n        j++;\n        k++;\n    }\n}\n\nvoid mergeSort(int arr[], int l, int r) {\n    if (l < r) {\n        // Find the middle point to divide the array into two halves\n        int m = l + (r-l)/2;\n\n        // Call mergeSort for first half\n        mergeSort(arr, l, m);\n\n        // Call mergeSort for second half\n        mergeSort(arr, m+1, r);\n\n        // Merge the sorted halves\n        merge(arr, l, m, r);\n    }\n}"
          },
          "Complexities": {
            "Time Complexity": "Worst, Average, and Best Case: O(n log n) - Merge sort always divides the array in half and takes linear time to merge two halves.",
            "Space Complexity": "O(n) - Requires additional space for the temporary arrays used in the merge process."
          }
        }
      },
      {
        "Topic": "Quick Sort",
        "Info": {
          "Definition": "Quick Sort is a highly efficient sorting algorithm and is based on partitioning of array of data into smaller arrays. A large array is partitioned into two arrays one of which holds values smaller than the specified value, say pivot, based on which the partition is made and another array holds values greater than the pivot value.",
          "Algorithms": {
            "Code":"void quickSort(int arr[], int low, int high) {\n  if (low < high) {\n    int pi = partition(arr, low, high);\n    quickSort(arr, low, pi - 1);\n    quickSort(arr, pi + 1, high);\n  }\n}\n\nint partition(int arr[], int low, int high) {\n  // This function takes last element as pivot, places the pivot element at its correct position in sorted array, and places all smaller to left of pivot and all greater elements to right of pivot.\n}"
          },
          "Complexities": {
            "Time Complexity": "Worst Case: O(n^2) when the pivot selection is poor. Average and Best Case: O(n log n) - The array is divided into subarrays that are processed recursively.",
            "Space Complexity": "O(log n) - The space complexity comes from the stack space used for recursion. The worst case is O(n), depending on the implementation."
          }
        }
      },
      {
        "Topic": "Heap Data Structure",
        "Info": {
          "Definition": "A Heap is a special Tree-based data structure that satisfies the heap property. In a max heap, for any given node C, if P is a parent node of C, then the key (the value) of P is greater than or equal to the key of C. The same property must be recursively true for all nodes in Binary Tree. Min heap is a heap where the value of parent nodes is less than or equal to that of child nodes.",
          "Algorithms": {
            "Insert (Heapify Up)": "Inserts a new element into the heap and re-arranges the heap to maintain the heap property.\n\nvoid insert(int key) {\n  heapSize++; // Assume heapSize is the current number of elements in the heap\n  int index = heapSize - 1;\n  heap[index] = key;\n  // Heapify up\n  while (index != 0 && heap[parent(index)] < heap[index]) {\n    swap(heap[index], heap[parent(index)]);\n    index = parent(index);\n  }\n}",
            "Delete (Heapify Down)": "Removes the root element from the heap and re-arranges it to maintain the heap property.\n\nvoid deleteRoot() {\n  if (heapSize <= 0) return;\n  heap[0] = heap[heapSize-1];\n  heapSize--;\n  heapifyDown(0);\n}",
            "Get Max or Min": "Retrieves the maximum element from a max heap or the minimum element from a min heap without removing it.\n\nint getPeak() {\n  return heap[0];\n}",
            "Build Heap (Heapify)": "Converts an unsorted array into a heap.\n\nvoid buildHeap(int arr[], int n) {\n  for (int i = (n / 2) - 1; i >= 0; i--) {\n    heapify(arr, n, i);\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Insert (Heapify Up)": "O(log n) - Because it may traverse from the node inserted at the very end up to the root node.",
              "Delete (Heapify Down)": "O(log n) - Due to the traversal down from the root to the leaf to maintain the heap property.",
              "Get Max or Min": "O(1) - The peak element is always at the root of the heap.",
              "Build Heap (Heapify)": "O(n) - Building the heap from an unsorted array takes linear time."
            },
            "Space Complexity": "O(n) - The space needed to store the heap structure."
          }
        }
      },
      {
        "Topic": "Heap Sort",
        "Info":{
          "Definition": "Heap Sort is a comparison-based sorting technique based on the Binary Heap data structure. It's similar to the selection sort where we first find the maximum element and place it at the end. The same process is repeated for the remaining elements, utilizing a heap to efficiently find the next maximum element.",
          "Algorithms":{
            "Code": "void heapify(int arr[], int n, int i) {\n    int largest = i; // Initialize largest as root\n    int l = 2 * i + 1; // left = 2*i + 1\n    int r = 2 * i + 2; // right = 2*i + 2\n\n    // If left child is larger than root\n    if (l < n && arr[l] > arr[largest])\n        largest = l;\n\n    // If right child is larger than largest so far\n    if (r < n && arr[r] > arr[largest])\n        largest = r;\n\n    // If largest is not root\n    if (largest != i) {\n        swap(arr[i], arr[largest]);\n\n        // Recursively heapify the affected sub-tree\n        heapify(arr, n, largest);\n    }\n}\n\nvoid heapSort(int arr[], int n) {\n    // Build heap (rearrange array)\n    for (int i = n / 2 - 1; i >= 0; i--)\n        heapify(arr, n, i);\n\n    // One by one extract an element from heap\n    for (int i = n - 1; i >= 0; i--) {\n        // Move current root to end\n        swap(arr[0], arr[i]);\n\n        // call max heapify on the reduced heap\n        heapify(arr, i, 0);\n    }\n}"
          },
        "Complexities":{
          "Time Complexity": {
            "Worst Case": "O(n log n)",
            "Average Case": "O(n log n)",
            "Best Case": "O(n log n)"
          },
          "Space Complexity": "O(1) - Heap sort is an in-place algorithm but may require a small stack for recursion during heapify."
        }
        
        }   
      },
      {
        "Topic": "Count Sort",
        "Info": {
          "Definition": "Count Sort is an integer sorting algorithm that operates by counting the number of occurrences of each distinct value in the input array. These counts are then used to compute the position of each element in the sorted array.",
          "Algorithms": {
            "Code": "void countSort(int arr[], int n) {\n    int output[n];\n    int count[256], i;\n    memset(count, 0, sizeof(count));\n\n    for(i = 0; arr[i]; ++i)\n        ++count[arr[i]];\n\n    for (i = 1; i <= 255; ++i)\n        count[i] += count[i-1];\n\n    for (i = 0; arr[i]; ++i) {\n        output[count[arr[i]]-1] = arr[i];\n        --count[arr[i]];\n    }\n\n    for (i = 0; arr[i]; ++i)\n        arr[i] = output[i];\n}"
          },
          "Complexities": {
            "Time Complexity": "O(n + k) - Where n is the number of elements and k is the range of the input.",
            "Space Complexity": "O(k) - The space used by the count array."
          }
        }
      },
      {
        "Topic": "Radix Sort",
        "Info": {
          "Definition": "Radix Sort is a non-comparative sorting algorithm that sorts integers by processing individual digits. Numbers are grouped by each digit, starting from the least significant digit to the most significant digit, using a stable algorithm like Count Sort as a subroutine.",
          "Algorithms": {
            "Code": "void countSort(int arr[], int n, int exp) {\n    vector<int> output(n);\n    int i, count[10] = {0};\n\n    for (i = 0; i < n; i++)\n        count[(arr[i] / exp) % 10]++;\n\n    for (i = 1; i < 10; i++)\n        count[i] += count[i - 1];\n\n    for (i = n - 1; i >= 0; i--) {\n        output[count[(arr[i] / exp) % 10] - 1] = arr[i];\n        count[(arr[i] / exp) % 10]--;\n    }\n\n    for (i = 0; i < n; i++)\n        arr[i] = output[i];\n}\n\nvoid radixSort(int arr[], int n) {\n    int m = getMax(arr, n);\n    for (int exp = 1; m / exp > 0; exp *= 10)\n        countSort(arr, n, exp);\n}"
          },
          "Complexities": {
            "Time Complexity": "O(nk) - Where n is the number of elements and k is the number of digits in the maximum number.",
            "Space Complexity": "O(n + k) - For the intermediate count sort operations."
          }
        }
      },
      {
        "Topic": "Bucket Sort",
        "Info": {
          "Definition": "Bucket Sort, or Bin Sort, operates by partitioning an array into a number of buckets. Each bucket is then sorted individually, either using a different sorting algorithm, or by recursively applying the bucket sort algorithm.",
          "Algorithms": {
            "Code": "void bucketSort(float arr[], int n) {\n    vector<float> b[n];\n    for (int i = 0; i < n; i++) {\n       int bi = n * arr[i]; // Index in bucket\n       b[bi].push_back(arr[i]);\n    }\n\n    for (int i = 0; i < n; i++)\n       sort(b[i].begin(), b[i].end());\n\n    int index = 0;\n    for (int i = 0; i < n; i++)\n       for (int j = 0; j < b[i].size(); j++)\n          arr[index++] = b[i][j];\n}"
          },
          "Complexities": {
            "Time Complexity": "Average Case: O(n + n^2/k + k), and Worst Case: O(n^2). Here, n is the number of elements, and k is the number of buckets.",
            "Space Complexity": "O(n*k) - For the buckets used during sorting."
          }
        }
      },
      {
        "Topic": "Dijkstra's Algorithm",
        "Info": {
          "Definition": "Dijkstra's Algorithm finds the shortest paths from a single source vertex to all other vertices in a weighted graph with non-negative edge weights.",
          "Algorithms": {
            "Code": "void dijkstra(const vector<vector<int>>& graph, int src) {\n  int V = graph.size();\n  vector<int> dist(V, INT_MAX);\n  dist[src] = 0;\n  vector<bool> sptSet(V, false);\n\n  for (int count = 0; count < V-1; count++) {\n    int u = -1;\n    for(int i = 0; i < V; i++)\n      if (!sptSet[i] && (u == -1 || dist[i] < dist[u]))\n        u = i;\n    sptSet[u] = true;\n    for (int v = 0; v < V; v++)\n      if (!sptSet[v] && graph[u][v] && dist[u] != INT_MAX && dist[u]+graph[u][v] < dist[v])\n        dist[v] = dist[u] + graph[u][v];\n  }\n}"
          },
          "Complexities": {
            "Time Complexity": "O(V^2) - For the implementation using adjacency matrix. With a priority queue, it can be reduced to O(V + E log V) where E is the number of edges.",
            "Space Complexity": "O(V) - Space needed for the distance array and the sptSet."
          }
        }
      },
      {
        "Topic": "Kruskal's Algorithm",
        "Info": {
          "Definition": "Kruskal's Algorithm finds a minimum spanning tree for a connected, undirected graph by adding increasing cost edges at each step, avoiding any cycles.",
          "Algorithms": {
            "Code": "struct Edge { int src, dest, weight; };\nstruct Graph { int V, E; vector<Edge> edges; };\nint find(vector<int>& parent, int i) {\n  if (parent[i] == i) return i;\n  return find(parent, parent[i]);\n}\nvoid kruskalMST(struct Graph& graph) {\n  sort(graph.edges.begin(), graph.edges.end(), [](Edge a, Edge b) { return a.weight < b.weight; });\n  vector<int> parent(graph.V);\n  for (int i = 0; i < graph.V; i++) parent[i] = i;\n  vector<Edge> mst;\n  for (Edge e : graph.edges) {\n    int x = find(parent, e.src);\n    int y = find(parent, e.dest);\n    if (x != y) {\n      mst.push_back(e);\n      parent[x] = y;\n    }\n  }\n  // mst contains the resulting minimum spanning tree\n}"
          },
          "Complexities": {
            "Time Complexity": "O(E log E) - Or O(E log V) because of the sorting of edges, where E is the number of edges in the graph.",
            "Space Complexity": "O(V + E) - For storing the graph and the minimum spanning tree."
          }
        }
      },
      {
        "Topic": "Recursion and Backtracking",
        "Info": {
          "Definition": "Recursion\nRecursion is a method of solving a problem where the solution depends on solutions to smaller instances of the same problem. A recursive function calls itself with a base case to stop the recursion.\nBacktracking\nBacktracking is an algorithmic-technique for solving problems recursively by trying to build a solution incrementally, one piece at a time, removing those solutions that fail to satisfy the constraints of the problem at any point of time.",
          
          "Algorithms": {
            
              "Recursion Example - Factorial": "int factorial(int n) {\n  if (n <= 1) return 1;\n  return n * factorial(n - 1);\n}",
              "Backtracking Example - N Queens Problem":"bool isSafe(int board[N][N], int row, int col) {\n  // Check this row on left side\n  // Check upper diagonal on left side\n  // Check lower diagonal on left side\n  // For simplification, these checks are omitted\n  return true;\n}\n\nbool solveNQUtil(int board[N][N], int col) {\n  if (col >= N) return true;\n  for (int i = 0; i < N; i++) {\n    if (isSafe(board, i, col)) {\n      board[i][col] = 1;\n      if (solveNQUtil(board, col + 1)) return true;\n      board[i][col] = 0; // BACKTRACK\n    }\n  }\n  return false;\n}"
            
          },
          "Complexities": {
            "Time Complexity": {
              "Recursion Example - Factorial": "O(n) - The time complexity is linear, as it makes a single call for each decrement of n until it reaches the base case.",
              "Backtracking Example - N Queens Problem": "O(N!) - The worst-case time complexity, as it tries every possible arrangement of queens."
            },
            "Space Complexity": {
              "Recursion Example - Factorial": "O(n) - Due to the call stack in recursion for each function call until the base case is reached.",
              "Backtracking Example - N Queens Problem": "O(N) - Mainly for the call stack in recursion. Additional space for the board is not considered here."
            }
          }
        }
      }   
    ]
  },
  {
    "category":"Hard",
    "Problems":[
      
      {
        "Topic": "Hash Table",
        "Info": {
          "Definition": "A hash table, also known as a hash map, is a data structure that implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index into an array of buckets or slots, from which the desired value can be found.",
          "Algorithms": {
            "Code": "class HashTable {\nprivate:\n  int BUCKET;\n  list<int> *table;\npublic:\n  HashTable(int V);\n  void insertItem(int key, int value);\n  void deleteItem(int key);\n  int hashFunction(int x) {\n    return (x % BUCKET);\n  }\n};\n\nHashTable::HashTable(int b) {\n  this->BUCKET = b;\n  table = new list<int>[BUCKET];\n}\n\nvoid HashTable::insertItem(int key, int value) {\n  int index = hashFunction(key);\n  table[index].push_back(value);\n}\n\nvoid HashTable::deleteItem(int key) {\n  int index = hashFunction(key);\n  list<int>::iterator i;\n  for (i = table[index].begin(); i != table[index].end(); i++) {\n    if (*i == key)\n      break;\n  }\n  if (i != table[index].end())\n    table[index].erase(i);\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Average case (insert/search/delete)": "O(1)",
              "Worst case (insert/search/delete)": "O(n) - Occurs when all keys are mapped to a single bucket"
            },
            "Space Complexity": "O(n) - Where n is the number of keys stored in the hash table."
          }
        }
      },
      
      {
        "Topic": "0/1 Knapsack Problem",
        "Info": {
          "Definition": "The 0/1 Knapsack Problem is a problem in combinatorial optimization where one has to maximize the total value of items in a knapsack without exceeding its capacity. Each item can either be included or excluded, hence the name 0/1.",
          "Algorithms": {
            "Code": "int knapSack(int W, int wt[], int val[], int n) {\n   vector<vector<int>> dp(n+1, vector<int>(W+1, 0));\n   for(int i = 1; i <= n; i++) {\n       for(int w = 1; w <= W; w++) {\n           if(wt[i-1] <= w)\n               dp[i][w] = max(val[i-1] + dp[i-1][w-wt[i-1]], dp[i-1][w]);\n           else\n               dp[i][w] = dp[i-1][w];\n       }\n   }\n   return dp[n][W];\n}"
          },
          "Complexities": {
            "Time Complexity": "O(nW) - Where n is the number of items and W is the capacity of the knapsack.",
            "Space Complexity": "O(nW) - For the DP table storing solutions for subproblems."
          }
        }
      },
      {
        "Topic": "Longest Common Subsequence",
        "Info": {
          "Definition": "The Longest Common Subsequence (LCS) problem involves finding the longest subsequence present in two sequences (not necessarily contiguous) such that the subsequence is common to both.",
          "Algorithms": {
            "Code": "int lcs(string &X, string &Y) {\n   int m = X.length(), n = Y.length();\n   vector<vector<int>> dp(m+1, vector<int>(n+1));\n   for(int i=1; i<=m; i++) {\n       for(int j=1; j<=n; j++) {\n           if(X[i-1] == Y[j-1])\n               dp[i][j] = dp[i-1][j-1] + 1;\n           else\n               dp[i][j] = max(dp[i-1][j], dp[i][j-1]);\n       }\n   }\n   return dp[m][n];\n}"
          },
          "Complexities": {
            "Time Complexity": "O(mn) - Where m and n are the lengths of the two sequences.",
            "Space Complexity": "O(mn) - For the DP table."
          }
        }
      },
      {
        "Topic": "Floyd-Warshall Algorithm",
        "Info": {
          "Definition": "The Floyd-Warshall Algorithm is a dynamic programming solution for finding the shortest paths between all pairs of vertices in a weighted graph. It can handle negative weight edges but not negative weight cycles.",
          "Algorithms": {
            "Code": "void floydWarshall(int graph[][V]) {\n    int dist[V][V], i, j, k;\n    for (i = 0; i < V; i++)\n        for (j = 0; j < V; j++)\n            dist[i][j] = graph[i][j];\n    for (k = 0; k < V; k++) {\n        for (i = 0; i < V; i++) {\n            for (j = 0; j < V; j++) {\n                if (dist[i][k] + dist[k][j] < dist[i][j])\n                    dist[i][j] = dist[i][k] + dist[k][j];\n            }\n        }\n    }\n}",
            "Complexities": {
              "Time Complexity": "O(V^3) - The algorithm runs three nested loops over the graph's vertices, where V is the number of vertices in the graph.",
              "Space Complexity": "O(V^2) - Space needed to store the distance matrix."
            }
          }
        }
      },
      {
        "Topic": "Prim's Algorithm",
        "Info": {
          "Definition": "Prim's Algorithm is a greedy algorithm that finds the minimum spanning tree for a weighted undirected graph, ensuring that every vertex is connected without any cycles and with the minimum possible total edge weight.",
          "Algorithms": {
            "Code": "void primMST(int graph[V][V]) {\n    int parent[V];\n    int key[V];\n    bool mstSet[V];\n    for (int i = 0; i < V; i++)\n        key[i] = INT_MAX, mstSet[i] = false;\n    key[0] = 0;\n    parent[0] = -1;\n    for (int count = 0; count < V-1; count++) {\n        int u = minKey(key, mstSet);\n        mstSet[u] = true;\n        for (int v = 0; v < V; v++)\n            if (graph[u][v] && !mstSet[v] && graph[u][v] < key[v])\n                parent[v] = u, key[v] = graph[u][v];\n    }\n    printMST(parent, V, graph);\n}"
          },
          "Complexities": {
            "Time Complexity": "O(V^2) - For a graph represented using adjacency matrix. Can be improved to O(E log V) with adjacency list and priority queue.",
            "Space Complexity": "O(V) - To store the keys, MST set, and parent array."
          }
        }
      },
      {
        "Topic": "Huffman Coding",
        "Info": {
          "Definition": "Huffman Coding is a widely used method of lossless data compression, which assigns variable-length codes to input characters, with shorter codes for more frequent characters. This algorithm uses a greedy technique to build a prefix-free binary tree called Huffman Tree.",
          "Algorithms": {
            "Code": "void buildHuffmanTree(vector<char>& data, vector<int>& freq, int size) {\n    priority_queue<HuffmanNode*, vector<HuffmanNode*>, compare> minHeap;\n    for (int i = 0; i < size; ++i)\n        minHeap.push(new HuffmanNode(data[i], freq[i]));\n    while (minHeap.size() != 1) {\n        HuffmanNode* left = minHeap.top(); minHeap.pop();\n        HuffmanNode* right = minHeap.top(); minHeap.pop();\n        HuffmanNode* top = new HuffmanNode('$', left->freq + right->freq);\n        top->left = left;\n        top->right = right;\n        minHeap.push(top);\n    }\n    printCodes(minHeap.top(), \"\");\n}"
          },
          "Complexities": {
            "Time Complexity": "O(n log n) - Where n is the number of unique characters. If there are N nodes, there will be N-1 merge operations and each operation involves a heap operation of O(log n).",
            "Space Complexity": "O(n) - To store the tree."
          }
        }
      },
      {
        "Topic": "Shell Sort",
        "Info": {
          "Definition": "Shell Sort is an in-place comparison sort which generalizes insertion sort to allow the exchange of items that are far apart. The idea is to arrange the list of elements so that, starting anywhere, taking every hth element produces a sorted list.",
          "Algorithms": {
            "Code": "void shellSort(int arr[], int n) {\n    for (int gap = n/2; gap > 0; gap /= 2) {\n        for (int i = gap; i < n; i += 1) {\n            int temp = arr[i];\n            int j;\n            for (j = i; j >= gap && arr[j - gap] > temp; j -= gap)\n                arr[j] = arr[j - gap];\n            arr[j] = temp;\n        }\n    }\n}"
          },
          "Complexities": {
            "Time Complexity": "Worst-case time complexity is O(n^2), but it can perform better on partially sorted arrays. The best case is O(n log n).",
            "Space Complexity": "O(1) - It is an in-place sorting algorithm."
          }
        }
      },
      {
        "Topic": "Ford-Fulkerson Algorithm",
        "Info": {
          "Definition": "The Ford-Fulkerson algorithm computes the maximum flow in a flow network. It initializes the flow to 0 and repeatedly increases it by finding augmenting paths from the source to the sink. The process continues until no augmenting paths are left.",
          "Algorithms": {
            "Code": "int fordFulkerson(int graph[V][V], int s, int t) {\n    int u, v;\n    int rGraph[V][V];\n    for (u = 0; u < V; u++)\n        for (v = 0; v < V; v++)\n             rGraph[u][v] = graph[u][v];\n    int parent[V];\n    int max_flow = 0;\n    while (bfs(rGraph, s, t, parent)) {\n        int path_flow = INT_MAX;\n        for (v = t; v != s; v = parent[v]) {\n            u = parent[v];\n            path_flow = min(path_flow, rGraph[u][v]);\n        }\n        for (v = t; v != s; v = parent[v]) {\n            u = parent[v];\n            rGraph[u][v] -= path_flow;\n            rGraph[v][u] += path_flow;\n        }\n        max_flow += path_flow;\n    }\n    return max_flow;\n}"
          },
          "Complexities": {
            "Time Complexity": "O(max_flow * E), where E is the number of edges. The algorithm runs while there are augmenting paths, and each path can add at most 'max_flow' amount of flow.",
            "Space Complexity": "O(V^2), as it requires storing the residual graph."
          }
        }
      },
      {
        "Topic": "Floyd-Warshall Algorithm",
        "Info": {
          "Definition": "The Floyd-Warshall algorithm is a dynamic programming solution for finding the shortest paths between all pairs of vertices in a weighted graph. It can handle negative weights but not negative cycles.",
          "Algorithms": {
            "Code": "void floydWarshall(int graph[][V]) {\n    int dist[V][V], i, j, k;\n    for (i = 0; i < V; i++)\n        for (j = 0; j < V; j++)\n            dist[i][j] = graph[i][j];\n    for (k = 0; k < V; k++) {\n        for (i = 0; i < V; i++) {\n            for (j = 0; j < V; j++) {\n                if (dist[i][k] + dist[k][j] < dist[i][j])\n                    dist[i][j] = dist[i][k] + dist[k][j];\n            }\n        }\n    }\n    printSolution(dist);\n}"
          },
          "Complexities": {
            "Time Complexity": "O(V^3), where V is the number of vertices in the graph. The algorithm has three nested loops, each iterating through the vertices.",
            "Space Complexity": "O(V^2), for storing the distance matrix."
          }
        }
      },
      {
        "Topic": "Rabin-Karp Algorithm",
        "Info": {
          "Definition": "The Rabin-Karp Algorithm is a string-searching algorithm that uses hashing to find any one of a set of pattern strings in a text. It is particularly useful for detecting multiple patterns in a text in a single pass. The algorithm matches the hash value of the pattern with the hash value of current substring of the text, and if the hash values match, it then checks for individual character matches.",
          "Algorithms": {
            "Code": "void rabinKarp(string const& s, string const& t) {\n    const int p = 31;\n    const int m = 1e9 + 9;\n    int S = s.size(), T = t.size();\n\n    vector<long long> p_pow(max(S, T));\n    p_pow[0] = 1;\n    for (int i = 1; i < (int)p_pow.size(); i++)\n        p_pow[i] = (p_pow[i-1] * p) % m;\n\n    vector<long long> h(T + 1, 0);\n    for (int i = 0; i < T; i++)\n        h[i+1] = (h[i] + (t[i] - 'a' + 1) * p_pow[i]) % m;\n\n    long long h_s = 0;\n    for (int i = 0; i < S; i++)\n        h_s = (h_s + (s[i] - 'a' + 1) * p_pow[i]) % m;\n\n    for (int i = 0; i + S - 1 < T; i++) { \n        long long cur_h = (h[i+S] + m - h[i]) % m; \n        if (cur_h == h_s * p_pow[i] % m)\n            cout << \"Pattern found at index: \" << i << endl;\n    }\n}"
          },
          "Complexities": {
            "Time Complexity": "Average and best case is O(n+m), where n is the length of text and m is the length of the pattern, but its worst case is O(nm), which occurs when all characters of the pattern and text are same as the hash value of all the substrings of the text will be same.",
            "Space Complexity": "O(n), where n is the length of the text, to store the hash values of all possible substrings of the text."
          }
        }
      },
      {
        "Topic": "Fibonacci Heap",
        "Info": {
          "Definition": "A Fibonacci Heap is a data structure for priority queue operations, consisting of a collection of heap-ordered trees. It has a better amortized running time than many other priority queue data structures including the binary heap and binomial heap.",
          "Algorithms": {
            "Code": "struct Node {\n    int key;\n    Node *prev, *next;\n    Node *child, *parent;\n    int degree;\n    bool marked;\n};\n\n// Initial creation of a Fibonacci heap\nNode* createHeap() {\n    Node* np = nullptr;\n    return np;\n}\n\n// Insertion operation in a Fibonacci heap\nvoid insert(Node* &heap, Node* node) {\n    // Implementation details\n}\n\n// Decrease key operation in a Fibonacci heap\nvoid decreaseKey(Node* &heap, Node* node, int new_val) {\n    // Implementation details\n}\n\n// Delete node operation from a Fibonacci heap\nvoid deleteNode(Node* &heap, Node* node) {\n    // Implementation details\n}"
          },
          "Complexities": {
            "Time Complexity": {
              "Insert": "O(1)",
              "Decrease Key": "O(1) amortized",
              "Delete Node": "O(log n) amortized"
            },
            "Space Complexity": "O(n), where n is the number of elements in the heap."
          }
        }
      },
      {
        "Topic": "Decrease Key and Delete Node from Fibonacci Heap",
        "Info": {
          "Definition": "In a Fibonacci Heap, the decrease key operation decreases the value of a given node, potentially breaking the heap property and requiring a cut and cascading cut operations. The delete node operation involves decreasing the value of the node to negative infinity (or a value lower than any heap element), thus moving it to the root list, and then performing a delete minimum operation.",
          "Algorithms": {
            "DecreaseKey Code": "void decreaseKey(Node* &heap, Node* node, int new_val) {\n    if (heap == nullptr || node == nullptr) return;\n    if (node->key < new_val) {\n        cout << \"New key is greater than current key\";\n        return;\n    }\n    node->key = new_val;\n    Node* parent = node->parent;\n    if (parent != nullptr && node->key < parent->key) {\n        cut(heap, node, parent);\n        cascadingCut(heap, parent);\n    }\n    if (node->key < heap->key) {\n        heap = node;\n    }\n}",
            "DeleteNode Code": "void deleteNode(Node* &heap, Node* node) {\n    decreaseKey(heap, node, INT_MIN);\n    Node* min = removeMin(heap);\n    // Assuming removeMin removes and returns the minimum element from the heap\n}"
          },
          "Complexities": {
            "Time Complexity": "Decrease Key: O(1) amortized, Delete Node: O(log n) amortized",
            "Space Complexity": "O(1), assuming no additional space is required apart from the input."
          }
        }
      },
      {
        "Topic": "Red-Black Tree",
        "Info": {
          "Definition": "A Red-Black Tree is a kind of self-balancing binary search tree where each node has an extra bit for denoting the color of the node, either red or black. A Red-Black Tree ensures that the tree remains balanced, and operations like insertion, deletion, and search can be performed in logarithmic time complexity.",
          "Algorithms": {
            "Insertion Code": "void insert(Node *&root, int data) {\n    // Perform normal BST insert\n    // Color the new node as RED\n    // Fix Red Black Tree violations\n}",
            "Deletion Code": "void deleteNode(Node *&root, int data) {\n    // Perform standard BST delete\n    // Fix Red Black Tree violations\n}"
          },
          "Complexities": {
            "Time Complexity": {
              "Search": "O(log n)",
              "Insert": "O(log n)",
              "Delete": "O(log n)"
            },
            "Space Complexity": "O(n), where n is the number of nodes in the tree."
          }
        }
      },
      
      
      {
        "Topic": "Spanning Tree",
        "Info": {
          "Definition": "A spanning tree of an undirected graph is a subgraph that includes all the vertices of the graph and is a tree. A single graph can have many different spanning trees.",
          "Algorithms": {
            "Code": "class Graph {\npublic:\n    int V; // Number of vertices\n    list<pair<int, int>> *adj; // Adjacency list, pair<vertex, weight>\n\n    Graph(int V) {\n        this->V = V;\n        adj = new list<pair<int, int>>[V];\n    }\n\n    void addEdge(int u, int v, int w) {\n        adj[u].push_back(make_pair(v, w));\n        adj[v].push_back(make_pair(u, w));\n    }\n\n    void primMST(); // Method to compute MST using Prim's algorithm\n};\n\nvoid Graph::primMST() {\n    priority_queue< pair<int, int>, vector <pair<int, int>> , greater<pair<int, int>> > pq;\n\n    int src = 0; // Taking vertex 0 as source\n\n    vector<int> key(V, INT_MAX);\n    vector<int> parent(V, -1);\n    vector<bool> inMST(V, false);\n\n    pq.push(make_pair(0, src));\n    key[src] = 0;\n\n    while (!pq.empty()) {\n        int u = pq.top().second;\n        pq.pop();\n\n        inMST[u] = true;  // Include vertex in MST\n\n        list< pair<int, int> >::iterator i;\n        for (i = adj[u].begin(); i != adj[u].end(); ++i) {\n            int v = (*i).first;\n            int weight = (*i).second;\n\n            if (inMST[v] == false && key[v] > weight) {\n                key[v] = weight;\n                pq.push(make_pair(key[v], v));\n                parent[v] = u;\n            }\n        }\n    }\n    // Printing constructed MST (The parent array stores the MST)\n}"
          },
          "Complexities": {
            "Time Complexity": "O(E log V) - For Prim's algorithm using a binary heap.",
            "Space Complexity": "O(V+E) - Space needed to store the tree structure."
          }
        }
      },
      {
        "Topic": "Bellman-Ford Algorithm",
        "Info": {
          "Definition": "The Bellman-Ford algorithm computes shortest paths from a single source vertex to all of the other vertices in a weighted graph. It is capable of handling graphs in which some of the edge weights are negative.",
          "Algorithms": {
            "Code": "int V, E; // V is the number of vertices and E is the number of edges\nstruct Edge { int u, v, w; };\nvector<Edge> edges;\n// Initialization\nvector<int> dist(V, INT_MAX);\ndist[src] = 0;\n// Relaxation\nfor(int i = 0; i < V-1; i++)\n  for(auto &edge : edges)\n    if(dist[edge.u] + edge.w < dist[edge.v])\n      dist[edge.v] = dist[edge.u] + edge.w;\n// Check for negative-weight cycles\nfor(auto &edge : edges)\n  if(dist[edge.u] + edge.w < dist[edge.v])\n    throw \"Graph contains a negative-weight cycle\";"
          },
          "Complexities": {
            "Time Complexity": "O(VE) - As it relaxes all edges V-1 times.",
            "Space Complexity": "O(V) - For storing distance and predecessor arrays."
          }
        }
      },
      {
        "Topic": "Strongly Connected Components (SCC)",
        "Info": {
          "Definition": "In a directed graph, a strongly connected component is a maximal set of vertices such that each pair of vertices is reachable from the other, i.e., each vertex in the set is reachable from every other vertex in the set.",
          "Algorithms": {
            "Code": "class Graph {\npublic:\n    int V; // Vertices\n    list<int> *adj; // Adjacency list\n    Graph(int V) { this->V = V; adj = new list<int>[V]; }\n    void addEdge(int v, int w) { adj[v].push_back(w); }\n    void fillOrder(int v, bool visited[], stack<int> &Stack);\n    void DFSUtil(int v, bool visited[]);\n    void printSCCs();\n    Graph getTranspose();\n};\n\nvoid Graph::DFSUtil(int v, bool visited[]) {\n    visited[v] = true;\n    list<int>::iterator i;\n    for(i = adj[v].begin(); i != adj[v].end(); ++i)\n        if(!visited[*i])\n            DFSUtil(*i, visited);\n}\n\nGraph Graph::getTranspose() {\n    Graph g(V);\n    for(int v = 0; v < V; v++)\n        for(list<int>::iterator i = adj[v].begin(); i != adj[v].end(); ++i)\n            g.adj[*i].push_back(v);\n    return g;\n}\n\n// Methods fillOrder and printSCCs to be implemented as per Kosaraju's algorithm steps."
          },
          "Complexities": {
            "Time Complexity": "O(V+E) for both Tarjan's and Kosaraju's algorithms. This is because each edge and vertex in the graph is visited once during the depth-first search process.",
            "Space Complexity": "O(V) for Tarjan's algorithm due to the stack and O(V+E) for Kosaraju's due to the need to store the transpose graph. Additionally, both algorithms require O(V) space for the visited array."
          }
        }
      }
       
    ]
  } 
]
