[
  {
    "category": "Easy",
    "Problems": [
      {
        "Topic": "Array Concept",
        "Info": {
          "Definition": "An array is a data structure that contains a group of elements. Typically these elements are all of the same data type, such as an integer or string. Arrays are commonly used to organize data so that a related set of values can be easily sorted or searched.",
          "Algorithms": {
            "Traversal": "for(int i = 0; i < arr.length; i++) {\n  System.out.println(arr[i]);\n}",
            "Insertion": "for(int i = arr.length-1; i > position; i--) {\n  arr[i] = arr[i-1];\n}\narr[position] = newValue;",
            "Deletion": "for(int i = position; i < arr.length-1; i++) {\n  arr[i] = arr[i+1];\n}",
            "Search": "for(int i = 0; i < arr.length; i++) {\n  if(arr[i] == searchValue) {\n    return i;\n  }\n}\nreturn -1;",
            "Update": "arr[position] = newValue;"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1LM1odKi9usluN9pubVakhA1J3_tTrGMj",
            "https://drive.google.com/uc?export=view&id=1lSyjjvLdlMQZJYFrrBqL4mCachQT-q36"
          ],
          "Complexities": {
            "Time Complexities": {
              "Traversal": "O(n)",
              "Insertion": "O(n)",
              "Deletion": "O(n)",
              "Search": "O(n)",
              "Update": "O(1)"
            },
            "Space Complexity": "General : O(1)"
          }
        }
      },
      {
        "Topic": "Pointers",
        "Info": {
          "Definition": "A pointer is a variable that stores the memory address of another variable. Pointers are used for various purposes in programming, such as accessing array elements, dynamic memory allocation, and for referencing functions. Pointers are a powerful feature of languages like C and C++, offering both flexibility and complexity.",
          "Algorithms": {
            "Pointer Initialization": "int* ptr = &var;",
            "Pointer Dereferencing": "*ptr = 10;",
            "Pointer to Pointer": "int** ptr2 = &ptr;",
            "Dynamic Memory Allocation": "int* ptr = (int*)malloc(sizeof(int));",
            "Deallocation": "free(ptr);",
            "Array Access Through Pointers": "for(int i = 0; i < n; i++) {\n  printf(\"%d\\n\", *(arr + i));\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1p3Dy41V0s5dodq6g0iG5YMSbChuX5_I4"
          ],
          "Complexities": {
            "Time Complexities": {
              "Pointer Initialization": "O(1)",
              "Pointer Dereferencing": "O(1)",
              "Pointer to Pointer": "O(1)",
              "Dynamic Memory Allocation": "O(1) for allocation and deallocation",
              "Array Access Through Pointers": "O(n)"
            },
            "Space Complexity": "O(1) for static allocation, varies for dynamic allocation"
          }
        }
      },
      {
        "Topic": "Dynamic Memory Allocation",
        "Info": {
          "Definition": "Dynamic memory allocation refers to the process of allocating memory at runtime, as opposed to static memory allocation where memory size must be specified at compile time. This allows for more flexible memory usage, enabling programs to use memory as needed during execution. Common operations include allocating, reallocating, and freeing memory.",
          "Algorithms": {
            "Allocation (malloc)": "void* ptr = malloc(size);",
            "Deallocation (free)": "free(ptr);",
            "Reallocation (realloc)": "ptr = realloc(ptr, newSize);",
            "Allocation for arrays (calloc)": "void* ptr = calloc(nItems, sizeOfEachItem);"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=17Z9PJV-sMET3xfnbEOiHsZlAvm83MlUt"
          ],
          "Complexities": {
            "Time Complexities": {
              "Allocation (malloc)": "O(1), but depends on the system's memory manager",
              "Deallocation (free)": "O(1), but can vary based on implementation",
              "Reallocation (realloc)": "O(n), as it may involve copying memory if the new size cannot be accommodated at the current location",
              "Allocation for arrays (calloc)": "O(n), as it initializes all bits to zero"
            },
            "Space Complexity": "O(n), where n is the amount of requested memory"
          }
        }
      },
      {
        "Topic": "Linear Search",
        "Info": {
          "Definition": "Linear Search is a searching algorithm that finds the position of a target value within an array. It sequentially checks each element of the array for the target value until a match is found or until all the elements have been searched.",
          "Algorithms": {
            "Basic Method": "for ( int i = 0; i < arr.length; i++ ){\n  if ( arr[i] == x )\n    return i;\nreturn -1;"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=15HNcatCOfEE7oCj4jaEEjKl3fhC6rKXy"
          ],
          "Complexities": {
            "Time Complexities": {
              "Best case": "O(1)",
              "Average case": "O(n)",
              "Worst case": "O(n)"
            },
            "Space Complexity": "The space complexity of the linear search is O(1)."
          }
        }
      },
      {
        "Topic": "Binary Search",
        "Info": {
          "Definition": "Binary Search is a searching algorithm for finding an element's position in a sorted array. In this approach, the element is always searched in the middle of a portion of an array. Binary search can be implemented only on a sorted list of items. If the elements are not sorted already, we need to sort them first.",
          "Algorithms": {
            "Iterative Method": "do {\n  mid = (low + high) / 2;\n  if (x == arr[mid]) {\n    return mid;\n  } else if (x > arr[mid]) { // x is on the right side\n    low = mid + 1;\n  } else {                       // x is on the left side\n    high = mid - 1;\n  }\n} while (low <= high);",
            "Recursive Method": "int binarySearch(int arr[], int x, int low, int high) {\n  if (low > high) {\n    return -1; // Element not found\n  } else {\n    int mid = (low + high) / 2;\n    if (x == arr[mid]) {\n      return mid;\n    } else if (x > arr[mid]) { // x is on the right side\n      return binarySearch(arr, x, mid + 1, high);\n    } else {                          // x is on the left side\n      return binarySearch(arr, x, low, mid - 1);\n    }\n  }\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1WEQuxTJ7JP5kqhPza-g6FTrdeaB22zr6"
          ],
          "Complexities": {
            "Time Complexities": {
              "Best case": "O(1)",
              "Average case": "O(log n)",
              "Worst case": "O(log n)"
            },
            "Space Complexity": "The space complexity of the binary search is O(1)."
          }
        }
      },
      {
        "Topic": "Stack Data Structure",
        "Info": {
          "Definition": "A stack is a linear data structure that follows the principle of Last In First Out (LIFO). This means the last element inserted inside the stack is removed first.You can think of the stack data structure as the pile of plates on top of another.LIFO Principle of Stack :In programming terms, putting an item on top of the stack is called push and removing an item is called pop.",
          "Algorithms": {
            "Push Operation": "void push(int stack[], int *top, int maxsize, int newitem) {\n  if (*top == maxsize - 1) {\n    cout << \"STACK FULL\";\n  } else {\n    stack[++(*top)] = newitem;\n  }\n}",
            "Pop Operation": "int pop(int stack[], int *top) {\n  if (*top == -1) {\n    cout << \"STACK EMPTY\";\n    return -1;\n  } else {\n    return stack[(*top)--];\n  }\n}",
            "isEmpty Operation": "bool isEmpty(int *top) {\n  return *top == -1;\n}",
            "isFull Operation": "bool isFull(int *top, int maxsize) {\n  return *top == maxsize - 1;\n}",
            "Peek Operation": "int peek(int stack[], int *top) {\n  if (*top == -1) {\n    cout << \"STACK EMPTY\";\n    return -1;\n  } else {\n    return stack[*top];\n  }\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1QmbVrM1BtUeSjDycjx8G_L61XtnVAb9R",
            "https://drive.google.com/uc?export=view&id=1h7BISI0pZ7bYuKdroH6FHiPFp-75N8T4"
          ],
          "Complexities": {
            "Time Complexities": {
              "Push": "O(1)",
              "isEmpty": "O(1)",
              "isFull": "O(1)",
              "Pop": "O(1)",
              "Peek": "O(1)"
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Stack Implementations (Using Arrays & Linked Lists)",
        "Info": {
          "Definition": "A stack is a linear data structure that follows the Last In First Out (LIFO) principle. Elements are added to and removed from the top of the stack. Stack implementations can use arrays or linked lists. An array-based stack has a fixed size, which limits its capacity, while a linked list-based stack can grow dynamically, allowing for more flexibility.",
          "Algorithms": {
            "Array-Based Stack Push": "void push(int x) {\n  if(top >= n-1) {\n    cout << \"Stack Overflow\";\n  } else {\n    arr[++top] = x;\n  }\n}",
            "Array-Based Stack Pop": "int pop() {\n  if(top <= -1) {\n    cout << \"Stack Underflow\";\n    return 0;\n  } else {\n    int x = arr[top--];\n    return x;\n  }\n}",
            "Array-Based Stack Peek": "int peek() {\n  if(top < 0) {\n    cout << \"Stack is Empty\";\n    return 0;\n  } else {\n    return arr[top];\n  }\n}",
            "Array-Based Stack Is Empty": "bool isEmpty() {\n  return (top < 0);\n}",
            "Array-Based Stack Is Full": "bool isFull() {\n  return (top >= n-1);\n}",
            "Linked List-Based Stack Push": "void push(int x) {\n  Node* newNode = new Node();\n  if (!newNode) {\n    cout << \"Heap Overflow\";\n  } else {\n    newNode->data = x;\n    newNode->next = top;\n    top = newNode;\n  }\n}",
            "Linked List-Based Stack Pop": "int pop() {\n  if (top == nullptr) {\n    cout << \"Stack Underflow\";\n    return 0;\n  } else {\n    Node* temp = top;\n    top = top->next;\n    int popped = temp->data;\n    delete temp;\n    return popped;\n  }\n}",
            "Linked List-Based Stack Peek": "int peek() {\n  if (top == nullptr) {\n    cout << \"Stack is Empty\";\n    return 0;\n  } else {\n    return top->data;\n  }\n}",
            "Linked List-Based Stack Is Empty": "bool isEmpty() {\n  return (top == nullptr);\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1eF9qNIRjkVqFy4qfJf5NmX6dHTP9gzPM"
          ],
          "Complexities": {
            "Time Complexities": {
              "Array-Based Stack Operations": "O(1) - For push, pop, peek, isEmpty, and isFull operations",
              "Linked List-Based Stack Operations": "O(1) - For push, pop, peek, and isEmpty operations"
            },
            "Space Complexity": "O(n) - For both array and linked list implementations, depending on the number of elements in the stack"
          }
        }
      },
      {
        "Topic": "Balanced Parentheses",
        "Info": {
          "Definition": "The problem of balanced parentheses involves determining whether a string of parentheses (which can include characters '(', ')', '{', '}', '[' and ']') is balanced. A string is considered balanced if each type of bracket is closed in the correct order and matches with the corresponding opening bracket.",
          "Algorithms": {
            "Using Stack": "bool isBalanced(string s) {\n  stack<char> stk;\n  for (char c : s) {\n    if (c == '(' || c == '{' || c == '[') {\n      stk.push(c);\n    } else {\n      if (stk.empty()) return false;\n      if (c == ')' && stk.top() != '(') return false;\n      if (c == '}' && stk.top() != '{') return false;\n      if (c == ']' && stk.top() != '[') return false;\n      stk.pop();\n    }\n  }\n  return stk.empty();\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1MjH_FyrFbq6tdXBEH6srnDfUQi1uKwBW"
          ],
          "Complexities": {
            "Time Complexity": "O(n), where n is the length of the input string. Each character in the string is processed once.",
            "Space Complexity": "O(n), in the worst case, all characters are opening brackets and will be pushed onto the stack."
          }
        }
      },
      {
        "Topic": "Stack Applications (Expression Evaluation)",
        "Info": {
          "Definition": "Expression evaluation is a key application of stacks, enabling the processing of arithmetic expressions in various notations including infix, prefix (Polish notation), and postfix (Reverse Polish notation). This involves scanning the expression, using stacks to manage operands and operators, and systematically applying operators following precedence rules. It simplifies managing complex arithmetic expressions' order of operations and handling of parentheses.",
          "Algorithms": {
            "Infix to Postfix Conversion": "stack<char> opStack; \nstring postfix = \"\"; \nfor(char& c : infix) { \n  if(isOperand(c)) postfix += c; \n  else if(c == '(') opStack.push(c); \n  else if(c == ')') { \n    while(opStack.top() != '(') { \n      postfix += opStack.top(); \n      opStack.pop(); \n    } \n    opStack.pop(); \n  } \n  else { \n    while(!opStack.empty() && precedence(opStack.top()) >= precedence(c)) { \n      postfix += opStack.top(); \n      opStack.pop(); \n    } \n    opStack.push(c); \n  } \n} \nwhile(!opStack.empty()) { \n  postfix += opStack.top(); \n  opStack.pop(); \n}",
            "Postfix Expression Evaluation": "stack<int> valStack; \nfor(char& c : postfix) { \n  if(isDigit(c)) valStack.push(c - '0'); \n  else { \n    int b = valStack.top(); \n    valStack.pop(); \n    int a = valStack.top(); \n    valStack.pop(); \n    valStack.push(applyOp(a, b, c)); \n  } \n}",
            "Prefix to Postfix Conversion": "stack<string> s; \nfor(int i = prefix.length() - 1; i >= 0; i--) { \n  if(isOperand(prefix[i])) s.push(string(1, prefix[i])); \n  else { \n    string op1 = s.top(); \n    s.pop(); \n    string op2 = s.top(); \n    s.pop(); \n    s.push(op1 + op2 + prefix[i]); \n  } \n}",
            "Prefix to Infix Conversion": "stack<string> s; \nfor(int i = prefix.length() - 1; i >= 0; i--) { \n  if(isOperand(prefix[i])) s.push(string(1, prefix[i])); \n  else { \n    string op1 = s.top(); \n    s.pop(); \n    string op2 = s.top(); \n    s.pop(); \n    s.push('(' + op1 + prefix[i] + op2 + ')'); \n  } \n}",
            "Prefix Expression Evaluation": "stack<int> Stack; \nfor(int i = prefix.length() - 1; i >= 0; i--) { \n  if(isDigit(prefix[i])) Stack.push(prefix[i] - '0'); \n  else { \n    int op1 = Stack.top(); \n    Stack.pop(); \n    int op2 = Stack.top(); \n    Stack.pop(); \n    Stack.push(applyOp(prefix[i], op1, op2)); \n  } \n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1TKaZDEP9FIxaWTO6auUVLMwdlym4Mozv",
            "https://drive.google.com/uc?export=view&id=1X-fpMdr88MLckJ4-5RunO3mr_-6dRckO",
            "https://drive.google.com/uc?export=view&id=1tRVGkxojEAkCdbmcE8JKpnbjMgjfMbXS",
            "https://drive.google.com/uc?export=view&id=1mtgh5y8XElYUXw3mCSk6Q037RIutc4dD",
            "https://drive.google.com/uc?export=view&id=1oHOlpirtQsM8lVbWbh1L5mblYaJKPiXJ"
          ],
          "Complexities": {
            "Time Complexities": {
              "Infix to Postfix Conversion": "O(n)",
              "Postfix Expression Evaluation": "O(n)",
              "Prefix to Postfix Conversion": "O(n)",
              "Prefix to Infix Conversion": "O(n)",
              "Prefix Expression Evaluation": "O(n)"
            },
            "Space Complexity": "O(n) - Requires space proportional to the length of the expression for the stack(s)"
          }
        }
      },
      {
        "Topic": "Queue Data Structure",
        "Info": {
          "Definition": "A queue is a useful data structure in programming. It is similar to the ticket queue outside a cinema hall, where the first person entering the queue is the first person who gets the ticket.Queue follows the First In First Out (FIFO) rule - the item that goes in first is the item that comes out first.",
          "Algorithms": {
            "Enqueue Operation": "void enqueue(int item) {\n  if (isFull()) {\n    cout << \"Queue is full\";\n  } else {\n    rear = (rear + 1) % capacity;\n    arr[rear] = item;\n    count++;\n  }\n}",
            "Dequeue Operation": "int dequeue() {\n  if (isEmpty()) {\n    cout << \"Queue is empty\";\n    return INT_MIN;\n  } else {\n    int item = arr[front];\n    front = (front + 1) % capacity;\n    count--;\n    return item;\n  }\n}",
            "isEmpty Operation": "bool isEmpty() {\n  return (count == 0);\n}",
            "isFull Operation": "bool isFull() {\n  return (count == capacity);\n}",
            "Peek Opeartion": "int peek() {\n  if (isEmpty()) {\n    cout << \"Queue is empty\";\n    return INT_MIN;\n  } else {\n    return arr[front];\n  }\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1q2373rxm-wAbDIk-caknbqI0Dbe-MY_R",
            "https://drive.google.com/uc?export=view&id=1cf_rE0mDg9zPfqp1NQp0fkCbDois7UPi"
          ],
          "Complexities": {
            "Time Complexities": {
              "Enqueue": "O(1)",
              "Dequeue": "O(1)",
              "isEmpty": "O(1)",
              "isFull": "O(1)",
              "Peek": "O(1)"
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Queue Implementations (Using Arrays & Linked Lists)",
        "Info": {
          "Definition": "A queue is a linear data structure that follows the First In First Out (FIFO) principle. Elements are added at one end, known as the rear, and removed from the other end, known as the front. Queue implementations commonly use arrays or linked lists. Array-based queues have a fixed size, while linked list-based queues can grow dynamically.",
          "Algorithms": {
            "Array-Based Queue Enqueue": "void enqueue(int queue[], int& rear, int element, int SIZE) {\n  if(rear < SIZE) {\n    queue[rear++] = element;\n  }\n}",
            "Array-Based Queue Dequeue": "int dequeue(int queue[], int& front, int& rear) {\n  if(front < rear) {\n    int element = queue[front];\n    for(int i = 0; i < rear - 1; i++) {\n      queue[i] = queue[i + 1];\n    }\n    rear--;\n    return element;\n  }\n  return -1; // or some indicator of empty queue\n}",
            "Array-Based Queue Is Full": "bool isFull(int rear, int SIZE) {\n  return rear == SIZE;\n}",
            "Array-Based Queue Is Empty": "bool isEmpty(int rear) {\n  return rear == 0;\n}",
            "Linked List-Based Queue Enqueue": "void enqueue(Node*& front, Node*& rear, int element) {\n  Node* newNode = new Node(element);\n  if(front == nullptr) {\n    front = rear = newNode;\n  } else {\n    rear->next = newNode;\n    rear = newNode;\n  }\n}",
            "Linked List-Based Queue Dequeue": "int dequeue(Node*& front, Node*& rear) {\n  if(front != nullptr) {\n    Node* temp = front;\n    int element = front->data;\n    front = front->next;\n    delete temp;\n    if(front == nullptr) {\n      rear = nullptr;\n    }\n    return element;\n  }\n  return -1; // or some indicator of empty queue\n}",
            "Linked List-Based Queue Is Empty": "bool isEmpty(Node* front) {\n  return front == nullptr;\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=11OJBChw8EoVIajHG8W7LFCMQ9odfuC3K"
          ],
          "Complexities": {
            "Time Complexities": {
              "Array-Based Queue Enqueue": "O(1) - Amortized",
              "Array-Based Queue Dequeue": "O(n) - Due to shifting elements",
              "Array-Based Queue Is Full": "O(1)",
              "Array-Based Queue Is Empty": "O(1)",
              "Linked List-Based Queue Enqueue": "O(1)",
              "Linked List-Based Queue Dequeue": "O(1)",
              "Linked List-Based Queue Is Empty": "O(1)"
            },
            "Space Complexity": {
              "Array-Based Queue": "O(n) - Fixed size based on initial allocation",
              "Linked List-Based Queue": "O(n) - Dynamic, depends on the number of elements"
            }
          }
        }
      },
      {
        "Topic": "Circular Queue",
        "Info": {
          "Definition": "A circular queue is the extended version of a regular queue where the last element is connected to the first element. Thus forming a circle-like structure.The circular queue solves the major limitation of the normal queue. In a normal queue, after a bit of insertion and deletion, there will be non-usable empty space.",
          "Algorithms": {
            "Enqueue Operation": "void enqueue(int item) {\n  if (isFull()) {\n    cout << \"Queue is full\";\n  } else {\n    rear = (rear + 1) % capacity;\n    arr[rear] = item;\n    count++;\n  }\n}",
            "Dequeue Operation": "int dequeue() {\n  if (isEmpty()) {\n    cout << \"Queue is empty\";\n    return INT_MIN;\n  } else {\n    int item = arr[front];\n    front = (front + 1) % capacity;\n    count--;\n    return item;\n  }\n}",
            "isEmpty Operation": "bool isEmpty() {\n  return (count == 0);\n}",
            "isFull Operation": "bool isFull() {\n  return (count == capacity);\n}",
            "Peek Opeartion": "int peek() {\n  if (isEmpty()) {\n    cout << \"Queue is empty\";\n    return INT_MIN;\n  }\n  return arr[front];\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1ggIpJ7Yxm5wl8MrWxZDIqSR9rgswLMBE",
            "https://drive.google.com/uc?export=view&id=1aXkZHMFjGwbTF3v2K-G1GOnQNrG877yt"
          ],
          "Complexities": {
            "Time Complexities": {
              "Enqueue": "O(1)",
              "Dequeue": "O(1)",
              "isEmpty": "O(1)",
              "isFull": "O(1)",
              "Peek": "O(1)"
            },
            "Space Complexity": "O(n)"
          }
        }
      },
      {
        "Topic": "Bubble Sort",
        "Info": {
          "Definition": "Bubble Sort is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order. The pass through the list is repeated until the list is sorted.",
          "Algorithms": {
            "Code": "void bubbleSort(int arr[], int n) {\n  for (int i = 0; i < n-1; i++) {\n    for (int j = 0; j < n-i-1; j++) {\n      if (arr[j] > arr[j+1]) {\n        swap(arr[j], arr[j+1]);\n      }\n    }\n  }\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1dptA2sS5yql0BQfCFcRZHuEv1KbnLZ3E"
          ],
          "Complexities": {
            "Time Complexities": {
              "Worst and Average Case": "O(n^2)",
              "Best Case": "O(n) when the array is already sorted"
            },
            "Space Complexity": "O(1) - Only requires a constant amount of additional space."
          }
        }
      },
      {
        "Topic": "Insertion Sort",
        "Info": {
          "Definition": "Insertion Sort is a simple sorting algorithm that builds the final sorted array one item at a time. It is much less efficient on large lists than more advanced algorithms such as quicksort, heapsort, or merge sort.",
          "Algorithms": {
            "Code": "void insertionSort(int arr[], int n) {\n  int i, key, j;\n  for (i = 1; i < n; i++) {\n    key = arr[i];\n    j = i - 1;\n    while (j >= 0 && arr[j] > key) {\n      arr[j + 1] = arr[j];\n      j = j - 1;\n    }\n    arr[j + 1] = key;\n  }\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1-oTAZslttkv6epIW3Brwy-hYZpyD_J5D"
          ],
          "Complexities": {
            "Time Complexities": {
              "Worst and Average Case": "O(n^2)",
              "Best Case": "O(n) when the array is already sorted"
            },
            "Space Complexity": "O(1) - It is an in-place sorting algorithm."
          }
        }
      },
      {
        "Topic": "Selection Sort",
        "Info": {
          "Definition": "Selection Sort is an in-place comparison sorting algorithm. It divides the input list into two parts: a sorted sublist of items which is built up from left to right at the front of the list, and a sublist of the remaining unsorted items that occupy the rest of the list. Initially, the sorted sublist is empty and the unsorted sublist is the entire input list. The algorithm proceeds by finding the smallest (or largest, depending on sorting order) element in the unsorted sublist, swapping it with the leftmost unsorted element, and moving the sublist boundaries one element to the right.",
          "Algorithms": {
            "Code": "void selectionSort(int arr[], int n) {\n  int i, j, min_idx;\n  for (i = 0; i < n-1; i++) {\n    min_idx = i;\n    for (j = i+1; j < n; j++) {\n      if (arr[j] < arr[min_idx]) {\n        min_idx = j;\n      }\n    }\n    swap(arr[min_idx], arr[i]);\n  }\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1rtI8jGVEJ1ksrT-NbgARehj6rM3aHCJV"
          ],
          "Complexities": {
            "Time Complexities": "Worst, Average, and Best Case: O(n^2), as it always runs O(n^2) operations regardless of the input.",
            "Space Complexity": "O(1) - Like bubble sort and insertion sort, selection sort also uses a constant amount of additional space."
          }
        }
      },
      {
        "Topic": "Fibonacci Sequence",
        "Info": {
          "Definition": "The Fibonacci sequence is a series of numbers where each number is the sum of the two preceding ones, usually starting with 0 and 1. It's a classic example demonstrating the power of Dynamic Programming in reducing the computational complexity of recursive algorithms.",
          "Algorithms": {
            "Code": "int fib(int n) {\n  if (n <= 1) return n;\n  vector<int> f(n + 1, 0);\n  f[1] = 1;\n  for (int i = 2; i <= n; i++) {\n    f[i] = f[i - 1] + f[i - 2];\n  }\n  return f[n];\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1nVytAoPzdnl-CjxeTH6XaTgFN7xMbXFJ"
          ],
          "Complexities": {
            "Time Complexity": "O(n) - Linear, as it iterates once up to n.",
            "Space Complexity": "O(n) - For storing the Fibonacci sequence up to n."
          }
        }
      },
      {
        "Topic": "Singly Linked List",
        "Info": {
          "Definition": "A singly linked list is a type of linked list in which each node points to the next node in the list and the last node points to null. It allows for efficient insertion and removal of elements from any position in the sequence.",
          "Algorithms": {
            "Insertion at End": "void insertAtEnd(Node** head, int newData) {\n  Node* newNode = new Node();\n  newNode->data = newData;\n  newNode->next = NULL;\n  if (*head == NULL) {\n    *head = newNode;\n    return;\n  }\n  Node* last = *head;\n  while (last->next != NULL) {\n    last = last->next;\n  }\n  last->next = newNode;\n}",
            "Insertion at Front": "void insertAtFront(Node** head, int newData) {\n  Node* newNode = new Node();\n  newNode->data = newData;\n  newNode->next = *head;\n  *head = newNode;\n}",
            "Deletion by Key": "void deleteByKey(Node** head, int key) {\n  Node* temp = *head, *prev = NULL;\n  if (temp != NULL && temp->data == key) {\n    *head = temp->next;\n    delete temp;\n    return;\n  }\n  while (temp != NULL && temp->data != key) {\n    prev = temp;\n    temp = temp->next;\n  }\n  if (temp == NULL) return;\n  prev->next = temp->next;\n  delete temp;\n}",
            "Search for an Element": "bool search(Node* head, int key) {\n  Node* current = head;\n  while (current != NULL) {\n    if (current->data == key) return true;\n    current = current->next;\n  }\n  return false;\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1zPqwMsjjQdAgyu6vXWZi-enb5AA3Q99V",
            "https://drive.google.com/uc?export=view&id=1zRM4AKmbMdeDLGahkGWcz9QBI9C2ex7G"
          ],
          "Complexities": {
            "Time Complexity": {
              "Insertion at End": "O(n)",
              "Insertion at Front": "O(1)",
              "Deletion by Key": "O(n)",
              "Search for an Element": "O(n)"
            },
            "Space Complexity": {
              "Overall": "O(n) - Storing n elements."
            }
          }
        }
      },
      {
        "Topic": "Doubly Linked List",
        "Info": {
          "Definition": "A doubly linked list is a type of linked list in which each node contains two links: one pointing to the next node and one to the previous node. This allows for efficient insertion and removal from both ends of the list.",
          "Algorithms": {
            "Insertion at End": "void insertAtEnd(DoubleNode** head, int newData) {\n  DoubleNode* newNode = new DoubleNode();\n  newNode->data = newData;\n  newNode->next = NULL;\n  if (*head == NULL) {\n    newNode->prev = NULL;\n    *head = newNode;\n    return;\n  }\n  DoubleNode* last = *head;\n  while (last->next != NULL) {\n    last = last->next;\n  }\n  last->next = newNode;\n  newNode->prev = last;\n}",
            "Insertion at Front": "void insertAtFront(DoubleNode** head, int newData) {\n  DoubleNode* newNode = new DoubleNode();\n  newNode->data = newData;\n  newNode->next = *head;\n  newNode->prev = NULL;\n  if (*head != NULL) {\n    (*head)->prev = newNode;\n  }\n  *head = newNode;\n}",
            "Deletion by Key": "void deleteByKey(DoubleNode** head, int key) {\n  DoubleNode* temp = *head;\n  if (temp != NULL && temp->data == key) {\n    *head = temp->next;\n    if (temp->next != NULL) temp->next->prev = temp->prev;\n    delete temp;\n    return;\n  }\n  while (temp != NULL && temp->data != key) {\n    temp = temp->next;\n  }\n  if (temp == NULL) return;\n  if (temp->next != NULL) temp->next->prev = temp->prev;\n  if (temp->prev != NULL) temp->prev->next = temp->next;\n  delete temp;\n}",
            "Search for an Element": "bool search(DoubleNode* head, int key) {\n  DoubleNode* current = head;\n  while (current != NULL) {\n    if (current->data == key) return true;\n    current = current->next;\n  }\n  return false;\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1-voQ4OzBVUvEO0gQeEIoNrwpl_phMqTA",
            "https://drive.google.com/uc?export=view&id=1PpbOm8IbJKLU2w73-V1Nwsr1vpoYj4DC"
          ],
          "Complexities": {
            "Time Complexity": {
              "Insertion at End": "O(n)",
              "Insertion at Front": "O(1)",
              "Deletion by Key": "O(n)",
              "Search for an Element": "O(n)"
            },
            "Space Complexity": {
              "Overall": "O(n) - Storing n elements, but requires additional space for the previous link in each node."
            }
          }
        }
      },
      {
        "Topic": "Circular Linked List",
        "Info": {
          "Definition": "A circular linked list is a type of linked list where all nodes are connected to form a circle. There is no NULL at the end. It can be implemented as a singly circular linked list or doubly circular linked list.",
          "Algorithms": {
            "Insertion at End": "void insertAtEnd(CircularNode** head, int newData) {\n  CircularNode* newNode = new CircularNode();\n  newNode->data = newData;\n  if (*head == NULL) {\n    newNode->next = newNode;\n    *head = newNode;\n  } else {\n    CircularNode* last = *head;\n    while (last->next != *head) {\n      last = last->next;\n    }\n    last->next = newNode;\n    newNode->next = *head;\n  }\n}",
            "Insertion at Front": "void insertAtFront(CircularNode** head, int newData) {\n  CircularNode* newNode = new CircularNode();\n  CircularNode* last = *head;\n  newNode->data = newData;\n  if (*head == NULL) {\n    newNode->next = newNode;\n    *head = newNode;\n  } else {\n    while (last->next != *head) {\n      last = last->next;\n    }\n    newNode->next = *head;\n    last->next = newNode;\n    *head = newNode;\n  }\n}",
            "Deletion by Key": "void deleteByKey(CircularNode** head, int key) {\n  if (*head == NULL) return;\n  CircularNode *temp = *head, *prev = NULL;\n  if (temp->data == key && temp->next == *head) {\n    *head = NULL;\n    delete temp;\n    return;\n  }\n  do {\n    if (temp->data == key) break;\n    prev = temp;\n    temp = temp->next;\n  } while (temp != *head);\n  if (temp->data == key) {\n    if (prev != NULL) prev->next = temp->next;\n    if (temp == *head) *head = prev->next;\n    delete temp;\n  }\n}",
            "Search for an Element": "bool search(CircularNode* head, int key) {\n  CircularNode* current = head;\n  if (current == NULL) return false;\n  do {\n    if (current->data == key) return true;\n    current = current->next;\n  } while (current != head);\n  return false;\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1jPJN9CKBwdZpnwvRGmnfnnAqlWjY_TTz",
            "https://drive.google.com/uc?export=view&id=1mXFmvvZjteEilD6FfTXeJor9B9Poph4B"
          ],
          "Complexities": {
            "Time Complexity": {
              "Insertion at End": "O(n)",
              "Insertion at Front": "O(n)",
              "Deletion by Key": "O(n)",
              "Search for an Element": "O(n)"
            },
            "Space Complexity": {
              "Overall": "O(n) - Storing n elements. Similar to singly or doubly linked lists but forms a circle."
            }
          }
        }
      },
      {
        "Topic": "Breadth-First Search (BFS) Algorithm",
        "Info": {
          "Definition": "Breadth-First Search (BFS) is an algorithm for traversing or searching tree or graph data structures. It starts at a selected node and explores all of the neighbor nodes at the present depth prior to moving on to the nodes at the next depth level.",
          "Algorithms": {
            "Code": "void bfs(int s, vector<int>& adj, vector<bool>& visited) {\n  queue<int> queue;\n  visited[s] = true;\n  queue.push(s);\n  while (!queue.empty()) {\n    int s = queue.front();\n    queue.pop();\n    cout << s << ' ';\n    for (auto u : adj[s]) {\n      if (!visited[u]) {\n        visited[u] = true;\n        queue.push(u);\n      }\n    }\n  }\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1gqD0hT_5ybCbXB9DJMba870MTttqK4ym"
          ],
          "Complexities": {
            "Time Complexity": "O(V+E) - Where V is the number of vertices and E is the number of edges.",
            "Space Complexity": "O(V) - Due to the storage of vertices in the queue."
          }
        }
      },
      {
        "Topic": "Depth-First Search (DFS) Algorithm",
        "Info": {
          "Definition": "Depth-First Search (DFS) is an algorithm for traversing or searching tree or graph data structures. The algorithm starts at the root node and explores as far as possible along each branch before backtracking.",
          "Algorithms": {
            "Code": "void dfs(int v, vector<int>& adj, vector<bool>& visited) {\n  visited[v] = true;\n  cout << v << ' ';\n  for(int u : adj[v]) {\n    if(!visited[u]) {\n      dfs(u, adj, visited);\n    }\n  }\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1oGpdaqspMy6waNlolrkjRWP9lRe7eGSF"
          ],
          "Complexities": {
            "Time Complexity": "O(V+E) - Where V is the number of vertices and E is the number of edges.",
            "Space Complexity": "O(V) - Due to the usage of the call stack in recursion."
          }
        }
      },
      {
        "Topic": "Bit Manipulation",
        "Info": {
          "Definition": "Bit manipulation involves the use of bitwise operations to directly manipulate individual bits of a binary number. This technique is useful for tasks such as setting, clearing, toggling, and testing bits, and is often utilized for optimization, as it can be more efficient than arithmetic operations.",
          "Algorithms": {
            "Set a Bit": "number |= 1 << x;",
            "Clear a Bit": "number &= ~(1 << x);",
            "Toggle a Bit": "number ^= 1 << x;",
            "Check a Bit": "(number & (1 << x)) != 0;",
            "Count Set Bits": "int countSetBits(int n) {\n  int count = 0;\n  while (n) {\n    count += n & 1;\n    n >>= 1;\n  }\n  return count;\n}",
            "Find the Rightmost Set Bit": "int rsb = n & -n;",
            "Turn Off the Rightmost Set Bit": "n = n & (n - 1);"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1D2E8yWAk7dHNPpwajBNBLz6xJJHqKI7k",
            "https://drive.google.com/uc?export=view&id=1sXlYzhY02nTh5UbOFJsPdSj2bsltGjGs",
            "https://drive.google.com/uc?export=view&id=1Ssr_IZGuwYt2ofWxWkpgooge3idnE8tl",
            "https://drive.google.com/uc?export=view&id=1U7ejo7kplqRGU-tl_lgGGLGsN2XWzQto",
            "https://drive.google.com/uc?export=view&id=1fiCv9Pjvebqpb4c3utq3f2erdUAOpgOE",
            "https://drive.google.com/uc?export=view&id=1ij4dDjSOG1wfDZIAppUDxBCMx8rkpbrq",
            "https://drive.google.com/uc?export=view&id=1Q9ziaGHiLu0i_P4KUQnpTxeu2EuM3_vM"
          ],
          "Complexities": {
            "Time Complexities": {
              "Set a Bit": "O(1)",
              "Clear a Bit": "O(1)",
              "Toggle a Bit": "O(1)",
              "Check a Bit": "O(1)",
              "Count Set Bits": "O(log n)",
              "Find the Rightmost Set Bit": "O(1)",
              "Turn Off the Rightmost Set Bit": "O(1)"
            },
            "Space Complexity": "O(1)"
          }
        }
      },
      {
        "Topic": "Two Pointer Technique",
        "Info": {
          "Definition": "The two-pointer technique involves using two pointers to traverse an array, usually in a single pass, to solve problems such as finding a pair that sums up to a target value or identifying whether a sequence is a palindrome. This technique can significantly reduce the time complexity from O(n^2) to O(n) for certain problems by eliminating the need for nested loops.",
          "Algorithms": {
            "Find a Pair with a Given Sum": "while(left < right) {\n  int currentSum = arr[left] + arr[right];\n  if(currentSum == targetSum) {\n    return [left, right];\n  } else if(currentSum < targetSum) {\n    left++;\n  } else {\n    right--;\n  }\n}",
            "Check for Palindrome": "while(left < right) {\n  if(arr[left] != arr[right]) {\n    return false;\n  }\n  left++;\n  right--;\n}\nreturn true;",
            "Remove Duplicates from Sorted Array": "int i = 0;\nfor (int j = 1; j < n; j++) {\n  if (arr[j] != arr[i]) {\n    i++;\n    arr[i] = arr[j];\n  }\n}\nreturn i + 1;",
            "Reverse Array": "int start = 0, end = n - 1;\nwhile(start < end) {\n  int temp = arr[start];\n  arr[start] = arr[end];\n  arr[end] = temp;\n  start++;\n  end--;\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1LR4zAnSUfOmT8XzjOMPsikXIe3bouOfs",
            "https://drive.google.com/uc?export=view&id=12ww6QY5HUu0UOu_aFJSsjut778OP80Of",
            "https://drive.google.com/uc?export=view&id=15rGjHvt34SLSA5HQ4U-QdTv4xHFpRBgN",
            "https://drive.google.com/uc?export=view&id=1weZBfafEh5BSYrH1Oh7XytkC_Qq7wAYr"
          ],
          "Complexities": {
            "Time Complexities": {
              "Find a Pair with a Given Sum": "O(n)",
              "Check for Palindrome": "O(n)",
              "Remove Duplicates from Sorted Array": "O(n)",
              "Reverse Array": "O(n)"
            },
            "Space Complexity": "O(1) - no additional space required apart from the input array"
          }
        }
      },
      {
        "Topic": "Sliding Window Technique",
        "Info": {
          "Definition": "The sliding window technique involves creating a window that slides over the data structure (such as an array or a string) to consider subarrays/substrings of varying sizes. This technique is particularly useful for finding the longest or shortest subarray/substring that meets certain criteria, and it can significantly improve efficiency by reducing the time complexity from O(n^2) to O(n) for many problems.",
          "Algorithms": {
            "Maximum Sum Subarray of Size K": "int maxSum = 0, windowSum = 0;\nint windowStart = 0;\nfor(int windowEnd = 0; windowEnd < arr.length; windowEnd++) {\n  windowSum += arr[windowEnd];\n  if(windowEnd >= K - 1) {\n    maxSum = Math.max(maxSum, windowSum);\n    windowSum -= arr[windowStart];\n    windowStart++;\n  }\n}",
            "Longest Substring Without Repeating Characters": "int start = 0, maxLength = 0;\nMap<Character, Integer> charIndexMap = new HashMap<>();\nfor(int end = 0; end < s.length(); end++) {\n  char rightChar = s.charAt(end);\n  if(charIndexMap.containsKey(rightChar)) {\n    start = Math.max(start, charIndexMap.get(rightChar) + 1);\n  }\n  charIndexMap.put(rightChar, end);\n  maxLength = Math.max(maxLength, end - start + 1);\n}",
            "Minimum Size Subarray Sum": "int start = 0, minLength = Integer.MAX_VALUE, windowSum = 0;\nfor(int end = 0; end < arr.length; end++) {\n  windowSum += arr[end];\n  while(windowSum >= targetSum) {\n    minLength = Math.min(minLength, end - start + 1);\n    windowSum -= arr[start];\n    start++;\n  }\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=10PTo1_M1RUo8xDw8A9soiQV6yqYWja4s"
          ],
          "Complexities": {
            "Time Complexities": {
              "Maximum Sum Subarray of Size K": "O(n)",
              "Longest Substring Without Repeating Characters": "O(n)",
              "Minimum Size Subarray Sum": "O(n)"
            },
            "Space Complexity": {
              "Maximum Sum Subarray of Size K": "O(1)",
              "Longest Substring Without Repeating Characters": "O(min(m, n)) - where m is the size of the character set",
              "Minimum Size Subarray Sum": "O(1)"
            }
          }
        }
      },
      {
        "Topic": "Matrix Operations",
        "Info": {
          "Definition": "Matrix operations include a variety of arithmetic and algebraic operations performed on matrices, which are rectangular arrays of numbers, symbols, or expressions arranged in rows and columns. Common operations include addition, subtraction, multiplication, transposition, and finding the determinant and inverse of a matrix. These operations are fundamental in linear algebra and are widely applied in scientific computing, engineering, and computer graphics.",
          "Algorithms": {
            "Matrix Addition": "for(int i = 0; i < rows; i++) {\n  for(int j = 0; j < cols; j++) {\n    result[i][j] = matA[i][j] + matB[i][j];\n  }\n}",
            "Matrix Subtraction": "for(int i = 0; i < rows; i++) {\n  for(int j = 0; j < cols; j++) {\n    result[i][j] = matA[i][j] - matB[i][j];\n  }\n}",
            "Matrix Multiplication": "for(int i = 0; i < rowsA; i++) {\n  for(int j = 0; j < colsB; j++) {\n    for(int k = 0; k < colsA; k++) {\n      result[i][j] += matA[i][k] * matB[k][j];\n    }\n  }\n}",
            "Matrix Transpose": "for(int i = 0; i < rows; i++) {\n  for(int j = 0; j < cols; j++) {\n    transpose[j][i] = matrix[i][j];\n  }\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=15RF6OjLNKSVp3J3i6fonI53TA6VPqM2R",
            "https://drive.google.com/uc?export=view&id=1mFvJeSgkBqQOaOwV7RNo1-f36oaYEHQv",
            "https://drive.google.com/uc?export=view&id=1NUrkPwdydz4k1047nV1u3utofPxSrXjT",
            "https://drive.google.com/uc?export=view&id=1JAzPLvwlYM-RCusn5-aSHCnhCA4DQkrH"
          ],
          "Complexities": {
            "Time Complexities": {
              "Matrix Addition/Subtraction": "O(n*m) - where n and m are the dimensions of the matrices",
              "Matrix Multiplication": "O(n^3) using the standard algorithm, but can be reduced with more advanced algorithms like Strassen's algorithm",
              "Matrix Transpose": "O(n*m) - where n and m are the dimensions of the matrix"
            },
            "Space Complexity": {
              "General": "O(n*m) - Additional space needed for the resulting matrix, where n and m are the dimensions of the input matrices"
            }
          }
        }
      },
      {
        "Topic": "Determinant of a Matrix",
        "Info": {
          "Definition": "The determinant of a matrix is a scalar value that can be computed from the elements of a square matrix and encapsulates certain properties of the matrix. It is often used in linear algebra, system of equations, geometry, and analysis to determine the scaling factor of linear transformations, solve systems of linear equations, and in criteria for invertibility of matrices.",
          "Algorithms": {
            "Recursive Determinant Calculation": "float determinant(float** matrix, int n) {\n  float det = 0;\n  if (n == 1) return matrix[0][0];\n  float** subMatrix = new float*[n-1];\n  for (int i = 0; i < n-1; i++) subMatrix[i] = new float[n-1];\n  int sign = 1;\n  for (int f = 0; f < n; f++) {\n    int subi = 0;\n    for (int i = 1; i < n; i++) {\n      int subj = 0;\n      for (int j = 0; j < n; j++) {\n        if (j == f) continue;\n        subMatrix[subi][subj] = matrix[i][j];\n        subj++;\n      }\n      subi++;\n    }\n    det += sign * matrix[0][f] * determinant(subMatrix, n - 1);\n    sign = -sign;\n  }\n  for (int i = 0; i < n-1; i++) delete[] subMatrix[i];\n  delete[] subMatrix;\n  return det;\n}",
            "Laplace's Expansion": "float laplaceDeterminant(float** matrix, int n) {\n  if (n == 1) return matrix[0][0];\n  float det = 0;\n  float** subMatrix = new float*[n-1];\n  // Initialize submatrix\n  for (int i = 0; i < n-1; i++) subMatrix[i] = new float[n-1];\n  for (int x = 0; x < n; x++) {\n    int subi = 0;\n    for (int i = 1; i < n; i++) {\n      int subj = 0;\n      for (int j = 0; j < n; j++) {\n        if (j == x) continue;\n        subMatrix[subi][subj++] = matrix[i][j];\n      }\n      subi++;\n    }\n    det += (x % 2 == 0 ? 1 : -1) * matrix[0][x] * laplaceDeterminant(subMatrix, n-1);\n  }\n  // Free submatrix memory\n  return det;\n}",
            "LU Decomposition Algorithm": "void LUdecomposition(float** matrix, int n, float& det) {\n  float** L = new float*[n];\n  float** U = new float*[n];\n  for (int i = 0; i < n; i++) {\n    L[i] = new float[n];\n    U[i] = new float[n];\n  }\n\n  // Initialize L and U\n  for (int i = 0; i < n; i++) {\n    for (int j = 0; j < n; j++) {\n      if (j < i) L[j][i] = 0;\n      else {\n        L[j][i] = matrix[j][i];\n        for (int k = 0; k < i; k++) {\n          L[j][i] -= L[j][k] * U[k][i];\n        }\n      }\n      if (j < i) U[i][j] = 0;\n      else if (j == i) U[i][j] = 1;\n      else {\n        U[i][j] = matrix[i][j] / L[i][i];\n        for (int k = 0; k < i; k++) {\n          U[i][j] -= ((L[i][k] * U[k][j]) / L[i][i]);\n        }\n      }\n    }\n  }\n\n  det = 1;\n  for (int i = 0; i < n; i++) {\n    det *= U[i][i];\n  }\n\n  // Clean up\n}\n\nThis pseudo-code sketch omits many details necessary for a complete implementation, including pivot selection (Partial or Full Pivoting) for numerical stability. The actual determinant calculation post-decomposition is straightforward, multiplying the diagonal elements of U."
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1BWfokg9lKcRBEk286hGyIhBDJudF1CvL",
            "https://drive.google.com/uc?export=view&id=1djRtE6ZvBbt3p0pCfA8GVRWsR9RI-4lG",
            "https://drive.google.com/uc?export=view&id=1rkqeHYkcyBbfb-Z62uEncS-VPFdmCjns"
          ],
          "Complexities": {
            "Time Complexity": {
              "Recursive Calculation": "O(n!), where n is the matrix size.",
              "Laplace's Expansion": "O(n!), improved by optimizations in practical implementations but still exponential for large n.",
              "LU Decomposition": "O(n^3), primarily due to the three nested loops required to compute the elements of L and U."
            },
            "Space Complexity": {
              "Recursive Calculation": "O(n^2), for the storage of the submatrices created during the recursive calls. The actual space used also includes the stack space due to recursion, which can be significant for large n.",
              "Laplace's Expansion": "O(n^3), due to recursive storage requirements for submatrices.",
              "LU Decomposition": "O(n^2), needed for storing the L and U matrices in addition to the original matrix."
            }
          }
        }
      },
      {
        "Topic": "Inverse of a Matrix",
        "Info": {
          "Definition": "The inverse of a matrix A is the matrix that, when multiplied by A, produces the identity matrix. Computing the inverse is crucial for many applications in linear algebra, including solving systems of linear equations.",
          "Algorithms": {
            "Gaussian Elimination": "void inverseMatrixUsingGaussian(float** matrix, int n, float** inverse) {\n  // Initialize inverse matrix as identity\n  for(int i = 0; i < n; i++) {\n    for(int j = 0; j < n; j++) {\n      inverse[i][j] = (i == j) ? 1.0 : 0.0;\n    }\n  }\n  // Apply Gaussian Elimination\n  for(int i = 0; i < n; i++) {\n    float pivotValue = matrix[i][i];\n    for(int j = 0; j < n; j++) {\n      matrix[i][j] /= pivotValue;\n      inverse[i][j] /= pivotValue;\n    }\n    for(int k = 0; k < n; k++) {\n      if(k != i) {\n        float factor = matrix[k][i];\n        for(int j = 0; j < n; j++) {\n          matrix[k][j] -= factor * matrix[i][j];\n          inverse[k][j] -= factor * inverse[i][j];\n        }\n      }\n    }\n  }\n}",
            "Adjunct and Determinant Method": "void inverseMatrixUsingAdjunct(float** matrix, int n, float** inverse) {\n  // Assuming determinant() and adjugate() functions are defined elsewhere\n  float det = determinant(matrix, n);\n  if(det == 0) return; // Non-invertible matrix\n  float** cofactorMatrix = adjugate(matrix, n);\n  for(int i = 0; i < n; i++) {\n    for(int j = 0; j < n; j++) {\n      inverse[i][j] = cofactorMatrix[i][j] / det;\n    }\n  }\n  // Clean up cofactorMatrix\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1RoLxZb7qgL27p2gS-3tO1DVs_-oe7Epk",
            "https://drive.google.com/uc?export=view&id=1Byfs3Gn-yDArZXQVwET8I5dpr6r8YtxB"
          ],
          "Complexities": {
            "Time Complexity": {
              "Gaussian Elimination": "O(n^3), due to the row reduction and normalization steps required.",
              "Adjunct and Determinant Method": "O(n^4), mainly because of the determinant and adjugate matrix computation."
            },
            "Space Complexity": {
              "Gaussian Elimination": "O(n^2), for storing the augmented matrix and the inverse.",
              "Adjunct and Determinant Method": "O(n^2), required for the cofactor matrix and the inverse matrix."
            }
          }
        }
      },
      {
        "Topic": "Sparse Matrix",
        "Info": {
          "Definition": "A Sparse Matrix is a matrix in which most of the elements are zero. Storing only non-zero elements significantly reduces memory usage and computation time for operations on sparse matrices. Efficient storage and processing of sparse matrices are crucial in fields like scientific computing, graph theory, and engineering.",
          "Algorithms": {
            "Compressed Sparse Row (CSR) Storage": "void convertToCSR(int** matrix, int rows, int cols, vector<int>& values, vector<int>& rowPtr, vector<int>& colInd) {\n  int nnz = 0;\n  rowPtr.push_back(0);\n  for (int i = 0; i < rows; i++) {\n    for (int j = 0; j < cols; j++) {\n      if (matrix[i][j] != 0) {\n        values.push_back(matrix[i][j]);\n        colInd.push_back(j);\n        nnz++;\n      }\n    }\n    rowPtr.push_back(nnz);\n  }\n}\n\n This code creates three vectors: 'values' for storing the non-zero elements, 'colInd' for the column indices of these elements, and 'rowPtr' to indicate the start of each row in the values array. It's efficient for row-wise traversal and for arithmetic operations and transformations.",
            "Coordinate List (COO) Storage": "void convertToCOO(int** matrix, int rows, int cols, vector<int>& rowInd, vector<int>& colInd, vector<int>& values) {\n  for (int i = 0; i < rows; i++) {\n    for (int j = 0; j < cols; j++) {\n      if (matrix[i][j] != 0) {\n        rowInd.push_back(i);\n        colInd.push_back(j);\n        values.push_back(matrix[i][j]);\n      }\n    }\n  }\n}\n\nSimilar to CSR but stores the row indices explicitly in 'rowInd', making it suitable for incremental construction and random access."
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=12-0jMzEdYIWOEn81EzKrjxOioy09m2R8",
            "https://drive.google.com/uc?export=view&id=1tdWLhdqwv4xZ-7jtNPHNJzDySsRAwYux"
          ],
          "Complexities": {
            "Space Complexity": {
              "CSR": "O(2n + m), where n is the number of non-zero elements and m is the number of rows. Ideal for large sparse matrices.",
              "COO": "O(3n), where n is the number of non-zero elements. Efficient for incrementally constructed matrices."
            }
          }
        }
      },
      {
        "Topic": "Euclid's Algorithm",
        "Info": {
          "Definition": "Euclid's algorithm is an efficient method for computing the greatest common divisor (GCD) of two numbers, the largest number that divides both of them without leaving a remainder. The algorithm is based on the principle that the GCD of two numbers also divides their difference. Starting with two integers, it repeatedly replaces the larger number by its difference with the smaller number until one of them becomes zero. The non-zero number at this point is the GCD of the original two numbers.",
          "Algorithms": {
            "Iterative Version": "int gcd(int a, int b) {\n  while (b != 0) {\n    int temp = b;\n    b = a % b;\n    a = temp;\n  }\n  return a;\n}",
            "Recursive Version": "int gcd(int a, int b) {\n  if (b == 0)\n    return a;\n  return gcd(b, a % b);\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1O5dDL3yzsveibr5aIpI7yAiqxAfkhHW1",
            "https://drive.google.com/uc?export=view&id=1hvEzMKRvm97FttrdkwUczO7qnPlLtdXZ"
          ],
          "Complexities": {
            "Time Complexity": "O(log(min(a, b))), where a and b are the two numbers whose GCD is to be computed. This complexity arises from the number of divisions performed, which is effectively the length of the sequence of remainders.",
            "Space Complexity": {
              "Iterative Version": "O(1), as it uses a fixed amount of space.",
              "Recursive Version": "O(log(min(a, b))) due to the recursion stack."
            }
          }
        }
      }
    ]
  },
  {
    "category": "Medium",
    "Problems": [
      {
        "Topic": "Adjacency Matrix",
        "Info": {
          "Definition": "An adjacency matrix is a square matrix used to represent a finite graph. The elements of the matrix indicate whether pairs of vertices are adjacent or not in the graph. For a graph with N vertices, the matrix will be of size NxN, where the value of the element at the ith row and jth column indicates the presence of an edge between the ith and jth vertices.",
          "Algorithms": {
            "Creating an Adjacency Matrix": "void createAdjacencyMatrix(int** matrix, int numVertices, vector<pair<int, int>>& edges) {\n  for(int i = 0; i < numVertices; i++) {\n    for(int j = 0; j < numVertices; j++) {\n      matrix[i][j] = 0;\n    }\n  }\n  for(auto& edge : edges) {\n    int u = edge.first, v = edge.second;\n    matrix[u][v] = 1;\n    matrix[v][u] = 1; // For undirected graph\n  }\n}",
            "Adding an Edge": "void addEdge(int** matrix, int u, int v) {\n  matrix[u][v] = 1;\n  matrix[v][u] = 1; // For undirected graph\n}",
            "Removing an Edge": "void removeEdge(int** matrix, int u, int v) {\n  matrix[u][v] = 0;\n  matrix[v][u] = 0; // For undirected graph\n}",
            "Checking if Two Vertices are Adjacent": "bool isAdjacent(int** matrix, int u, int v) {\n  return matrix[u][v] == 1;\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1dxMeY7m1v3y7tgflrMF4al5inA4ok2LB"
          ],
          "Complexities": {
            "Time Complexity": {
              "Creating an Adjacency Matrix": "O(V^2), where V is the number of vertices, due to initializing the matrix and setting edges.",
              "Adding/Removing an Edge": "O(1), as it involves updating a single element in the matrix.",
              "Checking Adjacency": "O(1), involves a direct access operation."
            },
            "Space Complexity": {
              "Overall": "O(V^2), for storing the adjacency matrix, regardless of the number of edges in the graph."
            }
          }
        }
      },
      {
        "Topic": "Adjacency List",
        "Info": {
          "Definition": "An adjacency list is a collection of lists or arrays used to represent a finite graph. Each list corresponds to a vertex in the graph and contains the list of its adjacent vertices or edges. This representation is preferred for sparse graphs where the number of edges is much less than the square of the number of vertices, as it saves space compared to an adjacency matrix.",
          "Algorithms": {
            "Creating an Adjacency List": "void createAdjacencyList(vector<vector<int>>& adjList, int numVertices, vector<pair<int, int>>& edges) {\n  adjList.resize(numVertices);\n  for(auto& edge : edges) {\n    int u = edge.first, v = edge.second;\n    adjList[u].push_back(v);\n    adjList[v].push_back(u); // For undirected graph\n  }\n}",
            "Adding an Edge": "void addEdge(vector<vector<int>>& adjList, int u, int v) {\n  adjList[u].push_back(v);\n  adjList[v].push_back(u); // For undirected graph\n}",
            "Removing an Edge": "void removeEdge(vector<vector<int>>& adjList, int u, int v) {\n  // Removing edge involves finding the vertex in the list and erasing it\n  adjList[u].erase(remove(adjList[u].begin(), adjList[u].end(), v), adjList[u].end());\n  adjList[v].erase(remove(adjList[v].begin(), adjList[v].end(), u), adjList[v].end());\n}",
            "Checking if Two Vertices are Adjacent": "bool isAdjacent(const vector<vector<int>>& adjList, int u, int v) {\n  return find(adjList[u].begin(), adjList[u].end(), v) != adjList[u].end();\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1kh87M8ROtCqXZJ4GgiokoYSzTDcUyODu"
          ],
          "Complexities": {
            "Time Complexity": {
              "Creating an Adjacency List": "O(E), where E is the number of edges, for inserting each edge into the list.",
              "Adding an Edge": "O(1), as it involves appending to a list.",
              "Removing an Edge": "O(V), where V is the number of vertices, in the worst case when all vertices are adjacent.",
              "Checking Adjacency": "O(V), in the worst case, requires traversing the list of adjacent vertices."
            },
            "Space Complexity": {
              "Overall": "O(V+E), where V is the number of vertices and E is the number of edges, efficiently representing sparse graphs."
            }
          }
        }
      },
      {
        "Topic": "Boyer Moore Majority Vote Algorithm",
        "Info": {
          "Definition": "The Boyer-Moore Majority Vote Algorithm is an efficient algorithm to find the majority element in an array, which appears more than n/2 times. The algorithm operates by maintaining a count for a potential majority element and updating this count based on the examination of each element in the array. If the count becomes zero, the algorithm picks another candidate for the majority element and continues until it processes the entire array.",
          "Algorithms": {
            "Code": "int majorityElement(vector<int>& nums) {\n  int count = 0;\n  int candidate = 0;\n  for (int num : nums) {\n    if (count == 0) {\n      candidate = num;\n    }\n    count += (num == candidate) ? 1 : -1;\n  }\n  return candidate;\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1lJ-xyHWFWmSuYzKUirNGaXFzOTO6aWKs"
          ],
          "Complexities": {
            "Time Complexity": "O(n), where n is the number of elements in the array.",
            "Space Complexity": "O(1), as it uses a fixed amount of extra space."
          }
        }
      },
      {
        "Topic": "Quickselect Algorithm",
        "Info": {
          "Definition": "The Quickselect algorithm is a selection algorithm to find the kth smallest element in an unordered list. It is related to the QuickSort sorting algorithm. Like QuickSort, Quickselect was developed by Tony Hoare, and it works by choosing a 'pivot' element from the array and partitioning the other elements into two sub-arrays, according to whether they are less than or greater than the pivot. The partitioning continues until the pivot is in its final position of kth smallest element.",
          "Algorithms": {
            "Code": "int quickSelect(vector<int>& nums, int left, int right, int k) {\n  if (left == right) return nums[left];\n  int pivotIndex = partition(nums, left, right);\n  if (k == pivotIndex) return nums[k];\n  else if (k < pivotIndex) return quickSelect(nums, left, pivotIndex - 1, k);\n  else return quickSelect(nums, pivotIndex + 1, right, k);\n}",
            "Partition Function": "int partition(vector<int>& nums, int left, int right) {\n  int pivot = nums[right];\n  int i = left;\n  for (int j = left; j <= right - 1; j++) {\n    if (nums[j] < pivot) {\n      swap(nums[i], nums[j]);\n      i++;\n    }\n  }\n  swap(nums[i], nums[right]);\n  return i;\n}"
          },
          "imageLink": ["https://drive.google.com/uc?export=view&id=1QhY0Olm_SlT10iCRCcSGOeEUjp8tVewJ"],
          "Complexities": {
            "Time Complexity": "Average case: O(n), where n is the number of elements in the array. Worst case: O(n^2), but with good pivot selection, the average case is expected.",
            "Space Complexity": "O(1), the algorithm operates in-place."
          }
        }
      },
      {
        "Topic": "KMP Algorithm",
        "Info": {
          "Definition": "The Knuth-Morris-Pratt (KMP) Algorithm is used for substring search, which efficiently finds all occurrences of a word within a text, doing so in linear time. The key to KMP's performance is the construction of a 'partial match' table (also known as the 'failure function') that allows the algorithm to skip ahead at specific points where a mismatch occurs, avoiding unnecessary comparisons.",
          "Algorithms": {
            "KMP Search": "void KMPSearch(string pat, string txt) {\n  int M = pat.length();\n  int N = txt.length();\n  vector<int> lps(M, 0);\n  computeLPSArray(pat, M, lps);\n  int i = 0; // index for txt[]\n  int j = 0; // index for pat[]\n  while (i < N) {\n    if (pat[j] == txt[i]) {\n      j++;\n      i++;\n    }\n    if (j == M) {\n      cout << \"Found pattern at index \" << i - j;\n      j = lps[j - 1];\n    }\n    else if (i < N && pat[j] != txt[i]) {\n      if (j != 0) j = lps[j - 1];\n      else i = i + 1;\n    }\n  }\n}",
            "computeLPSArray": "void computeLPSArray(string pat, int M, vector<int>& lps) {\n  int len = 0;\n  lps[0] = 0; // lps[0] is always 0\n  int i = 1;\n  while (i < M) {\n    if (pat[i] == pat[len]) {\n      len++;\n      lps[i] = len;\n      i++;\n    } else {\n      if (len != 0) {\n        len = lps[len - 1];\n      } else {\n        lps[i] = 0;\n        i++;\n      }\n    }\n  }\n}"
          },
          "imageLink":["https://drive.google.com/uc?export=view&id=1ab1m8fcI6qP6Sp30KynE0rWW9Nsmax8w"],
          "Complexities": {
            "Time Complexity": "O(N+M), where N is the length of the text and M is the length of the pattern.",
            "Space Complexity": "O(M), for the LPS (Longest Prefix Suffix) array."
          }
        }
      },
      {
        "Topic": "Flood Fill Algorithm",
        "Info": {
          "Definition": "The Flood Fill algorithm is used to fill a connected region of a specific color with another color. It is similar to the 'bucket fill' tool in paint programs. The algorithm starts at a target pixel and changes the color of that pixel and all adjacent pixels of the same color. The process repeats recursively for each of the adjacent pixels, effectively 'flooding' the region with the new color.",
          "Algorithms": {
            "Code": "void floodFillUtil(vector<vector<int>>& screen, int x, int y, int prevC, int newC) {\n  // Base cases\n  if (x < 0 || x >= screen.size() || y < 0 || y >= screen[0].size()) return;\n  if (screen[x][y] != prevC) return;\n  if (screen[x][y] == newC) return;\n  // Replace the color at (x, y)\n  screen[x][y] = newC;\n  // Recur for north, east, south and west\n  floodFillUtil(screen, x+1, y, prevC, newC);\n  floodFillUtil(screen, x-1, y, prevC, newC);\n  floodFillUtil(screen, x, y+1, prevC, newC);\n  floodFillUtil(screen, x, y-1, prevC, newC);\n}",
            "Flood Fill": "void floodFill(vector<vector<int>>& screen, int x, int y, int newC) {\n  int prevC = screen[x][y];\n  if (prevC == newC) return;\n  floodFillUtil(screen, x, y, prevC, newC);\n}"
          },
          "imageLink":["https://drive.google.com/uc?export=view&id=1K3RvaitdT6_RHw2So091AxBczrEgPBQy"],
          "Complexities": {
            "Time Complexity": "O(n), where n is the number of pixels in the screen. In the worst case, all pixels will need to be visited.",
            "Space Complexity": "O(n), in the worst case, due to the recursion stack if all pixels need to be visited."
          }
        }
      },
      {
        "Topic": "Lee Algorithm",
        "Info": {
          "Definition": "Lee algorithm is a breadth-first search (BFS) based algorithm used for finding the shortest path in a maze or a grid, from a starting point to a target point, while avoiding obstacles. It explores all possible directions one step at a time, expanding outwards from the starting point until it reaches the target, effectively finding the shortest path.",
          "Algorithms": {
            "Lee Algorithm": "void leeAlgorithm(int grid[][], int startX, int startY, int endX, int endY) {\n  queue<pair<int, int>> q;\n  q.push({startX, startY});\n  grid[startX][startY] = 0; // Starting point\n  while (!q.empty()) {\n    pair<int, int> p = q.front();\n    q.pop();\n    int x = p.first, y = p.second;\n    // Check all 4 directions\n    for (int i = 0; i < 4; i++) {\n      int adjX = x + dx[i], adjY = y + dy[i];\n      // Check if valid move\n      if (isValid(adjX, adjY) && grid[adjX][adjY] == 1) {\n        grid[adjX][adjY] = grid[x][y] + 1;\n        q.push({adjX, adjY});\n        if (adjX == endX && adjY == endY) // Reached destination\n          return;\n      }\n    }\n  }\n}\n\n This pseudocode assumes 'grid' is a 2D array where 0 represents obstacles, 1 represents possible paths, and distances are marked as the algorithm progresses. 'dx' and 'dy' arrays define movement directions (up, down, left, right), and 'isValid' checks for valid moves within the grid boundaries and obstacle avoidance."
          },
          "imageLink":["https://drive.google.com/uc?export=view&id=1T7W14EXcudPfs6oyD8l38Mu6olU03QOw"],
          "Complexities": {
            "Time Complexity": "O(n*m), where n and m are the dimensions of the grid, since each cell is visited at most once.",
            "Space Complexity": "O(n*m), due to the queue potentially holding all cells in the worst case."
          }
        }
      },
      {
        "Topic": "Kadane's Algorithm",
        "Info": {
          "Definition": "Kadane's algorithm is used to find the maximum sum subarray from a given array of integers. This includes both the case where the array contains all negative numbers and the case of mixed positive and negative numbers. The algorithm scans the entire array by keeping track of the maximum sum subarray found so far and the current sum of elements from the start of the array.",
          "Algorithms": {
            "Code": "int maxSubArray(vector<int>& nums) {\n  int maxSoFar = nums[0], currentMax = nums[0];\n  for(int i = 1; i < nums.size(); i++) {\n    currentMax = max(nums[i], currentMax + nums[i]);\n    maxSoFar = max(maxSoFar, currentMax);\n  }\n  return maxSoFar;\n}"
          },
          "imageLink":["https://drive.google.com/uc?export=view&id=1rzq0qrys7qiaBpFDfIqvy6gYyPDM1Nuy"],
          "Complexities": {
            "Time Complexity": "O(n), where n is the number of elements in the array.",
            "Space Complexity": "O(1), as it requires a constant space regardless of the input size."
          }
        }
      },
      {
        "Topic": "Priority Queue",
        "Info": {
          "Definition": "A priority queue is a special type of queue in which each element is associated with a priority value. And, elements are served on the basis of their priority. That is, higher priority elements are served first.However, if elements with the same priority occur, they are served according to their order in the queue.",
          "Algorithms": {
            "Insert Operation": "void insert(int priority, int data) {\n  if (isFull()) {\n    cout << \"Priority Queue is full\";\n    return;\n  }\n  Node* newNode = new Node(priority, data);\n  if (isEmpty() || priority > front->priority) {\n    newNode->next = front;\n    front = newNode;\n  } else {\n    Node* temp = front;\n    while (temp->next != NULL && temp->next->priority >= priority) {\n      temp = temp->next;\n    }\n    newNode->next = temp->next;\n    temp->next = newNode;\n  }\n  size++;\n}",
            "Delete Operation": "void delete() {\n  if (isEmpty()) {\n    cout << \"Priority Queue is empty\";\n    return;\n  }\n  Node* temp = front;\n  front = front->next;\n  delete temp;\n  size--;\n}",
            "isEmpty Operation": "bool isEmpty() {\n  return (front == NULL);\n}",
            "isFull Operation": "bool isFull() {\n  void* temp = malloc(sizeof(Node));\n  if (temp == NULL) {\n    return true; // System cannot allocate more memory\n  }\n  free(temp); // Free the allocated memory\n  return false;\n}",
            "Peek Opeartion": "int peek() {\n  if (isEmpty()) {\n    cout << \"Priority Queue is empty\";\n    return INT_MIN;\n  }\n  return front->data;\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1aOHkH5UGM8Jh-hy71l3ed-ARz8xjcUbM",
            "https://drive.google.com/uc?export=view&id=1B9a0Glo1YagaCubDw2d70PvsjG0hB7IX"
          ],
          "Complexities": {
            "Time Complexities": {
              "Insert": "O(n) - In the worst case, we traverse the entire list.",
              "Delete": "O(1) - Deletion always occurs at the front.",
              "Peek": "O(1) - Peeking only looks at the front element.",
              "isEmpty": "O(1)",
              "isFull": "Depends on system memory availability. The check itself is O(1), but actual conditions may vary."
            },
            "Space Complexity": "O(n) - Storage grows with the number of elements."
          }
        }
      },
      {
        "Topic": "Deque Data Structure",
        "Info": {
          "Definition": "Deque or Double Ended Queue is a type of queue in which insertion and removal of elements can either be performed from the front or the rear. Thus, it does not follow FIFO rule (First In First Out).\nTypes of Deque:\nInput Restricted Deque:  In this deque, input is restricted at a single end but allows deletion at both the ends.\nOutput Restricted Deque:  In this deque, output is restricted at a single end but allows insertion at both the ends.",
          "Algorithms": {
            "Insert Operation": "void insert(int priority, int data) {\n  if (isFull()) {\n    cout << \"Priority Queue is full\";\n    return;\n  }\n  Node* newNode = new Node(priority, data);\n  if (isEmpty() || priority > front->priority) {\n    newNode->next = front;\n    front = newNode;\n  } else {\n    Node* temp = front;\n    while (temp->next != NULL && temp->next->priority >= priority) {\n      temp = temp->next;\n    }\n    newNode->next = temp->next;\n    temp->next = newNode;\n  }\n  size++;\n}",
            "Delete Operation": "void delete() {\n  if (isEmpty()) {\n    cout << \"Priority Queue is empty\";\n    return;\n  }\n  Node* temp = front;\n  front = front->next;\n  delete temp;\n  size--;\n}",
            "isEmpty Operation": "bool isEmpty() {\n  return (front == NULL);\n}",
            "isFull Operation": "bool isFull() {\n  Node* temp = new (nothrow) Node;\n  if (temp == nullptr) {\n    return true; // System cannot allocate more memory\n  }\n  delete temp;\n  return false;\n}",
            "Peek Opeartion": "int peek() {\n  if (isEmpty()) {\n    cout << \"Priority Queue is empty\";\n    return INT_MIN;\n  }\n  return front->data;\n}"
          },
          "imageLink": [
            "https://drive.google.com/uc?export=view&id=1RhYqy9AhzJu9bhDC2kvy_NfDXMcGkPo_",
            "https://drive.google.com/uc?export=view&id=1Rj14RvQSTNuVg1UJPS1EflhiFqM38FqK"
          ],
          "Complexities": {
            "Time Complexities": {
              "Insert": "O(n) - In the worst case, we traverse the entire list.",
              "Delete": "O(1) - Deletion always occurs at the front.",
              "Peek": "O(1) - Peeking only looks at the front element.",
              "isEmpty": "O(1)",
              "isFull": "Varies - Typically, it might depend on available system memory for dynamic data structures."
            },
            "Space Complexity": "O(n) - Space complexity grows linearly with the number of elements in the deque."
          }
        }
      },
      {
        "Topic": "Perfect Binary Tree",
        "Info": {
          "Definition": "A perfect binary tree is a type of binary tree where every internal node has exactly two children and all leaf nodes are at the same level.",
          "Algorithms": {
            "Create Perfect Binary Tree": "Node* createPerfectBinaryTree(int depth) {\n  if (depth == 0) return NULL;\n  Node* node = new Node(0); // Assuming Node is a structure with 'left' and 'right' children.\n  node->left = createPerfectBinaryTree(depth - 1);\n  node->right = createPerfectBinaryTree(depth - 1);\n  return node;\n}",
            "Check if Binary Tree is Perfect": "bool isPerfectBinaryTree(Node* root) {\n  int depth = findDepth(root);\n  return isPerfect(root, depth, 0);\n}\n\nint findDepth(Node* node) {\n  int depth = 0;\n  while (node != NULL) {\n    depth++;\n    node = node->left;\n  }\n  return depth;\n}\n\nbool isPerfect(Node* node, int depth, int level) {\n  if (node == NULL) return true;\n  if (node->left == NULL && node->right == NULL) return (depth == level + 1);\n  if (node->left == NULL || node->right == NULL) return false;\n  return isPerfect(node->left, depth, level + 1) && isPerfect(node->right, depth, level + 1);\n}",
            "Calculate Height": "int calculateHeight(Node* node) {\n  if (node == NULL) return 0;\n  return 1 + calculateHeight(node->left); // Or right, since it's perfect\n}"
          },
          "imageLink": ["https://drive.google.com/uc?export=view&id=1sPVszqBuPenuZQd5tV7T1ifVC5vZ1nwE","https://drive.google.com/uc?export=view&id=1Qt9GSvFL4G30udwoCiKOJVdksiVdcWVU","https://drive.google.com/uc?export=view&id=1GM_pgmqMDQ38TRiqAFRlW-0pMTsc4yTy"],
          "Complexities": {
            "Time Complexity": {
              "Create Perfect Binary Tree": "O(2^depth - 1), as it creates a tree with 2^depth - 1 nodes.",
              "Check if Binary Tree is Perfect": "O(n), where n is the number of nodes, since it checks each node.",
              "Calculate Height": "O(depth), because the tree is perfect, the depth equals the height."
            },
            "Space Complexity": {
              "Create Perfect Binary Tree": "O(2^depth - 1), for storing all nodes of the tree.",
              "Check if Binary Tree is Perfect": "O(depth), due to recursion stack depth in the worst case.",
              "Calculate Height": "O(depth), for the call stack during recursion."
            }
          }
        }
      },
      {
        "Topic": "Nearly Perfect Binary Tree",
        "Info": {
          "Definition": "A nearly perfect binary tree, also known as an almost complete binary tree, is a type of binary tree where all levels of the tree are fully filled except possibly for the last level, which is filled from left to right. In other words, all nodes are as left as possible. This means that a nearly perfect binary tree is similar to a complete binary tree, but it may have one less node in the last level, and the nodes in the last level are filled from left to right.",
          "Algorithms": {
            "Insertion in a Nearly Perfect Binary Tree": "void insert(Node** root, int data) {\n  queue<Node*> q;\n  q.push(*root);\n  while (!q.empty()) {\n    Node* temp = q.front();\n    q.pop();\n    if (!temp->left) {\n      temp->left = new Node(data);\n      break;\n    } else {\n      q.push(temp->left);\n    }\n    if (!temp->right) {\n      temp->right = new Node(data);\n      break;\n    } else {\n      q.push(temp->right);\n    }\n  }\n}",
            "Deletion in a Nearly Perfect Binary Tree": "void deleteNode(Node** root, int data) {\n  if (*root == NULL) return;\n  if ((*root)->left == NULL && (*root)->right == NULL) {\n    if ((*root)->data == data) {\n      delete *root;\n      *root = NULL;\n    }\n    return;\n  }\n  queue<Node*> q;\n  q.push(*root);\n  Node *temp, *keyNode = NULL;\n  while (!q.empty()) {\n    temp = q.front();\n    q.pop();\n    if (temp->data == data) keyNode = temp;\n    if (temp->left) q.push(temp->left);\n    if (temp->right) q.push(temp->right);\n  }\n  if (keyNode != NULL) {\n    int x = temp->data;\n    deleteDeepest(root, temp);\n    keyNode->data = x;\n  }\n}",
            "Delete Deepest Node": "void deleteDeepest(Node** root, Node* delNode) {\n  queue<Node*> q;\n  q.push(*root);\n  Node* temp;\n  while (!q.empty()) {\n    temp = q.front();\n    q.pop();\n    if (temp == delNode) {\n      temp = NULL;\n      delete delNode;\n      return;\n    }\n    if (temp->right) {\n      if (temp->right == delNode) {\n        temp->right = NULL;\n        delete delNode;\n        return;\n      } else\n        q.push(temp->right);\n    }\n    if (temp->left) {\n      if (temp->left == delNode) {\n        temp->left = NULL;\n        delete delNode;\n        return;\n      } else\n        q.push(temp->left);\n    }\n  }\n}"
          },
          "imageLink":["https://drive.google.com/uc?export=view&id=1hZKepDpZJLR07A40PMIzXfnAlewVDnLr","https://drive.google.com/uc?export=view&id=1l65qsWGQJs0HGSS0--KVUdIx4IbxowHK","https://drive.google.com/uc?export=view&id=192eNs254X3zofprnW_OCC7Nu2sMYW6wb"],
          "Complexities": {
            "Time Complexity": {
              "Insertion": "O(n), as it might need to traverse the tree to find the insertion point.",
              "Deletion": "O(n), as it requires finding the node, then the deepest node, and rearranging."
            },
            "Space Complexity": {
              "General": "O(n), primarily for queue storage in both insertion and deletion operations."
            }
          }
        }
      },      
      {
        "Topic": "Full Binary Tree",
        "Info": {
          "Definition": "A full binary tree (sometimes proper binary tree or 2-tree) is a tree in which every node other than the leaves has two children.",
          "Algorithms": {
            "Insert Operation": "TreeNode* insert(TreeNode* node, int value) {\n  if (node == NULL) return new TreeNode(value);\n  std::queue<TreeNode*> q;\n  q.push(node);\n  while (!q.empty()) {\n    TreeNode* temp = q.front();\n    q.pop();\n    if (!temp->left) {\n      temp->left = new TreeNode(value);\n      break;\n    } else q.push(temp->left);\n    if (!temp->right) {\n      temp->right = new TreeNode(value);\n      break;\n    } else q.push(temp->right);\n  }\n  return node;\n}",
            "Delete Operation": "void deleteNode(TreeNode** root, int key) {\n  if (*root == NULL) return;\n\n  TreeNode* toDelete = findNode(*root, key);\n  if (toDelete == NULL) return;\n\n  TreeNode* deepestRightmost = getDeepestRightmostNode(*root);\n  if (deepestRightmost == NULL) return;\n\n  int temp = deepestRightmost->value;\n  deleteDeepestRightmostNode(root, deepestRightmost);\n  toDelete->value = temp;\n}\n\nTreeNode* findNode(TreeNode* node, int key) {\n  // Implementation to find the node with the given key\n}\n\nTreeNode* getDeepestRightmostNode(TreeNode* root) {\n  // Implementation to get the deepest and rightmost node\n}\n\nvoid deleteDeepestRightmostNode(TreeNode** root, TreeNode* delNode) {\n  // Implementation to delete the deepest and rightmost node\n}",
            "Check if Full Binary Tree": "bool isFullBinaryTree(TreeNode* root) {\n  if (root == NULL) return true;\n  if (!root->left && !root->right) return true;\n  if (root->left && root->right) return isFullBinaryTree(root->left) && isFullBinaryTree(root->right);\n  return false;\n}",
            "Calculate Tree Height": "int calculateHeight(TreeNode* node) {\n  if (node == NULL) return 0;\n  int leftHeight = calculateHeight(node->left);\n  int rightHeight = calculateHeight(node->right);\n  return std::max(leftHeight, rightHeight) + 1;\n}",
            "Is Perfect Binary Tree": "bool isPerfectBinaryTree(TreeNode* root) {\n  int depth = calculateHeight(root);\n  return isPerfect(root, depth, 0);\n}\nbool isPerfect(TreeNode* node, int depth, int level) {\n  if (node == NULL) return true;\n  if (!node->left && !node->right) return depth == level + 1;\n  if (!node->left || !node->right) return false;\n  return isPerfect(node->left, depth, level + 1) && isPerfect(node->right, depth, level + 1);\n}"
          },
          "imageLink":["https://drive.google.com/uc?export=view&id=1VP1JrZjKqZ9cSVjGgBM_VhHPDR-1X0KO","https://drive.google.com/uc?export=view&id=1z7GSI-qFXl2zLeSoTwit_4ijlk2U_r7S","https://drive.google.com/uc?export=view&id=1L5VPna_RQT9NW8Uv2IQF68l_uPlLlr8N","https://drive.google.com/uc?export=view&id=16KheYy4hpN4Fxe7NBaMQQ84LHVGRj2gb"],
          "Complexities": {
            "Time Complexity": {
              "Insert Operation": "O(N), as it might need to traverse the tree to find the insertion spot.",
              "Delete Operation": "O(N), as finding the node and the deepest rightmost node may each require traversing the tree.",
              "Check if Full Binary Tree": "O(N), as it requires checking each node.",
              "Calculate Tree Height": "O(N), as it performs a post-order traversal of the tree.",
              "Is Perfect Binary Tree": "O(N), due to the need to check every node's depth."
            },
            "Space Complexity": {
              "Insert Operation": "O(N), due to the potential size of the queue.",
              "Delete Operation": "O(H), where H is the height of the tree, for recursive call stack.",
              "Check if Full Binary Tree": "O(H), where H is the height of the tree, due to recursive call stack.",
              "Calculate Tree Height": "O(H), for the recursive stack space.",
              "Is Perfect Binary Tree": "O(H), for the call stack during the depth and perfection checks."
            }
          }
        }
      },
      {
        "Topic": "Complete Binary Tree",
        "Info": {
          "Definition": "A complete binary tree is a binary tree in which all levels are fully filled except possibly the last, which is filled from left to right.",
          "Algorithms": {
            "Insertion": "void insert(Node*& root, int key) {\n  if (root == NULL) {\n    root = new Node(key);\n    return;\n  }\n  queue<Node*> q;\n  q.push(root);\n  while (!q.empty()) {\n    Node* temp = q.front(); q.pop();\n    if (!temp->left) {\n      temp->left = new Node(key);\n      break;\n    } else {\n      q.push(temp->left);\n    }\n    if (!temp->right) {\n      temp->right = new Node(key);\n      break;\n    } else {\n      q.push(temp->right);\n    }\n  }\n}",
            "Deletion": "void deleteNode(Node*& root, int key) {\n  if (root == NULL) return;\n  if (root->data == key && root->left == NULL && root->right == NULL) {\n    delete root;\n    root = NULL;\n    return;\n  }\n  queue<Node*> q;\n  q.push(root);\n  Node* temp;\n  Node* key_node = NULL;\n  while (!q.empty()) {\n    temp = q.front(); q.pop();\n    if (temp->data == key) key_node = temp;\n    if (temp->left) q.push(temp->left);\n    if (temp->right) q.push(temp->right);\n  }\n  if (key_node != NULL) {\n    int x = temp->data;\n    deleteDeepest(root, temp);\n    key_node->data = x;\n  }\n}",
            "Check If Complete": "bool isComplete(Node* root) {\n  if (root == NULL) return true;\n  queue<Node*> q;\n  q.push(root);\n  bool flag = false;\n  while (!q.empty()) {\n    Node* temp = q.front(); q.pop();\n    if (temp->left) {\n      if (flag) return false;\n      q.push(temp->left);\n    } else {\n      flag = true;\n    }\n    if (temp->right) {\n      if (flag) return false;\n      q.push(temp->right);\n    } else {\n      flag = true;\n    }\n  }\n  return true;\n}",
            "Calculate Height": "int height(Node* node) {\n  if (node == NULL) return 0;\n  int leftHeight = height(node->left);\n  int rightHeight = height(node->right);\n  return max(leftHeight, rightHeight) + 1;\n}"
          },
          "imageLink":["https://drive.google.com/uc?export=view&id=1aDVprWnfSjSDYAS3hknOAqYqOqYhLgOf","https://drive.google.com/uc?export=view&id=1IdtvBbfe5R5xsmZfZ6JxCmz1612JuEDY","https://drive.google.com/uc?export=view&id=1u6QjoiL3s2yRbtTvp6wwPh6XcGuYwbSN"],
          "Complexities": {
            "Time Complexity": {
              "Insertion": "O(n), as it may need to traverse the tree to find the insertion spot.",
              "Deletion": "O(n), as it requires searching for the node and the deepest rightmost node.",
              "Check If Complete": "O(n), requires traversing all nodes to check completeness.",
              "Calculate Height": "O(n), as it performs a full traversal in the worst case."
            },
            "Space Complexity": {
              "Insertion": "O(n) for the queue used in level-order traversal.",
              "Deletion": "O(n) for the queue used in level-order traversal.",
              "Check If Complete": "O(n) for the queue used in level-order traversal.",
              "Calculate Height": "O(h), where h is the height of the tree, due to recursion stack depth."
            }
          }
        }
      },
      {
        "Topic": "Balanced Binary Tree",
        "Info": {
          "Definition": "A balanced binary tree is a type of binary tree where the difference between heights of left and right subtrees of any node is not more than one. Balanced binary trees, such as AVL trees or Red-Black trees, automatically maintain height balance to ensure operation complexities.",
          "Algorithms": {
            "Insertion": "Node* insert(Node* node, int key) {\n  if (node == NULL) return(new Node(key));\n  if (key < node->key) node->left = insert(node->left, key);\n  else if (key > node->key) node->right = insert(node->right, key);\n  else return node;\n  node->height = 1 + max(height(node->left), height(node->right));\n  int balance = getBalance(node);\n  if (balance > 1 && key < node->left->key) return rightRotate(node);\n  if (balance < -1 && key > node->right->key) return leftRotate(node);\n  if (balance > 1 && key > node->left->key) {\n    node->left = leftRotate(node->left);\n    return rightRotate(node);\n  }\n  if (balance < -1 && key < node->right->key) {\n    node->right = rightRotate(node->right);\n    return leftRotate(node);\n  }\n  return node;\n}",
            "Deletion": "Node* deleteNode(Node* root, int key) {\n  if (root == NULL) return root;\n  if ( key < root->key ) root->left = deleteNode(root->left, key);\n  else if( key > root->key ) root->right = deleteNode(root->right, key);\n  else {\n    if( (root->left == NULL) || (root->right == NULL) ) {\n      Node *temp = root->left ? root->left : root->right;\n      if (temp == NULL) {\n        temp = root;\n        root = NULL;\n      } else *root = *temp;\n      free(temp);\n    } else {\n      Node* temp = minValueNode(root->right);\n      root->key = temp->key;\n      root->right = deleteNode(root->right, temp->key);\n    }\n  }\n  if (root == NULL) return root;\n  root->height = max(height(root->left), height(root->right)) + 1;\n  int balance = getBalance(root);\n  if (balance > 1 && getBalance(root->left) >= 0) return rightRotate(root);\n  if (balance > 1 && getBalance(root->left) < 0) {\n    root->left = leftRotate(root->left);\n    return rightRotate(root);\n  }\n  if (balance < -1 && getBalance(root->right) <= 0) return leftRotate(root);\n  if (balance < -1 && getBalance(root->right) > 0) {\n    root->right = rightRotate(root->right);\n    return leftRotate(root);\n  }\n  return root;\n}"
          },
          "imageLink":["https://drive.google.com/uc?export=view&id=1gnOkx5uESTvmAF2KFQ-f9c7j3qN8HK_9","https://drive.google.com/uc?export=view&id=15p71UVkFOO0CVnOhoW6RQXHJMgc9IHm7"],
          "Complexities": {
            "Time Complexity": "O(log n) - For operations like insertion and deletion, due to height-balancing. This ensures that the tree remains balanced, thereby maintaining a logarithmic height.",
            "Space Complexity": "O(n) - Space needed to store all nodes in the tree."
          }
        }
      },
      {
        "Topic": "Invert/Flip Binary Tree",
        "Info": {
          "Definition": "Inverting or flipping a binary tree involves swapping the left and right child of all nodes in the tree. This operation transforms the tree into its mirror image. It's a common problem in binary tree data structures, showcasing the use of recursion or iterative approaches to traverse and modify trees.",
          "Algorithms": {
            "Recursive Solution": "TreeNode* invertTree(TreeNode* root) {\n  if (root == NULL) return NULL;\n  TreeNode* temp = root->left;\n  root->left = invertTree(root->right);\n  root->right = invertTree(temp);\n  return root;\n}",
            "Iterative Solution": "TreeNode* invertTreeIterative(TreeNode* root) {\n  if (root == NULL) return NULL;\n  queue<TreeNode*> q;\n  q.push(root);\n  while (!q.empty()) {\n    TreeNode* current = q.front(); q.pop();\n    swap(current->left, current->right);\n    if (current->left) q.push(current->left);\n    if (current->right) q.push(current->right);\n  }\n  return root;\n}"
          },
          "imageLink":["https://drive.google.com/uc?export=view&id=1-bAgg9uNqYXT6ZEmrdVp6n5WdvNcvIqh","https://drive.google.com/uc?export=view&id=1fIJ9cQwDVOGfHrFP3HnGbGQjgbCZeI6H"],
          "Complexities": {
            "Time Complexity": {
              "Recursive Solution": "O(n), where n is the number of nodes in the binary tree. Each node is visited once.",
              "Iterative Solution": "O(n), similar to the recursive solution since each node in the tree is visited once."
            },
            "Space Complexity": {
              "Recursive Solution": "O(h), where h is the height of the tree. This space is used by the recursion stack.",
              "Iterative Solution": "O(n), in the worst case, due to the storage of nodes in the queue."
            }
          }
        }
      },
      {
        "Topic": "Binary Search Tree",
        "Info": {
          "Definition": "A binary search tree (BST) is a binary tree where each node has a key greater than all keys in the node's left subtree and less than those in the right subtree.",
          "Algorithms": {
            "Insertion": "Node* insertBST(Node* node, int key) {\n  if (node == NULL) return new Node(key);\n  if (key < node->data) node->left = insertBST(node->left, key);\n  else if (key > node->data) node->right = insertBST(node->right, key);\n  return node;\n}",
            "Deletion": "Node* deleteBST(Node* root, int key) {\n  if (root == NULL) return root;\n  if (key < root->data) root->left = deleteBST(root->left, key);\n  else if (key > root->data) root->right = deleteBST(root->right, key);\n  else {\n    if (root->left == NULL) {\n      Node *temp = root->right;\n      delete root;\n      return temp;\n    } else if (root->right == NULL) {\n      Node *temp = root->left;\n      delete root;\n      return temp;\n    }\n    Node* temp = minValueNode(root->right);\n    root->data = temp->data;\n    root->right = deleteBST(root->right, temp->data);\n  }\n  return root;\n}",
            "Search": "Node* searchBST(Node* root, int key) {\n  if (root == NULL || root->data == key) return root;\n  if (key < root->data) return searchBST(root->left, key);\n  return searchBST(root->right, key);\n}",
            "Find Minimum Value": "Node* minValueNode(Node* node) {\n  Node* current = node;\n  while (current && current->left != NULL) {\n    current = current->left;\n  }\n  return current;\n}",
            "Find Maximum Value": "Node* maxValueNode(Node* node) {\n  Node* current = node;\n  while (current && current->right != NULL) {\n    current = current->right;\n  }\n  return current;\n}"
          },
          "imageLink":["https://drive.google.com/uc?export=view&id=1l9SwCsIPvtk0z8RqfeXSTAfHJZw7Yjxr","https://drive.google.com/uc?export=view&id=1ROaa7YJcePA0RcQnSYN9FOn2fu20jnGR"],
          "Complexities": {
            "Time Complexity": {
              "Insertion": "O(n) in the worst case, O(log n) in the average case.",
              "Deletion": "O(n) in the worst case, O(log n) in the average case.",
              "Search": "O(n) in the worst case, O(log n) in the average case.",
              "Find Minimum/Maximum Value": "O(n) in the worst case, O(log n) in the average case."
            },
            "Space Complexity": {
              "General": "O(n) for storing all nodes. O(h) for recursive call stack, where h is the height of the tree."
            }
          }
        }
      },
      {
        "Topic": "AVL Tree",
        "Info": {
          "Definition": "An AVL tree is a self-balancing binary search tree, where the difference between heights of left and right subtrees cannot be more than one for all nodes.",
          "Algorithms": {
            "Insertion": "Node* insertAVL(Node* node, int key) {\n  if (node == NULL) return new Node(key);\n  if (key < node->key) node->left = insertAVL(node->left, key);\n  else if (key > node->key) node->right = insertAVL(node->right, key);\n  else return node;\n  node->height = 1 + max(height(node->left), height(node->right));\n  int balance = getBalance(node);\n  if (balance > 1 && key < node->left->key) return rightRotate(node);\n  if (balance < -1 && key > node->right->key) return leftRotate(node);\n  if (balance > 1 && key > node->left->key) {\n    node->left = leftRotate(node->left);\n    return rightRotate(node);\n  }\n  if (balance < -1 && key < node->right->key) {\n    node->right = rightRotate(node->right);\n    return leftRotate(node);\n  }\n  return node;\n}",
            "Deletion": "Node* deleteAVL(Node* root, int key) {\n  if (root == NULL) return root;\n  if (key < root->key) root->left = deleteAVL(root->left, key);\n  else if (key > root->key) root->right = deleteAVL(root->right, key);\n  else {\n    if ((root->left == NULL) || (root->right == NULL)) {\n      Node* temp = root->left ? root->left : root->right;\n      if (temp == NULL) {\n        temp = root;\n        root = NULL;\n      } else *root = *temp;\n      free(temp);\n    } else {\n      Node* temp = minValueNode(root->right);\n      root->key = temp->key;\n      root->right = deleteAVL(root->right, temp->key);\n    }\n  }\n  if (root == NULL) return root;\n  root->height = 1 + max(height(root->left), height(root->right));\n  int balance = getBalance(root);\n  if (balance > 1 && getBalance(root->left) >= 0) return rightRotate(root);\n  if (balance > 1 && getBalance(root->left) < 0) {\n    root->left = leftRotate(root->left);\n    return rightRotate(root);\n  }\n  if (balance < -1 && getBalance(root->right) <= 0) return leftRotate(root);\n  if (balance < -1 && getBalance(root->right) > 0) {\n    root->right = rightRotate(root->right);\n    return leftRotate(root);\n  }\n  return root;\n}",
            "Search": "Node* searchAVL(Node* root, int key) {\n  if (root == NULL || root->key == key) return root;\n  if (key < root->key) return searchAVL(root->left, key);\n  else return searchAVL(root->right, key);\n}",
            "Find Minimum Value": "Node* minValueNode(Node* node) {\n  Node* current = node;\n  while (current && current->left != NULL) current = current->left;\n  return current;\n}",
            "Find Maximum Value": "Node* maxValueNode(Node* node) {\n  Node* current = node;\n  while (current && current->right != NULL) current = current->right;\n  return current;\n}",
            "Check Height": "int height(Node* node) {\n  if (node == NULL) return 0;\n  return node->height;\n}"
          },
          "imageLink":["https://drive.google.com/uc?export=view&id=1Gt4F4Rcf1qKQCZNCzDkKQ9kvkNKWYo3_","https://drive.google.com/uc?export=view&id=1eGX8vepCSxHWHDWjIXma5RSfyRn3vJ1T"],
          "Complexities": {
            "Time Complexity": {
              "Insertion": "O(log n), as the tree remains balanced.",
              "Deletion": "O(log n), due to rebalancing.",
              "Search": "O(log n), benefiting from the balanced nature of the AVL.",
              "Find Minimum/Maximum Value": "O(log n), due to the tree's balanced height.",
              "Check Height": "O(1), height is maintained with the node."
            },
            "Space Complexity": "O(n) - Space needed to store all nodes in the tree."
          }
        }
      },
      {
        "Topic": "AVL Tree Rotations",
        "Info": {
          "Definition": "An AVL tree is a self-balancing binary search tree where the difference between heights of left and right subtrees cannot be more than one for all nodes. This ensures O(log n) complexity for search, insert, and delete operations. AVL trees maintain balance using four types of rotations.",
          "Algorithms": {
            "Right Rotation": "Node* rightRotate(Node* y) {\n  Node* x = y->left;\n  Node* T2 = x->right;\n  // Perform rotation\n  x->right = y;\n  y->left = T2;\n  // Update heights\n  y->height = max(height(y->left), height(y->right)) + 1;\n  x->height = max(height(x->left), height(x->right)) + 1;\n  // Return new root\n  return x;\n}",
            "Left Rotation": "Node* leftRotate(Node* x) {\n  Node* y = x->right;\n  Node* T2 = y->left;\n  // Perform rotation\n  y->left = x;\n  x->right = T2;\n  // Update heights\n  x->height = max(height(x->left), height(x->right)) + 1;\n  y->height = max(height(y->left), height(y->right)) + 1;\n  // Return new root\n  return y;\n}",
            "Left Right Rotation": "Node* leftRightRotate(Node* node) {\n  node->left = leftRotate(node->left);\n  return rightRotate(node);\n}",
            "Right Left Rotation": "Node* rightLeftRotate(Node* node) {\n  node->right = rightRotate(node->right);\n  return leftRotate(node);\n}"
          },
          "imageLink":["https://drive.google.com/uc?export=view&id=1_mKHCz2Eejvlj-0IYIrjbe9Bnq7NO3kw","https://drive.google.com/uc?export=view&id=1omgDFANz7xu2olp1_OgU2lUQqNtwwgDV","https://drive.google.com/uc?export=view&id=1G6OHyj2zvRVoMlkrpOCjavvLyctn8WbP","https://drive.google.com/uc?export=view&id=15hd-8B1FqADv2CHg_GchHxA-kqlXrBDf"],
          "Complexities": {
            "Time Complexity": "O(1), rotation operations are constant time.",
            "Space Complexity": {
              "Overall": "O(n), where n is the number of nodes in the AVL tree, for storing the nodes themselves."
            }
          }
        }
      },
      {
        "Topic": "Red-Black Tree",
        "Info": {
          "Definition": "A Red-Black Tree is a self-balancing binary search tree where each node has an extra bit for denoting the color of the node, either red or black. It ensures that the tree remains balanced, and operations like insertion, deletion, and search can be performed in logarithmic time complexity.",
          "Algorithms": {
            "Insertion Code": "void insert(Node *&root, int data) {\n  Node *newNode = new Node(data);\n  root = BSTInsert(root, newNode);\n  fixViolation(root, newNode);\n}",
            "Deletion Code": "void deleteNode(Node *&root, int data) {\n  Node *nodeToDelete = search(root, data);\n  if (nodeToDelete != NULL) {\n    root = deleteBSTNode(root, nodeToDelete);\n    fixDeleteViolation(root);\n  }\n}",
            "Search Code": "Node* search(Node* root, int data) {\n  if (root == NULL || root->data == data) return root;\n  if (data < root->data) return search(root->left, data);\n  else return search(root->right, data);\n}",
            "Rotate Left": "void rotateLeft(Node *&root, Node *&pt) {\n  Node *pt_right = pt->right;\n  pt->right = pt_right->left;\n  if (pt->right != NULL) pt->right->parent = pt;\n  pt_right->parent = pt->parent;\n  if (pt->parent == NULL) root = pt_right;\n  else if (pt == pt->parent->left) pt->parent->left = pt_right;\n  else pt->parent->right = pt_right;\n  pt_right->left = pt;\n  pt->parent = pt_right;\n}",
            "Rotate Right": "void rotateRight(Node *&root, Node *&pt) {\n  Node *pt_left = pt->left;\n  pt->left = pt_left->right;\n  if (pt->left != NULL) pt->left->parent = pt;\n  pt_left->parent = pt->parent;\n  if (pt->parent == NULL) root = pt_left;\n  else if (pt == pt->parent->left) pt->parent->left = pt_left;\n  else pt->parent->right = pt_left;\n  pt_left->right = pt;\n  pt->parent = pt_left;\n}",
            "Fix Insertion Violation": "void fixViolation(Node *&root, Node *&pt) {\n  Node *parent = NULL;\n  Node *grandparent = NULL;\n  while ((pt != root) && (pt->color != BLACK) && (pt->parent->color == RED)) {\n    parent = pt->parent;\n    grandparent = pt->parent->parent;\n    if (parent == grandparent->left) {\n      Node *uncle = grandparent->right;\n      if (uncle != NULL && uncle->color == RED) {\n        grandparent->color = RED;\n        parent->color = BLACK;\n        uncle->color = BLACK;\n        pt = grandparent;\n      } else {\n        if (pt == parent->right) {\n          rotateLeft(root, parent);\n          pt = parent;\n          parent = pt->parent;\n        }\n        rotateRight(root, grandparent);\n        swap(parent->color, grandparent->color);\n        pt = parent;\n      }\n    } else {\n      Node *uncle = grandparent->left;\n      if (uncle != NULL && uncle->color == RED) {\n        grandparent->color = RED;\n        parent->color = BLACK;\n        uncle->color = BLACK;\n        pt = grandparent;\n      } else {\n        if (pt == parent->left) {\n          rotateRight(root, parent);\n          pt = parent;\n          parent = pt->parent;\n        }\n        rotateLeft(root, grandparent);\n        swap(parent->color, grandparent->color);\n        pt = parent;\n      }\n    }\n  }\n  root->color = BLACK;\n}",
            "Fix Deletion Violation": "void fixDeleteViolation(Node *&root) {\n  // Pseudocode for handling deletion violations. Actual implementation would depend on the node's relationship with its parent and siblings, requiring rotations and color flips to maintain tree properties.\n}"
          },
          "imageLink":["https://drive.google.com/uc?export=view&id=1dQ6sthqbPeJePTEJBt57-dBK4YefszBg","https://drive.google.com/uc?export=view&id=1Ugltp4GWtuOft2Ek1K2s6ClqsnKuHwbe"],
          "Complexities": {
            "Time Complexity": {
              "Search": "O(log n) - due to the balanced nature of the tree.",
              "Insert": "O(log n) - including fixing the tree structure to maintain red-black properties.",
              "Delete": "O(log n) - including adjustments post-deletion to ensure the tree remains balanced."
            },
            "Space Complexity": "O(n) - to store all the nodes in the tree."
          }
        }
      },
      {
        "Topic": "Segment Trees",
        "Info": {
          "Definition": "A segment tree is a tree data structure used for storing information about intervals, or segments. It allows querying which of the stored segments contain a given point. Essentially, it is a binary tree used for storing the intervals or segments of an array. Segment trees support operations like finding the minimum, maximum, sum, and greatest common divisor of intervals with update and query times logarithmic to the number of intervals.",
          "Algorithms": {
            "Build Tree": "void buildTree(int* arr, int* segTree, int start, int end, int treeNode) {\n  if(start == end) {\n    segTree[treeNode] = arr[start];\n    return;\n  }\n  int mid = (start + end) / 2;\n  buildTree(arr, segTree, start, mid, 2*treeNode);\n  buildTree(arr, segTree, mid+1, end, 2*treeNode+1);\n  segTree[treeNode] = min(segTree[2*treeNode], segTree[2*treeNode+1]);\n}",
            "Update Tree": "void updateTree(int* arr, int* segTree, int start, int end, int treeNode, int idx, int value) {\n  if(start == end) {\n    arr[idx] = value;\n    segTree[treeNode] = value;\n    return;\n  }\n  int mid = (start + end) / 2;\n  if(idx > mid) {\n    updateTree(arr, segTree, mid+1, end, 2*treeNode+1, idx, value);\n  } else {\n    updateTree(arr, segTree, start, mid, 2*treeNode, idx, value);\n  }\n  segTree[treeNode] = min(segTree[2*treeNode], segTree[2*treeNode+1]);\n}",
            "Query Tree": "int queryTree(int* segTree, int start, int end, int treeNode, int left, int right) {\n  if(start > right || end < left) {\n    return INT_MAX;\n  }\n  if(start >= left && end <= right) {\n    return segTree[treeNode];\n  }\n  int mid = (start + end) / 2;\n  int ans1 = queryTree(segTree, start, mid, 2*treeNode, left, right);\n  int ans2 = queryTree(segTree, mid+1, end, 2*treeNode+1, left, right);\n  return min(ans1, ans2);\n}"
          },
          "imageLink":["https://drive.google.com/uc?export=view&id=1n1fQ-TpVN9RU2nznOuciOt1CBv4wMfNX","https://drive.google.com/uc?export=view&id=1VS6obXurJu8ov880ew4X1XcCLko_G-nM","https://drive.google.com/uc?export=view&id=1fipvSBuV7ZTuOXItIgK0G5NRWBK2QDg8"],
          "Complexities": {
            "Time Complexities": {
              "Build Tree": "O(n), where n is the number of elements in the array",
              "Update Tree": "O(log n), where n is the number of elements in the array",
              "Query Tree": "O(log n), for querying a range of elements"
            },
            "Space Complexity": {
              "Build Tree": "O(4*n), due to the storage of 4 times the number of elements in the segment tree array",
              "Update Tree": "O(4*n), does not change the overall space requirement of the segment tree",
              "Query Tree": "O(log n), for the recursion stack, not counting the space for the segment tree itself"
            }
          }
        }
      },
      {
        "Topic": "Tree Traversals",
        "Info": {
          "Definition": "Traversing a tree means visiting every node in the tree. You might, for instance, want to add all the values in the tree or find the largest one. For all these operations, you will need to visit each node of the tree.Tree traversal algorithms are methods for visiting all the nodes in a tree data structure. There are several types of traversals, each visiting the nodes in a different order. The three fundamental depth-first search (DFS) traversals for binary trees are preorder, inorder, and postorder.\nPreorder Traversal : Visits the current node before its child nodes (Root, Left, Right). \n Inorder Traversal:  Visits the left child, then the current node, and finally the right child (Left, Root, Right). This traversal method is used especially for binary search trees where it returns nodes in non-decreasing order. \n PostOrder Traversal :Visits the current node after its child nodes (Left, Right, Root). This method is used to delete the tree or get the postfix expression of an expression tree.\n  Additionally, level order traversal is a type of breadth-first search (BFS) that visits nodes level by level.",
          "Algorithms": {
            "Preorder Traversal": "void preorderTraversal(Node* root) {\n  if (root == NULL) return;\n  cout << root->data << ' ';\n  preorderTraversal(root->left);\n  preorderTraversal(root->right);\n}",
            "Inorder Traversal": "void inorderTraversal(Node* root) {\n  if (root == NULL) return;\n  inorderTraversal(root->left);\n  cout << root->data << ' ';\n  inorderTraversal(root->right);\n}",
            "Postorder Traversal": "void postorderTraversal(Node* root) {\n  if (root == NULL) return;\n  postorderTraversal(root->left);\n  postorderTraversal(root->right);\n  cout << root->data << ' ';\n}",
            "Level Order Traversal": "void levelOrderTraversal(Node* root) {\n  if (root == NULL) return;\n  queue<Node*> q;\n  q.push(root);\n  while (!q.empty()) {\n    Node* node = q.front();\n    cout << node->data << ' ';\n    q.pop();\n    if (node->left != NULL) q.push(node->left);\n    if (node->right != NULL) q.push(node->right);\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Preorder": "O(n)",
              "Inorder": "O(n)",
              "Postorder": "O(n)",
              "Level Order": "O(n)"
            },
            "Space Complexity": {
              "DFS based traversals":"O(h) for DFS traversals - where h is the height of the tree. This space complexity accounts for the call stack during recursive calls." ,
              "BFS based traversals":"For Level Order Traversal, space complexity is O(w), where w is the maximum width of the tree."
            }
          }
        }
      },
      {
        "Topic": "Splay Tree",
        "Info": {
          "Definition": "A Splay Tree is a self-adjusting binary search tree with the additional property that recently accessed elements are quick to access again. It performs basic operations such as insertion, look-up, and deletion in O(log n) amortized time. Operations on the tree involve a series of splay operations, moving an element to the root of the tree through a combination of tree rotations.",
          "Algorithms": {
            "Splay Operation": "void splay(Node*& root, int key) {\n  if (root == NULL || root->key == key) return;\n\n  // Node to be splayed is in the left subtree\n  if (root->key > key) {\n    if (root->left == NULL) return;\n    // Zig-Zig (Left Left)\n    if (root->left->key > key) {\n      splay(root->left->left, key);\n      root = rightRotate(root);\n    } else if (root->left->key < key) { // Zig-Zag (Left Right)\n      splay(root->left->right, key);\n      if (root->left->right != NULL)\n        root->left = leftRotate(root->left);\n    }\n    root = (root->left == NULL) ? root : rightRotate(root);\n  } else { // Node to be splayed is in the right subtree\n    if (root->right == NULL) return;\n    // Zag-Zig (Right Left)\n    if (root->right->key > key) {\n      splay(root->right->left, key);\n      if (root->right->left != NULL)\n        root->right = rightRotate(root->right);\n    } else if (root->right->key < key) { // Zag-Zag (Right Right)\n      splay(root->right->right, key);\n      root = leftRotate(root);\n    }\n    root = (root->right == NULL) ? root : leftRotate(root);\n  }\n}",
            "Right Rotate": "Node* rightRotate(Node* x) {\n  Node* y = x->left;\n  x->left = y->right;\n  y->right = x;\n  return y;\n}",
            "Left Rotate": "Node* leftRotate(Node* x) {\n  Node* y = x->right;\n  x->right = y->left;\n  y->left = x;\n  return y;\n}"
          },
          "Complexities": {
            "Time Complexity": "O(log n) amortized for operations like search, insert, and delete, considering the tree remains balanced.",
            "Space Complexity": "O(n), for storing the tree elements."
          }
        }
      },
      {
        "Topic": "Fenwick Tree",
        "Info": {
          "Definition": "A Fenwick Tree, also known as a Binary Indexed Tree (BIT), is a data structure that provides efficient methods for calculating prefix sums in an array of numbers. It allows for the calculation of the sum of the elements in a given range as well as updating the value of an element in logarithmic time. The Fenwick Tree is widely used in scenarios where there are frequent updates and queries on an array.",
          "Algorithms": {
            "Update Function": "void updateBIT(int BITree[], int n, int index, int val) {\n  index = index + 1;\n  while (index <= n) {\n    BITree[index] += val;\n    index += index & (-index);\n  }\n}",
            "Get Sum Function": "int getSum(int BITree[], int index) {\n  int sum = 0;\n  index = index + 1;\n  while (index > 0) {\n    sum += BITree[index];\n    index -= index & (-index);\n  }\n  return sum;\n}",
            "Construction": "void constructBITree(int arr[], int **BITree, int n) {\n  *BITree = new int[n+1];\n  for (int i = 1; i <= n; i++)\n    (*BITree)[i] = 0;\n  for (int i = 0; i < n; i++)\n    updateBIT(*BITree, n, i, arr[i]);\n}"
          },
          "Complexities": {
            "Time Complexity": {
              "Update Function": "O(log n), for updating a value in the array.",
              "Get Sum Function": "O(log n), for calculating the prefix sum up to a given index.",
              "Construction": "O(n log n), for constructing the Fenwick Tree from an array of n elements."
            },
            "Space Complexity": "O(n), for storing the Fenwick Tree."
          }
        }
      },
      {
        "Topic": "B-Tree",
        "Info": {
          "Definition": "A B-Tree is a self-balancing tree data structure that maintains sorted data and allows searches, sequential access, insertions, and deletions in logarithmic time. It generalizes the binary search tree, allowing for nodes with more than two children.",
          "Algorithms": {
            "Insertion Code": "void insert(Node* &root, int key) {\n    // Check if the tree is empty\n    if (root == nullptr) {\n        root = createNode(key);\n        return;\n    }\n\n    // Recursive insert function\n    // Insert logic for B-Tree insertion\n}",
            "Deletion Code": "void deleteKey(Node* &root, int key) {\n    // Deletion logic for B-Tree\n    // Handle cases: leaf and internal nodes\n}"
          },
          "Complexities": {
            "Time Complexity": {
              "Search": "O(log n)",
              "Insert": "O(log n)",
              "Delete": "O(log n)"
            },
            "Space Complexity": "O(n), where n is the number of keys in the tree."
          }
        }
      },
      {
        "Topic": "B+ Tree",
        "Info": {
          "Definition": "A B+ Tree is a type of B-Tree used in databases and filesystems to store data for efficient retrieval. It differs from a B-Tree by storing all data in leaf nodes and using internal nodes as a means to provide a pathway to these leaf nodes.",
          "Algorithms": {
            "Insertion Code": "void BPlusTreeInsertion(Node* &root, int key) {\n    // Insert logic for B+ Tree\n    // Ensures that all data is in the leaf nodes\n}",
            "Deletion Code": "void BPlusTreeDeletion(Node* &root, int key) {\n    // Deletion logic for B+ Tree\n    // Adjusts tree to maintain properties after deletion\n}"
          },
          "Complexities": {
            "Time Complexity": {
              "Search": "O(log n)",
              "Insert": "O(log n)",
              "Delete": "O(log n)"
            },
            "Space Complexity": "O(n), where n is the number of keys."
          }
        }
      },
      {
        "Topic": "Merge Sort",
        "Info": {
          "Definition": "Merge Sort is a divide-and-conquer algorithm that divides the input array into two halves, calls itself for the two halves, and then merges the two sorted halves. It is known for its consistent performance and is often used in sorting libraries.",
          "Algorithms": {
            "Code": "void merge(int arr[], int l, int m, int r) {\n    int n1 = m - l + 1;\n    int n2 = r - m;\n\n    // Create temp arrays\n    int L[n1], R[n2];\n\n    // Copy data to temp arrays L[] and R[]\n    for (int i = 0; i < n1; i++)\n        L[i] = arr[l + i];\n    for (int j = 0; j < n2; j++)\n        R[j] = arr[m + 1 + j];\n\n    // Merge the temp arrays back into arr[l..r]\n    int i = 0; // Initial index of first subarray\n    int j = 0; // Initial index of second subarray\n    int k = l; // Initial index of merged subarray\n    while (i < n1 && j < n2) {\n        if (L[i] <= R[j]) {\n            arr[k] = L[i];\n            i++;\n        } else {\n            arr[k] = R[j];\n            j++;\n        }\n        k++;\n    }\n\n    // Copy the remaining elements of L[], if there are any\n    while (i < n1) {\n        arr[k] = L[i];\n        i++;\n        k++;\n    }\n\n    // Copy the remaining elements of R[], if there are any\n    while (j < n2) {\n        arr[k] = R[j];\n        j++;\n        k++;\n    }\n}\n\nvoid mergeSort(int arr[], int l, int r) {\n    if (l < r) {\n        // Find the middle point to divide the array into two halves\n        int m = l + (r-l)/2;\n\n        // Call mergeSort for first half\n        mergeSort(arr, l, m);\n\n        // Call mergeSort for second half\n        mergeSort(arr, m+1, r);\n\n        // Merge the sorted halves\n        merge(arr, l, m, r);\n    }\n}"
          },
          "Complexities": {
            "Time Complexity": "Worst, Average, and Best Case: O(n log n) - Merge sort always divides the array in half and takes linear time to merge two halves.",
            "Space Complexity": "O(n) - Requires additional space for the temporary arrays used in the merge process."
          }
        }
      },
      {
        "Topic": "Quick Sort",
        "Info": {
          "Definition": "Quick Sort is a highly efficient sorting algorithm and is based on partitioning of array of data into smaller arrays. A large array is partitioned into two arrays one of which holds values smaller than the specified value, say pivot, based on which the partition is made and another array holds values greater than the pivot value.",
          "Algorithms": {
            "Code": "void quickSort(int arr[], int low, int high) {\n  if (low < high) {\n    int pi = partition(arr, low, high);\n    quickSort(arr, low, pi - 1);\n    quickSort(arr, pi + 1, high);\n  }\n}\n\nint partition(int arr[], int low, int high) {\n  // This function takes last element as pivot, places the pivot element at its correct position in sorted array, and places all smaller to left of pivot and all greater elements to right of pivot.\n}"
          },
          "Complexities": {
            "Time Complexity": "Worst Case: O(n^2) when the pivot selection is poor. Average and Best Case: O(n log n) - The array is divided into subarrays that are processed recursively.",
            "Space Complexity": "O(log n) - The space complexity comes from the stack space used for recursion. The worst case is O(n), depending on the implementation."
          }
        }
      },
      {
        "Topic": "Heap Data Structure",
        "Info": {
          "Definition": "A Heap is a special Tree-based data structure that satisfies the heap property. In a max heap, for any given node C, if P is a parent node of C, then the key (the value) of P is greater than or equal to the key of C. The same property must be recursively true for all nodes in Binary Tree. Min heap is a heap where the value of parent nodes is less than or equal to that of child nodes.",
          "Algorithms": {
            "Insert (Heapify Up)": "Inserts a new element into the heap and re-arranges the heap to maintain the heap property.\n\nvoid insert(int key) {\n  heapSize++; // Assume heapSize is the current number of elements in the heap\n  int index = heapSize - 1;\n  heap[index] = key;\n  // Heapify up\n  while (index != 0 && heap[parent(index)] < heap[index]) {\n    swap(heap[index], heap[parent(index)]);\n    index = parent(index);\n  }\n}",
            "Delete (Heapify Down)": "Removes the root element from the heap and re-arranges it to maintain the heap property.\n\nvoid deleteRoot() {\n  if (heapSize <= 0) return;\n  heap[0] = heap[heapSize-1];\n  heapSize--;\n  heapifyDown(0);\n}",
            "Get Max or Min": "Retrieves the maximum element from a max heap or the minimum element from a min heap without removing it.\n\nint getPeak() {\n  return heap[0];\n}",
            "Build Heap (Heapify)": "Converts an unsorted array into a heap.\n\nvoid buildHeap(int arr[], int n) {\n  for (int i = (n / 2) - 1; i >= 0; i--) {\n    heapify(arr, n, i);\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Insert (Heapify Up)": "O(log n) - Because it may traverse from the node inserted at the very end up to the root node.",
              "Delete (Heapify Down)": "O(log n) - Due to the traversal down from the root to the leaf to maintain the heap property.",
              "Get Max or Min": "O(1) - The peak element is always at the root of the heap.",
              "Build Heap (Heapify)": "O(n) - Building the heap from an unsorted array takes linear time."
            },
            "Space Complexity": "O(n) - The space needed to store the heap structure."
          }
        }
      },
      {
        "Topic": "Heap Sort",
        "Info": {
          "Definition": "Heap Sort is a comparison-based sorting technique based on the Binary Heap data structure. It's similar to the selection sort where we first find the maximum element and place it at the end. The same process is repeated for the remaining elements, utilizing a heap to efficiently find the next maximum element.",
          "Algorithms": {
            "Code": "void heapify(int arr[], int n, int i) {\n    int largest = i; // Initialize largest as root\n    int l = 2 * i + 1; // left = 2*i + 1\n    int r = 2 * i + 2; // right = 2*i + 2\n\n    // If left child is larger than root\n    if (l < n && arr[l] > arr[largest])\n        largest = l;\n\n    // If right child is larger than largest so far\n    if (r < n && arr[r] > arr[largest])\n        largest = r;\n\n    // If largest is not root\n    if (largest != i) {\n        swap(arr[i], arr[largest]);\n\n        // Recursively heapify the affected sub-tree\n        heapify(arr, n, largest);\n    }\n}\n\nvoid heapSort(int arr[], int n) {\n    // Build heap (rearrange array)\n    for (int i = n / 2 - 1; i >= 0; i--)\n        heapify(arr, n, i);\n\n    // One by one extract an element from heap\n    for (int i = n - 1; i >= 0; i--) {\n        // Move current root to end\n        swap(arr[0], arr[i]);\n\n        // call max heapify on the reduced heap\n        heapify(arr, i, 0);\n    }\n}"
          },
          "Complexities": {
            "Time Complexity": {
              "Worst Case": "O(n log n)",
              "Average Case": "O(n log n)",
              "Best Case": "O(n log n)"
            },
            "Space Complexity": "O(1) - Heap sort is an in-place algorithm but may require a small stack for recursion during heapify."
          }
        }
      },
      {
        "Topic": "Count Sort",
        "Info": {
          "Definition": "Count Sort is an integer sorting algorithm that operates by counting the number of occurrences of each distinct value in the input array. These counts are then used to compute the position of each element in the sorted array.",
          "Algorithms": {
            "Code": "void countSort(int arr[], int n) {\n    int output[n];\n    int count[256], i;\n    memset(count, 0, sizeof(count));\n\n    for(i = 0; arr[i]; ++i)\n        ++count[arr[i]];\n\n    for (i = 1; i <= 255; ++i)\n        count[i] += count[i-1];\n\n    for (i = 0; arr[i]; ++i) {\n        output[count[arr[i]]-1] = arr[i];\n        --count[arr[i]];\n    }\n\n    for (i = 0; arr[i]; ++i)\n        arr[i] = output[i];\n}"
          },
          "Complexities": {
            "Time Complexity": "O(n + k) - Where n is the number of elements and k is the range of the input.",
            "Space Complexity": "O(k) - The space used by the count array."
          }
        }
      },
      {
        "Topic": "Radix Sort",
        "Info": {
          "Definition": "Radix Sort is a non-comparative sorting algorithm that sorts integers by processing individual digits. Numbers are grouped by each digit, starting from the least significant digit to the most significant digit, using a stable algorithm like Count Sort as a subroutine.",
          "Algorithms": {
            "Code": "void countSort(int arr[], int n, int exp) {\n    vector<int> output(n);\n    int i, count[10] = {0};\n\n    for (i = 0; i < n; i++)\n        count[(arr[i] / exp) % 10]++;\n\n    for (i = 1; i < 10; i++)\n        count[i] += count[i - 1];\n\n    for (i = n - 1; i >= 0; i--) {\n        output[count[(arr[i] / exp) % 10] - 1] = arr[i];\n        count[(arr[i] / exp) % 10]--;\n    }\n\n    for (i = 0; i < n; i++)\n        arr[i] = output[i];\n}\n\nvoid radixSort(int arr[], int n) {\n    int m = getMax(arr, n);\n    for (int exp = 1; m / exp > 0; exp *= 10)\n        countSort(arr, n, exp);\n}"
          },
          "Complexities": {
            "Time Complexity": "O(nk) - Where n is the number of elements and k is the number of digits in the maximum number.",
            "Space Complexity": "O(n + k) - For the intermediate count sort operations."
          }
        }
      },
      {
        "Topic": "Bucket Sort",
        "Info": {
          "Definition": "Bucket Sort, or Bin Sort, operates by partitioning an array into a number of buckets. Each bucket is then sorted individually, either using a different sorting algorithm, or by recursively applying the bucket sort algorithm.",
          "Algorithms": {
            "Code": "void bucketSort(float arr[], int n) {\n    vector<float> b[n];\n    for (int i = 0; i < n; i++) {\n       int bi = n * arr[i]; // Index in bucket\n       b[bi].push_back(arr[i]);\n    }\n\n    for (int i = 0; i < n; i++)\n       sort(b[i].begin(), b[i].end());\n\n    int index = 0;\n    for (int i = 0; i < n; i++)\n       for (int j = 0; j < b[i].size(); j++)\n          arr[index++] = b[i][j];\n}"
          },
          "Complexities": {
            "Time Complexity": "Average Case: O(n + n^2/k + k), and Worst Case: O(n^2). Here, n is the number of elements, and k is the number of buckets.",
            "Space Complexity": "O(n*k) - For the buckets used during sorting."
          }
        }
      },
      {
        "Topic": "Cycle Sort Algorithm",
        "Info": {
          "Definition": "Cycle Sort is an in-place, unstable sorting algorithm ideal for distinct elements, noted for its ability to minimize the number of writes to the memory, which makes it suitable for situations where write operations are costly. It works by considering the array as a collection of cycles, where it moves each element to its correct position within its cycle through a series of rotations, achieving sorting with the minimum number of memory writes.",
          "Algorithms": {
            "Code": "void cycleSort(int arr[], int n) {\n  for (int cycle_start = 0; cycle_start <= n - 2; cycle_start++) {\n    int item = arr[cycle_start];\n    int pos = cycle_start;\n    for (int i = cycle_start + 1; i < n; i++)\n      if (arr[i] < item)\n        pos++;\n    if (pos == cycle_start)\n      continue;\n    while (item == arr[pos])\n      pos += 1;\n    if (pos != cycle_start) {\n      swap(item, arr[pos]);\n    }\n    while (pos != cycle_start) {\n      pos = cycle_start;\n      for (int i = cycle_start + 1; i < n; i++)\n        if (arr[i] < item)\n          pos += 1;\n      while (item == arr[pos])\n        pos += 1;\n      if (item != arr[pos]) {\n        swap(item, arr[pos]);\n      }\n    }\n  }\n}"
          },
          "Complexities": {
            "Time Complexity": "O(n^2), where n is the number of elements in the array. Despite its quadratic time complexity, it has the theoretical minimum number of writes.",
            "Space Complexity": "O(1), as it is an in-place sorting algorithm."
          }
        }
      },
      {
        "Topic": "Pigeonhole Sort Algorithm",
        "Info": {
          "Definition": "Pigeonhole sorting is a sorting algorithm that is suitable for sorting lists of elements where the number of elements (n) and the length of the range of possible key values (N) are approximately the same. It works by assigning each value to a 'pigeonhole' based on its key value and then going through the pigeonholes in order and putting the elements back into the original array in sorted order.",
          "Algorithms": {
            "Code": "void pigeonholeSort(int arr[], int n) {\n  int min = *min_element(arr, arr + n);\n  int max = *max_element(arr, arr + n);\n  int range = max - min + 1;\n  vector<int> holes[range];\n  for (int i = 0; i < n; i++)\n    holes[arr[i] - min].push_back(arr[i]);\n  int index = 0;\n  for (int i = 0; i < range; i++) {\n    for (int j = 0; j < holes[i].size(); j++) {\n      arr[index++] = holes[i][j];\n    }\n  }\n}"
          },
          "Complexities": {
            "Time Complexity": "O(n + N), where n is the number of elements in the array and N is the range of the input.",
            "Space Complexity": "O(n + N), for the pigeonholes used to sort the elements."
          }
        }
      },
      {
        "Topic": "Comb Sort Algorithm",
        "Info": {
          "Definition": "Comb sort is an improvement on the Bubble Sort algorithm. Like Bubble Sort, Comb Sort also involves comparing and swapping adjacent elements but tries to eliminate turtles or small values near the end of the list, as these are what slow down the sorting process. It achieves this by using a gap that is larger than 1, allowing swaps of elements far apart. The gap size is reduced at each step until it becomes 1, making the algorithm essentially Bubble Sort, but by this time, most turtles have been dealt with, making the final sorting phase efficient.",
          "Algorithms": {
            "Code": "void combSort(int arr[], int n) {\n  int gap = n;\n  bool swapped = true;\n  while (gap != 1 || swapped == true) {\n    gap = (gap * 10) / 13;\n    if (gap < 1)\n      gap = 1;\n    swapped = false;\n    for (int i = 0; i < n - gap; i++) {\n      if (arr[i] > arr[i + gap]) {\n        swap(arr[i], arr[i + gap]);\n        swapped = true;\n      }\n    }\n  }\n}"
          },
          "Complexities": {
            "Time Complexity": "Average case: O(n^2/2^p), where p is the number of increments. The worst-case time complexity is O(n^2), but in practical scenarios, it tends to be closer to O(n log n) for partially sorted sequences.",
            "Space Complexity": "O(1), as it only requires a constant amount of extra space."
          }
        }
      },
      {
        "Topic": "Dijkstra's Algorithm",
        "Info": {
          "Definition": "Dijkstra's Algorithm finds the shortest paths from a single source vertex to all other vertices in a weighted graph with non-negative edge weights.",
          "Algorithms": {
            "Code": "void dijkstra(const vector<vector<int>>& graph, int src) {\n  int V = graph.size();\n  vector<int> dist(V, INT_MAX);\n  dist[src] = 0;\n  vector<bool> sptSet(V, false);\n\n  for (int count = 0; count < V-1; count++) {\n    int u = -1;\n    for(int i = 0; i < V; i++)\n      if (!sptSet[i] && (u == -1 || dist[i] < dist[u]))\n        u = i;\n    sptSet[u] = true;\n    for (int v = 0; v < V; v++)\n      if (!sptSet[v] && graph[u][v] && dist[u] != INT_MAX && dist[u]+graph[u][v] < dist[v])\n        dist[v] = dist[u] + graph[u][v];\n  }\n}"
          },
          "Complexities": {
            "Time Complexity": "O(V^2) - For the implementation using adjacency matrix. With a priority queue, it can be reduced to O(V + E log V) where E is the number of edges.",
            "Space Complexity": "O(V) - Space needed for the distance array and the sptSet."
          }
        }
      },
      {
        "Topic": "Minimal Spanning Tree",
        "Info": {
          "Definition": "A Minimal Spanning Tree (MST) of a connected, undirected graph is a tree formed from graph edges that connects all the vertices together, without any cycles and with the minimum possible total edge weight. Finding a MST is a key problem in network design, such as designing the least expensive network, road, electrical grid, or in any application where a problem can be represented as a weighted graph. The two most famous algorithms for finding a MST are Kruskal's algorithm and Prim's algorithm.",
          "Algorithms": {
            "Kruskal's Algorithm Implementation": "struct Edge { int src, dest, weight; };\nvector<int> parent, rank;\nint find(int i) {\n  if (parent[i] != i)\n    parent[i] = find(parent[i]);\n  return parent[i];\n}\nvoid unionSet(int x, int y) {\n  x = find(x);\n  y = find(y);\n  if (rank[x] > rank[y])\n    parent[y] = x;\n  else\n    parent[x] = y;\n  if (rank[x] == rank[y])\n    rank[y]++;\n}\nvoid KruskalMST(vector<Edge>& edges, int V) {\n  sort(edges.begin(), edges.end(), [](Edge a, Edge b) { return a.weight < b.weight; });\n  parent.resize(V);\n  rank.resize(V, 0);\n  for (int i = 0; i < V; i++)\n    parent[i] = i;\n  vector<Edge> mst;\n  for (Edge e : edges) {\n    if (find(e.src) != find(e.dest)) {\n      unionSet(e.src, e.dest);\n      mst.push_back(e);\n    }\n  }\n}",
            "Prim's Algorithm Implementation": "int minKey(vector<int>& key, vector<bool>& mstSet, int V) {\n  int min = INT_MAX, min_index;\n  for (int v = 0; v < V; v++)\n    if (mstSet[v] == false && key[v] < min)\n      min = key[v], min_index = v;\n  return min_index;\n}\nvoid primMST(vector<vector<int>>& graph, int V) {\n  vector<int> parent(V);\n  vector<int> key(V, INT_MAX);\n  vector<bool> mstSet(V, false);\n  key[0] = 0;\n  parent[0] = -1;\n  for (int count = 0; count < V-1; count++) {\n    int u = minKey(key, mstSet, V);\n    mstSet[u] = true;\n    for (int v = 0; v < V; v++)\n      if (graph[u][v] && mstSet[v] == false && graph[u][v] < key[v])\n        parent[v] = u, key[v] = graph[u][v];\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Kruskal's Algorithm": "O(E log E) or O(E log V), where E is the number of edges and V is the number of vertices.",
              "Prim's Algorithm": "O(E log V) using a binary heap and adjacency list, where E is the number of edges and V is the number of vertices."
            },
            "Space Complexity": {
              "Kruskal's Algorithm": "O(E + V), for storing the edge list and the disjoint set data structure.",
              "Prim's Algorithm": "O(V), for storing the keys, parents, and priority queue or heap."
            }
          }
        }
      },
      {
        "Topic": "Kruskal's Algorithm",
        "Info": {
          "Definition": "Kruskal's Algorithm finds a minimum spanning tree for a connected, undirected graph by adding increasing cost edges at each step, avoiding any cycles.",
          "Algorithms": {
            "Code": "struct Edge { int src, dest, weight; };\nstruct Graph { int V, E; vector<Edge> edges; };\nint find(vector<int>& parent, int i) {\n  if (parent[i] == i) return i;\n  return find(parent, parent[i]);\n}\nvoid kruskalMST(struct Graph& graph) {\n  sort(graph.edges.begin(), graph.edges.end(), [](Edge a, Edge b) { return a.weight < b.weight; });\n  vector<int> parent(graph.V);\n  for (int i = 0; i < graph.V; i++) parent[i] = i;\n  vector<Edge> mst;\n  for (Edge e : graph.edges) {\n    int x = find(parent, e.src);\n    int y = find(parent, e.dest);\n    if (x != y) {\n      mst.push_back(e);\n      parent[x] = y;\n    }\n  }\n  // mst contains the resulting minimum spanning tree\n}"
          },
          "Complexities": {
            "Time Complexity": "O(E log E) - Or O(E log V) because of the sorting of edges, where E is the number of edges in the graph.",
            "Space Complexity": "O(V + E) - For storing the graph and the minimum spanning tree."
          }
        }
      },
      {
        "Topic": "Prim's Algorithm",
        "Info": {
          "Definition": "Prim's Algorithm is a greedy algorithm that finds the minimum spanning tree for a weighted undirected graph, ensuring that every vertex is connected without any cycles and with the minimum possible total edge weight.",
          "Algorithms": {
            "Code": "void primMST(int graph[V][V]) {\n    int parent[V];\n    int key[V];\n    bool mstSet[V];\n    for (int i = 0; i < V; i++)\n        key[i] = INT_MAX, mstSet[i] = false;\n    key[0] = 0;\n    parent[0] = -1;\n    for (int count = 0; count < V-1; count++) {\n        int u = minKey(key, mstSet);\n        mstSet[u] = true;\n        for (int v = 0; v < V; v++)\n            if (graph[u][v] && !mstSet[v] && graph[u][v] < key[v])\n                parent[v] = u, key[v] = graph[u][v];\n    }\n    printMST(parent, V, graph);\n}"
          },
          "Complexities": {
            "Time Complexity": "O(V^2) - For a graph represented using adjacency matrix. Can be improved to O(E log V) with adjacency list and priority queue.",
            "Space Complexity": "O(V) - To store the keys, MST set, and parent array."
          }
        }
      },
      {
        "Topic": "Recursion and Backtracking",
        "Info": {
          "Definition": "Recursion\nRecursion is a method of solving a problem where the solution depends on solutions to smaller instances of the same problem. A recursive function calls itself with a base case to stop the recursion.\nBacktracking\nBacktracking is an algorithmic-technique for solving problems recursively by trying to build a solution incrementally, one piece at a time, removing those solutions that fail to satisfy the constraints of the problem at any point of time.",

          "Algorithms": {
            "Recursion Example - Factorial": "int factorial(int n) {\n  if (n <= 1) return 1;\n  return n * factorial(n - 1);\n}",
            "Backtracking Example - N Queens Problem": "bool isSafe(int board[N][N], int row, int col) {\n  // Check this row on left side\n  // Check upper diagonal on left side\n  // Check lower diagonal on left side\n  // For simplification, these checks are omitted\n  return true;\n}\n\nbool solveNQUtil(int board[N][N], int col) {\n  if (col >= N) return true;\n  for (int i = 0; i < N; i++) {\n    if (isSafe(board, i, col)) {\n      board[i][col] = 1;\n      if (solveNQUtil(board, col + 1)) return true;\n      board[i][col] = 0; // BACKTRACK\n    }\n  }\n  return false;\n}"
          },
          "Complexities": {
            "Time Complexity": {
              "Recursion Example - Factorial": "O(n) - The time complexity is linear, as it makes a single call for each decrement of n until it reaches the base case.",
              "Backtracking Example - N Queens Problem": "O(N!) - The worst-case time complexity, as it tries every possible arrangement of queens."
            },
            "Space Complexity": {
              "Recursion Example - Factorial": "O(n) - Due to the call stack in recursion for each function call until the base case is reached.",
              "Backtracking Example - N Queens Problem": "O(N) - Mainly for the call stack in recursion. Additional space for the board is not considered here."
            }
          }
        }
      },
      {
        "Topic": "Backtracking Applications",
        "Info": {
          "Definition": "Backtracking is an algorithmic technique for solving problems recursively by trying to build a solution incrementally, one piece at a time, and removing those solutions that fail to satisfy the constraints of the problem at any point of time. It is particularly useful for traversal problems, constraint satisfaction problems like Sudoku solver, N queens problem, and graph coloring.",
          "Algorithms": {
            "Sudoku Solver": "void solveSudoku(vector<vector<int>>& board) {\n  if(solve(board)) {\n    print(board);\n  }\n}\nbool solve(vector<vector<int>>& board) {\n  for(int i = 0; i < board.size(); i++) {\n    for(int j = 0; j < board[0].size(); j++) {\n      if(board[i][j] == 0) {\n        for(int c = 1; c <= 9; c++) {\n          if(isValid(board, i, j, c)) {\n            board[i][j] = c;\n            if(solve(board))\n              return true;\n            else\n              board[i][j] = 0;\n          }\n        }\n        return false;\n      }\n    }\n  }\n  return true;\n}",
            "N Queens Problem": "bool solveNQ(vector<vector<int>>& board, int col) {\n  if(col >= N) return true;\n  for(int i = 0; i < N; i++) {\n    if(isSafe(board, i, col)) {\n      board[i][col] = 1;\n      if(solveNQ(board, col + 1)) return true;\n      board[i][col] = 0; // backtrack\n    }\n  }\n  return false;\n}",
            "Graph Coloring": "bool graphColoring(vector<int> graph[], int m, int V) {\n  vector<int> color(V, 0);\n  if(!graphColoringUtil(graph, m, color, 0, V)) {\n    return false;\n  }\n  return true;\n}\nbool graphColoringUtil(vector<int> graph[], int m, vector<int>& color, int v, int V) {\n  if(v == V) return true;\n  for(int c = 1; c <= m; c++) {\n    if(isSafe(v, graph, color, c, V)) {\n      color[v] = c;\n      if(graphColoringUtil(graph, m, color, v+1, V)) return true;\n      color[v] = 0; // backtrack\n    }\n  }\n  return false;\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Sudoku Solver": "O(9^(n^2)), where n is the number of rows/columns of the board (typically 9)",
              "N Queens Problem": "O(N!), where N is the number of queens",
              "Graph Coloring": "O(m^V), where m is the number of colors and V is the number of vertices"
            },
            "Space Complexity": {
              "Sudoku Solver": "O(n^2), for storing the board",
              "N Queens Problem": "O(N), for the recursion call stack",
              "Graph Coloring": "O(V), for storing colors assigned to vertices"
            }
          }
        }
      },
      {
        "Topic": "Disjoint Set Union (Union Find)",
        "Info": {
          "Definition": "Disjoint Set Union (DSU), also known as Union Find, is a data structure that keeps track of a set of elements partitioned into a number of disjoint (non-overlapping) subsets. It supports two key operations: 'find', which identifies the subset to which an element belongs; and 'union', which merges two subsets. It's particularly useful for graph-based algorithms, such as finding cycles and building minimum spanning trees.",
          "Algorithms": {
            "Union Find Implementation": "class UnionFind {\nprivate:\n  vector<int> parent, rank;\npublic:\n  UnionFind(int N) {\n    parent.resize(N);\n    rank.resize(N, 0);\n    for(int i = 0; i < N; ++i) parent[i] = i;\n  }\n  int find(int x) {\n    if (parent[x] != x) {\n      parent[x] = find(parent[x]); // Path compression\n    }\n    return parent[x];\n  }\n  void unionSet(int x, int y) {\n    int xRoot = find(x), yRoot = find(y);\n    if (xRoot != yRoot) {\n      if (rank[xRoot] < rank[yRoot]) {\n        parent[xRoot] = yRoot;\n      } else if (rank[xRoot] > rank[yRoot]) {\n        parent[yRoot] = xRoot;\n      } else {\n        parent[yRoot] = xRoot;\n        rank[xRoot] = rank[xRoot] + 1;\n      }\n    }\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Find": "Amortized O((n)), where (n) is the inverse Ackermann function. Practically, it's almost constant.",
              "Union": "Amortized O((n)), as it includes the cost of two find operations plus the cost of the union."
            },
            "Space Complexity": {
              "Union Find": "O(n), where n is the number of elements, for storing the parent and rank arrays."
            }
          }
        }
      },
      {
        "Topic": "Fractional Knapsack",
        "Info": {
          "Definition": "The Fractional Knapsack problem is a problem in combinatorial optimization. Given a set of items, each with a weight and a value, determine the amount of each item to include in a collection so that the total weight is less than or equal to a given limit and the total value is as large as possible. Unlike the 0/1 Knapsack problem, items may be broken into smaller pieces, hence 'fractional'. The solution is found using a greedy approach.",
          "Algorithms": {
            "Fractional Knapsack Algorithm": "struct Item {\n  int value, weight;\n};\nbool cmp(Item a, Item b) {\n  double r1 = (double)a.value / a.weight;\n  double r2 = (double)b.value / b.weight;\n  return r1 > r2;\n}\ndouble fractionalKnapsack(int W, Item arr[], int n) {\n  sort(arr, arr + n, cmp);\n  int curWeight = 0;\n  double finalvalue = 0.0;\n  for (int i = 0; i < n; i++) {\n    if (curWeight + arr[i].weight <= W) {\n      curWeight += arr[i].weight;\n      finalvalue += arr[i].value;\n    } else {\n      int remain = W - curWeight;\n      finalvalue += arr[i].value * ((double) remain / arr[i].weight);\n      break;\n    }\n  }\n  return finalvalue;\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Fractional Knapsack Algorithm": "O(n log n) for sorting the items based on their value/weight ratio, followed by O(n) for computing the final value."
            },
            "Space Complexity": {
              "Fractional Knapsack Algorithm": "O(1), not including the input space, as no additional space is needed beyond variables for calculation."
            }
          }
        }
      },
      {
        "Topic": "Job Scheduling in Greedy Algorithm",
        "Info": {
          "Definition": "Job scheduling is a common problem in computer science, where jobs with different deadlines and profits need to be scheduled in a way that maximizes total profit. The greedy approach to this problem involves sorting the jobs based on a specific criterion, such as profit or deadline, and then scheduling the jobs in a way that maximizes profit while meeting deadlines.",
          "Algorithms": {
            "Job Scheduling Algorithm": "struct Job {\n  char id;\n  int deadline, profit;\n};\nbool comparison(Job a, Job b) {\n  return (a.profit > b.profit);\n}\nvoid printJobScheduling(vector<Job> arr, int n) {\n  sort(arr.begin(), arr.end(), comparison);\n  vector<int> result(n, -1);\n  vector<bool> slot(n, false);\n  for (int i = 0; i < n; i++) {\n    for (int j = min(n, arr[i].deadline) - 1; j >= 0; j--) {\n      if (slot[j] == false) {\n        result[j] = i;\n        slot[j] = true;\n        break;\n      }\n    }\n  }\n  for (int i = 0; i < n; i++)\n    if (slot[i])\n      cout << arr[result[i]].id << ' ';\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Job Scheduling Algorithm": "O(n log n) for sorting the jobs by profit, followed by O(n^2) for scheduling jobs where n is the number of jobs."
            },
            "Space Complexity": {
              "Job Scheduling Algorithm": "O(n) for storing the result and slot arrays."
            }
          }
        }
      },
      {
        "Topic": "Memoization & Tabulation in Dynamic Programming",
        "Info": {
          "Definition": "Memoization and Tabulation are optimization techniques used in dynamic programming to reduce the computation time of recursive algorithms by storing results of expensive function calls. Memoization is a top-down approach, where results are stored in a table as they are computed from the recursive calls. Tabulation is a bottom-up approach, where the table is filled in order systematically, ensuring that all sub-problems are solved before solving the larger problem.",
          "Algorithms": {
            "Memoization Example (Fibonacci)": "int fib(int n, vector<int>& memo) {\n  if (n <= 1) return n;\n  if (memo[n] != -1) return memo[n];\n  memo[n] = fib(n-1, memo) + fib(n-2, memo);\n  return memo[n];\n}",
            "Tabulation Example (Fibonacci)": "int fib(int n) {\n  vector<int> table(n+1, 0);\n  table[1] = 1;\n  for(int i = 2; i <= n; i++) {\n    table[i] = table[i-1] + table[i-2];\n  }\n  return table[n];\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Memoization Example": "O(n), as it ensures that each problem is solved only once",
              "Tabulation Example": "O(n), similar efficiency but fills in a table from the bottom up"
            },
            "Space Complexity": {
              "Memoization Example": "O(n), for storing the memoization table plus the recursion call stack",
              "Tabulation Example": "O(n), for storing the tabulation table without additional space for recursion"
            }
          }
        }
      },
      {
        "Topic": "Traveling Salesman Problem",
        "Info": {
          "Definition": "The Traveling Salesman Problem (TSP) is a classic algorithmic problem in the field of computer science and operations research. It asks for the shortest possible route that visits a set of cities, each exactly once, and returns to the origin city. It is an NP-hard problem in combinatorial optimization, important in theoretical computer science and optimization.",
          "Algorithms": {
            "Brute Force Solution": "int tsp(vector<vector<int>>& graph, vector<bool>& v, int currPos, int n, int count, int cost, int ans) {\n  if (count == n && graph[currPos][0]) {\n    ans = min(ans, cost + graph[currPos][0]);\n    return ans;\n  }\n  for (int i = 0; i < n; i++) {\n    if (!v[i] && graph[currPos][i]) {\n      v[i] = true;\n      ans = tsp(graph, v, i, n, count + 1, cost + graph[currPos][i], ans);\n      v[i] = false;\n    }\n  }\n  return ans;\n}",
            "Dynamic Programming Solution (Held-Karp Algorithm)": "int tspDP(vector<vector<int>>& distance) {\n  int n = distance.size();\n  vector<vector<int>> dp(1 << n, vector<int>(n, INT_MAX));\n  dp[1][0] = 0;\n  for (int mask = 1; mask < (1 << n); mask += 2) {\n    for (int i = 1; i < n; i++) {\n      if ((mask & (1 << i)) != 0) {\n        for (int j = 0; j < n; j++) {\n          if ((mask & (1 << j)) != 0) {\n            dp[mask][i] = min(dp[mask][i], dp[mask ^ (1 << i)][j] + distance[j][i]);\n          }\n        }\n      }\n    }\n  }\n  int ans = INT_MAX;\n  for (int i = 1; i < n; i++) {\n    ans = min(ans, dp[(1 << n) - 1][i] + distance[i][0]);\n  }\n  return ans;\n}"
          },
          "Complexities": {
            "Time Complexity": {
              "Brute Force Solution": "O(n!), where n is the number of cities. This approach examines every possible tour.",
              "Dynamic Programming Solution": "O(n^2 * 2^n), significantly more efficient than brute force for small to medium-sized sets of cities."
            },
            "Space Complexity": {
              "Brute Force Solution": "O(n), due to the recursion stack.",
              "Dynamic Programming Solution": "O(n * 2^n), for storing the dynamic programming table."
            }
          }
        }
      },
      {
        "Topic": "Subset Sum Problem",
        "Info": {
          "Definition": "The Subset Sum Problem is a classic problem in computer science and combinatorial optimization. Given a set of integers and a target sum, the problem is to determine if there exists a subset of the given set whose sum is equal to the given target sum. It is a particular case of the Knapsack Problem and is known to be NP-complete.",
          "Algorithms": {
            "Recursive Solution": "bool isSubsetSum(vector<int>& set, int n, int sum) {\n  if (sum == 0) return true;\n  if (n == 0) return false;\n  if (set[n-1] > sum) return isSubsetSum(set, n-1, sum);\n  return isSubsetSum(set, n-1, sum) || isSubsetSum(set, n-1, sum-set[n-1]);\n}",
            "Dynamic Programming Solution": "bool isSubsetSumDP(vector<int>& set, int sum) {\n  int n = set.size();\n  vector<vector<bool>> dp(n+1, vector<bool>(sum+1, false));\n  for (int i = 0; i <= n; i++) dp[i][0] = true;\n  for (int i = 1; i <= n; i++) {\n    for (int j = 1; j <= sum; j++) {\n      if (set[i-1] <= j) dp[i][j] = dp[i-1][j] || dp[i-1][j-set[i-1]];\n      else dp[i][j] = dp[i-1][j];\n    }\n  }\n  return dp[n][sum];\n}"
          },
          "Complexities": {
            "Time Complexity": {
              "Recursive Solution": "O(2^n), where n is the number of elements in the set. This is due to the generation of all subsets.",
              "Dynamic Programming Solution": "O(n*sum), where n is the number of elements and sum is the target sum, due to the use of a 2D array."
            },
            "Space Complexity": {
              "Recursive Solution": "O(n), for the recursion stack.",
              "Dynamic Programming Solution": "O(n*sum), for storing the DP table."
            }
          }
        }
      }
    ]
  },
  {
    "category": "Hard",
    "Problems": [
      {
        "Topic": "Hash Table",
        "Info": {
          "Definition": "A hash table, also known as a hash map, is a data structure that implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index into an array of buckets or slots, from which the desired value can be found.",
          "Algorithms": {
            "Code": "class HashTable {\nprivate:\n  int BUCKET;\n  list<int> *table;\npublic:\n  HashTable(int V);\n  void insertItem(int key, int value);\n  void deleteItem(int key);\n  int hashFunction(int x) {\n    return (x % BUCKET);\n  }\n};\n\nHashTable::HashTable(int b) {\n  this->BUCKET = b;\n  table = new list<int>[BUCKET];\n}\n\nvoid HashTable::insertItem(int key, int value) {\n  int index = hashFunction(key);\n  table[index].push_back(value);\n}\n\nvoid HashTable::deleteItem(int key) {\n  int index = hashFunction(key);\n  list<int>::iterator i;\n  for (i = table[index].begin(); i != table[index].end(); i++) {\n    if (*i == key)\n      break;\n  }\n  if (i != table[index].end())\n    table[index].erase(i);\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Average case (insert/search/delete)": "O(1)",
              "Worst case (insert/search/delete)": "O(n) - Occurs when all keys are mapped to a single bucket"
            },
            "Space Complexity": "O(n) - Where n is the number of keys stored in the hash table."
          }
        }
      },
      {
        "Topic": "Hashing Techniques",
        "Info": {
          "Definition": "Hashing techniques are methods used to store and retrieve data efficiently by converting the key into a unique hash index where the value is stored. This process allows for fast data access. Common hashing techniques include Chaining and Open Addressing, which address collisions - when two keys hash to the same index - in different ways.",
          "Algorithms": {
            "Chaining": "Chaining involves using an array of linked lists. The hash function assigns an index to each key, and the key-value pair is then added to the linked list at that index. This allows multiple values to exist at the same index, effectively handling collisions.",
            "Open Addressing": "Open Addressing resolves collisions by finding another empty slot or bucket within the array for the key-value pair. Common methods include Linear Probing, where the next empty slot is found in a linear sequence; Quadratic Probing, which searches for an empty slot based on a quadratic formula; and Double Hashing, which uses a second hash function to find an empty slot.",
            "Linear Probing": "void insert(key, value) { int index = hashFunction(key); while(array[index] is not empty) { index = (index + 1) % array_size; } array[index] = value; }",
            "Quadratic Probing": "void insert(key, value) { int index = hashFunction(key); int i = 0; while(array[(index + i*i) % array_size] is not empty) { i++; } array[(index + i*i) % array_size] = value; }",
            "Double Hashing": "void insert(key, value) { int index1 = hashFunction1(key); int index2 = hashFunction2(key); int i = 0; while(array[(index1 + i*index2) % array_size] is not empty) { i++; } array[(index1 + i*index2) % array_size] = value; }"
          },
          "Complexities": {
            "Time Complexities": {
              "Chaining": "Average: O(1), Worst: O(n), where n is the number of keys",
              "Open Addressing": "Average: O(1), Worst: O(n), although performance degrades with increased loading factor",
              "Linear Probing": "Average: O(1), Worst: O(n)",
              "Quadratic Probing": "Average: O(1), Worst: O(n)",
              "Double Hashing": "Average: O(1), Worst: O(n)"
            },
            "Space Complexity": {
              "Chaining": "O(n), where n is the number of keys, potentially more due to linked list overhead",
              "Open Addressing": "O(n), where n is the size of the array. Typically requires a larger array size than chaining to maintain performance",
              "Linear Probing": "O(n), where n is the size of the array",
              "Quadratic Probing": "O(n), where n is the size of the array",
              "Double Hashing": "O(n), where n is the size of the array"
            }
          }
        }
      },
      {
        "Topic": "Trie Data Structure",
        "Info": {
          "Definition": "A trie, also known as a prefix tree or digital tree, is a type of search tree used to store a dynamic set or associative array where the keys are usually strings. Unlike a binary search tree, no node in the trie stores the key associated with that node; instead, its position in the tree defines the key with which it is associated. All the descendants of a node have a common prefix of the string associated with that node, and the root is associated with the empty string.",
          "Algorithms": {
            "Insertion": "void insert(string key) {\n  TrieNode* node = root;\n  for (char ch : key) {\n    if (!node->children[ch - 'a'])\n      node->children[ch - 'a'] = new TrieNode();\n    node = node->children[ch - 'a'];\n  }\n  node->isEndOfWord = true;\n}",
            "Search": "bool search(string key) {\n  TrieNode* node = root;\n  for (char ch : key) {\n    if (!node->children[ch - 'a'])\n      return false;\n    node = node->children[ch - 'a'];\n  }\n  return node != nullptr && node->isEndOfWord;\n}",
            "StartsWith": "bool startsWith(string prefix) {\n  TrieNode* node = root;\n  for (char ch : prefix) {\n    if (!node->children[ch - 'a'])\n      return false;\n    node = node->children[ch - 'a'];\n  }\n  return true;\n}",
            "Deletion": "bool deleteWord(TrieNode* node, string key, int depth = 0) {\n  if (node) {\n    if (depth == key.size()) {\n      if (node->isEndOfWord) {\n        node->isEndOfWord = false;\n        return isEmpty(node);\n      }\n    } else {\n      int index = key[depth] - 'a';\n      if (deleteWord(node->children[index], key, depth + 1) && !node->isEndOfWord) {\n        delete node->children[index];\n        node->children[index] = nullptr;\n        return isEmpty(node);\n      }\n    }\n  }\n  return false;\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Insertion": "O(m), where m is the key length",
              "Search": "O(m), where m is the key length",
              "StartsWith": "O(m), where m is the prefix length",
              "Deletion": "O(m), where m is the key length"
            },
            "Space Complexity": {
              "Insertion": "O(m), for inserting a key of length m",
              "Search": "O(1), does not require additional space",
              "StartsWith": "O(1), does not require additional space",
              "Deletion": "O(m), in the worst case, for deleting a key of length m"
            }
          }
        }
      },
      {
        "Topic": "0/1 Knapsack Problem",
        "Info": {
          "Definition": "The 0/1 Knapsack Problem is a problem in combinatorial optimization where one has to maximize the total value of items in a knapsack without exceeding its capacity. Each item can either be included or excluded, hence the name 0/1.",
          "Algorithms": {
            "Code": "int knapSack(int W, int wt[], int val[], int n) {\n   vector<vector<int>> dp(n+1, vector<int>(W+1, 0));\n   for(int i = 1; i <= n; i++) {\n       for(int w = 1; w <= W; w++) {\n           if(wt[i-1] <= w)\n               dp[i][w] = max(val[i-1] + dp[i-1][w-wt[i-1]], dp[i-1][w]);\n           else\n               dp[i][w] = dp[i-1][w];\n       }\n   }\n   return dp[n][W];\n}"
          },
          "Complexities": {
            "Time Complexity": "O(nW) - Where n is the number of items and W is the capacity of the knapsack.",
            "Space Complexity": "O(nW) - For the DP table storing solutions for subproblems."
          }
        }
      },
      {
        "Topic": "Longest Common Subsequence",
        "Info": {
          "Definition": "The Longest Common Subsequence (LCS) problem involves finding the longest subsequence present in two sequences (not necessarily contiguous) such that the subsequence is common to both.",
          "Algorithms": {
            "Code": "int lcs(string &X, string &Y) {\n   int m = X.length(), n = Y.length();\n   vector<vector<int>> dp(m+1, vector<int>(n+1));\n   for(int i=1; i<=m; i++) {\n       for(int j=1; j<=n; j++) {\n           if(X[i-1] == Y[j-1])\n               dp[i][j] = dp[i-1][j-1] + 1;\n           else\n               dp[i][j] = max(dp[i-1][j], dp[i][j-1]);\n       }\n   }\n   return dp[m][n];\n}"
          },
          "Complexities": {
            "Time Complexity": "O(mn) - Where m and n are the lengths of the two sequences.",
            "Space Complexity": "O(mn) - For the DP table."
          }
        }
      },
      {
        "Topic": "Matrix Chain Multiplication",
        "Info": {
          "Definition": "Matrix Chain Multiplication is a dynamic programming problem that aims to determine the most efficient way to multiply a given sequence of matrices together. The goal is to find the optimal parenthesization of the matrices such that the number of scalar multiplications is minimized. The problem does not involve actually multiplying the matrices, but rather determining the order in which to perform the multiplications.",
          "Algorithms": {
            "Recursive Solution": "int MatrixChainOrder(int p[], int i, int j) {\n  if(i == j)\n    return 0;\n  int min = INT_MAX;\n  for (int k = i; k < j; k++) {\n    int count = MatrixChainOrder(p, i, k) +\n                MatrixChainOrder(p, k+1, j) +\n                p[i-1]*p[k]*p[j];\n    if (count < min)\n      min = count;\n  }\n  return min;\n}",
            "Dynamic Programming Solution": "int MatrixChainOrder(int p[], int n) {\n  int m[n][n];\n  for (int i=1; i<n; i++)\n    m[i][i] = 0;\n  for (int L=2; L<n; L++) {\n    for (int i=1; i<n-L+1; i++) {\n      int j = i+L-1;\n      m[i][j] = INT_MAX;\n      for (int k=i; k<=j-1; k++) {\n        int q = m[i][k] + m[k+1][j] + p[i-1]*p[k]*p[j];\n        if (q < m[i][j])\n          m[i][j] = q;\n      }\n    }\n  }\n  return m[1][n-1];\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Recursive Solution": "O(2^n), where n is the number of matrices. This approach has exponential time complexity due to the recomputation of subproblems.",
              "Dynamic Programming Solution": "O(n^3), where n is the number of matrices. This approach optimizes the recursive solution by solving each subproblem only once."
            },
            "Space Complexity": {
              "Recursive Solution": "O(n), for the recursion call stack, where n is the depth of the recursion tree.",
              "Dynamic Programming Solution": "O(n^2), for storing the results of subproblems in a 2D array."
            }
          }
        }
      },
      {
        "Topic": "Floyd-Warshall Algorithm",
        "Info": {
          "Definition": "The Floyd-Warshall Algorithm is a dynamic programming solution for finding the shortest paths between all pairs of vertices in a weighted graph. It can handle negative weight edges but not negative weight cycles.",
          "Algorithms": {
            "Code": "void floydWarshall(int graph[][V]) {\n    int dist[V][V], i, j, k;\n    for (i = 0; i < V; i++)\n        for (j = 0; j < V; j++)\n            dist[i][j] = graph[i][j];\n    for (k = 0; k < V; k++) {\n        for (i = 0; i < V; i++) {\n            for (j = 0; j < V; j++) {\n                if (dist[i][k] + dist[k][j] < dist[i][j])\n                    dist[i][j] = dist[i][k] + dist[k][j];\n            }\n        }\n    }\n}"
          },
          "Complexities": {
            "Time Complexity": "O(V^3) - The algorithm runs three nested loops over the graph's vertices, where V is the number of vertices in the graph.",
            "Space Complexity": "O(V^2) - Space needed to store the distance matrix."
          }
        }
      },
      {
        "Topic": "Transitive Closure",
        "Info": {
          "Definition": "The transitive closure of a graph is a measure of which vertices are reachable from other vertices through a path in the graph. In more formal terms, if there exists a path from vertex u to vertex v, then v is considered reachable from u. The transitive closure of a graph can be represented as a matrix, where the element at the ith row and jth column is 1 if there is a path from vertex i to vertex j, and 0 otherwise. The Floyd-Warshall algorithm is a common method used to compute the transitive closure of a graph.",
          "Algorithms": {
            "Floyd-Warshall Algorithm for Transitive Closure": "void transitiveClosure(vector<vector<int>>& graph) {\n  int V = graph.size();\n  vector<vector<int>> tc(V, vector<int>(V));\n  for (int i = 0; i < V; i++)\n    for (int j = 0; j < V; j++)\n      tc[i][j] = graph[i][j];\n  for (int k = 0; k < V; k++) {\n    for (int i = 0; i < V; i++) {\n      for (int j = 0; j < V; j++) {\n        if (tc[i][k] + tc[k][j] < tc[i][j])\n          tc[i][j] = tc[i][k] + tc[k][j];\n      }\n    }\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Floyd-Warshall Algorithm": "O(V^3), where V is the number of vertices in the graph."
            },
            "Space Complexity": {
              "Floyd-Warshall Algorithm": "O(V^2), for storing the transitive closure matrix."
            }
          }
        }
      },
      {
        "Topic": "Huffman Coding",
        "Info": {
          "Definition": "Huffman Coding is a widely used method of lossless data compression, which assigns variable-length codes to input characters, with shorter codes for more frequent characters. This algorithm uses a greedy technique to build a prefix-free binary tree called Huffman Tree.",
          "Algorithms": {
            "Code": "void buildHuffmanTree(vector<char>& data, vector<int>& freq, int size) {\n    priority_queue<HuffmanNode*, vector<HuffmanNode*>, compare> minHeap;\n    for (int i = 0; i < size; ++i)\n        minHeap.push(new HuffmanNode(data[i], freq[i]));\n    while (minHeap.size() != 1) {\n        HuffmanNode* left = minHeap.top(); minHeap.pop();\n        HuffmanNode* right = minHeap.top(); minHeap.pop();\n        HuffmanNode* top = new HuffmanNode('$', left->freq + right->freq);\n        top->left = left;\n        top->right = right;\n        minHeap.push(top);\n    }\n    printCodes(minHeap.top(), \"\");\n}"
          },
          "Complexities": {
            "Time Complexity": "O(n log n) - Where n is the number of unique characters. If there are N nodes, there will be N-1 merge operations and each operation involves a heap operation of O(log n).",
            "Space Complexity": "O(n) - To store the tree."
          }
        }
      },
      {
        "Topic": "Shell Sort",
        "Info": {
          "Definition": "Shell Sort is an in-place comparison sort which generalizes insertion sort to allow the exchange of items that are far apart. The idea is to arrange the list of elements so that, starting anywhere, taking every hth element produces a sorted list.",
          "Algorithms": {
            "Code": "void shellSort(int arr[], int n) {\n    for (int gap = n/2; gap > 0; gap /= 2) {\n        for (int i = gap; i < n; i += 1) {\n            int temp = arr[i];\n            int j;\n            for (j = i; j >= gap && arr[j - gap] > temp; j -= gap)\n                arr[j] = arr[j - gap];\n            arr[j] = temp;\n        }\n    }\n}"
          },
          "Complexities": {
            "Time Complexity": "Worst-case time complexity is O(n^2), but it can perform better on partially sorted arrays. The best case is O(n log n).",
            "Space Complexity": "O(1) - It is an in-place sorting algorithm."
          }
        }
      },
      {
        "Topic": "Graph Cycle Detection (in Directed and Undirected Graphs)",
        "Info": {
          "Definition": "Cycle detection in graphs is a fundamental algorithmic problem that involves finding whether a graph contains a cycle. A cycle occurs when a path exists in the graph that starts and ends at the same vertex. The approach to cycle detection varies between directed and undirected graphs due to the nature of the edges.",
          "Algorithms": {
            "DFS for Undirected Graphs": "bool isCyclicUtil(int v, bool visited[], int parent, vector<int> adj[]) {\n  visited[v] = true;\n  for (auto i = adj[v].begin(); i != adj[v].end(); ++i) {\n    if (!visited[*i]) {\n      if (isCyclicUtil(*i, visited, v, adj))\n        return true;\n    } else if (*i != parent)\n      return true;\n  }\n  return false;\n}",
            "DFS for Directed Graphs": "bool isCyclicUtil(int v, bool visited[], bool *recStack, vector<int> adj[]) {\n  if(visited[v] == false) {\n    visited[v] = true;\n    recStack[v] = true;\n    for(auto i = adj[v].begin(); i != adj[v].end(); ++i) {\n      if (!visited[*i] && isCyclicUtil(*i, visited, recStack, adj))\n        return true;\n      else if (recStack[*i])\n        return true;\n    }\n  }\n  recStack[v] = false;\n  return false;\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "DFS for Undirected Graphs": "O(V+E), where V is the number of vertices and E is the number of edges",
              "DFS for Directed Graphs": "O(V+E), similar to undirected graphs but takes into account the direction of edges"
            },
            "Space Complexity": {
              "DFS for Undirected Graphs": "O(V), for storing visited information and recursion stack",
              "DFS for Directed Graphs": "O(V), additionally requires space for the recursion stack and to maintain the recursive call stack for directed graphs"
            }
          }
        }
      },
      {
        "Topic": "Check for Bipartite Graph",
        "Info": {
          "Definition": "A bipartite graph is a graph whose vertices can be divided into two disjoint sets such that every edge connects a vertex in one set to a vertex in the other set. Graphs containing odd-length cycles are not bipartite.",
          "Algorithms": {
            "Using DFS": "bool isBipartiteDFS(vector<vector<int>>& graph) {\n  vector<int> colors(graph.size(), -1);\n  for (int i = 0; i < graph.size(); i++) {\n    if (colors[i] == -1) {\n      if (!dfsCheck(graph, i, colors, 0)) return false;\n    }\n  }\n  return true;\n}\nbool dfsCheck(const vector<vector<int>>& graph, int node, vector<int>& colors, int color) {\n  if (colors[node] != -1) return colors[node] == color;\n  colors[node] = color;\n  for (int next : graph[node]) {\n    if (!dfsCheck(graph, next, colors, 1 - color)) return false;\n  }\n  return true;\n}",
            "Using BFS": "bool isBipartiteBFS(vector<vector<int>>& graph) {\n  vector<int> colors(graph.size(), -1);\n  for (int i = 0; i < graph.size(); i++) {\n    if (colors[i] == -1) {\n      queue<int> q;\n      q.push(i);\n      colors[i] = 0;\n      while (!q.empty()) {\n        int node = q.front(); q.pop();\n        for (int next : graph[node]) {\n          if (colors[next] == -1) {\n            colors[next] = 1 - colors[node];\n            q.push(next);\n          } else if (colors[next] == colors[node]) return false;\n        }\n      }\n    }\n  }\n  return true;\n}"
          },
          "Complexities": {
            "Time Complexity": {
              "Using DFS": "O(V+E), where V is the number of vertices and E is the number of edges in the graph. This reflects the need to visit each vertex and traverse each edge.",
              "Using BFS": "O(V+E), similar to DFS, due to the need to examine each vertex and edge in the graph."
            },
            "Space Complexity": "O(V), for both algorithms, to store the color of each vertex. The DFS uses a recursion stack, and BFS uses a queue, both of which could, in the worst case, contain all V vertices in the graph."
          }
        }
      },
      {
        "Topic": "Bridges in a Graph",
        "Info": {
          "Definition": "In graph theory, a bridge (also known as a cut-edge) is an edge of a graph whose removal increases the graph's number of connected components. Identifying bridges in a graph is crucial in understanding its structure, such as in network connectivity and topology analysis. Bridges indicate points of vulnerability in a network and are important for designing robust networks.",
          "Algorithms": {
            "Finding Bridges Algorithm": "void findBridges(vector<vector<int>>& graph) {\n  vector<int> disc(graph.size(), -1), low(graph.size(), -1);\n  int time = 0;\n  vector<pair<int, int>> bridges;\n  function<void(int, int)> dfs = [&](int u, int parent) {\n    disc[u] = low[u] = time++;\n    for (int v : graph[u]) {\n      if (v == parent) continue;\n      if (disc[v] == -1) { // If v is not visited\n        dfs(v, u);\n        low[u] = min(low[u], low[v]);\n        if (low[v] > disc[u]) {\n          bridges.push_back({u, v});\n        }\n      } else { // Update low value\n        low[u] = min(low[u], disc[v]);\n      }\n    }\n  };\n  for (int i = 0; i < graph.size(); i++) {\n    if (disc[i] == -1) {\n      dfs(i, -1);\n    }\n  }\n  // bridges vector contains all the bridges in the graph\n}",
            "Note": "This algorithm uses Depth-First Search (DFS) to find bridges. The disc and low arrays keep track of discovery times of vertices and the earliest visited vertex reachable from the subtree rooted with the vertex respectively."
          },
          "Complexities": {
            "Time Complexity": "O(V+E), where V is the number of vertices and E is the number of edges in the graph. This complexity arises from the DFS traversal of the graph.",
            "Space Complexity": "O(V), for the storage of disc and low arrays, along with the recursion stack space."
          }
        }
      },
      {
        "Topic": "Vertex Cover Problem",
        "Info": {
          "Definition": "The Vertex Cover Problem is a fundamental problem in graph theory and computer science, where it involves finding a minimum set of vertices in a graph such that each edge of the graph is incident to at least one vertex in the set. The problem is NP-complete, indicating that there is no known polynomial-time solution for finding the minimum vertex cover in a general graph.",
          "Algorithms": {
            "Approximation Algorithm": "vector<int> approximateVertexCover(vector<vector<int>>& graph) {\n  vector<int> vertexCover;\n  vector<bool> visited(graph.size(), false);\n  for (int u = 0; u < graph.size(); u++) {\n    if (!visited[u]) {\n      for (auto v : graph[u]) {\n        if (!visited[v]) {\n          // Add both vertices of the edge to the vertex cover\n          vertexCover.push_back(u);\n          vertexCover.push_back(v);\n          visited[u] = true;\n          visited[v] = true;\n          break; // Move to the next vertex\n        }\n      }\n    }\n  }\n  return vertexCover;\n}",
            "Note": "This approximation algorithm does not guarantee the minimum vertex cover but finds a cover that is within a factor of 2 of the optimal size. The algorithm iterates through each vertex and its edges, adding both the current vertex and one of its adjacent vertices to the vertex cover if they haven't been added yet."
          },
          "Complexities": {
            "Time Complexity": "O(V + E), where V is the number of vertices and E is the number of edges in the graph, as it essentially goes through each edge once.",
            "Space Complexity": "O(V), for storing the vertex cover and visited vertices."
          }
        }
      },
      {
        "Topic": "Hamiltonian Paths",
        "Info": {
          "Definition": "A Hamiltonian path is a path in an undirected or directed graph that visits each vertex exactly once. A Hamiltonian cycle (or circuit) is a Hamiltonian path that is a cycle, meaning the path returns to the starting vertex. Determining whether such paths and cycles exist in a graph is an NP-complete problem, and thus no polynomial-time algorithm is known for all classes of graphs.",
          "Algorithms": {
            "Backtracking Algorithm for Hamiltonian Cycles": "bool hamiltonianCycle(vector<vector<int>>& graph) {\n  vector<int> path(graph.size(), -1);\n  path[0] = 0; // start from the first vertex\n  if (hamCycleUtil(graph, path, 1) == false) {\n    return false;\n  }\n  printPath(path);\n  return true;\n}\nbool hamCycleUtil(vector<vector<int>>& graph, vector<int>& path, int pos) {\n  if (pos == graph.size()) {\n    if (graph[path[pos-1]][path[0]] == 1) return true;\n    else return false;\n  }\n  for (int v = 1; v < graph.size(); v++) {\n    if (isSafe(v, graph, path, pos)) {\n      path[pos] = v;\n      if (hamCycleUtil(graph, path, pos + 1) == true) return true;\n      path[pos] = -1; // backtrack\n    }\n  }\n  return false;\n}",
            "isSafe Function": "bool isSafe(int v, vector<vector<int>>& graph, vector<int>& path, int pos) {\n  if (graph[path[pos - 1]][v] == 0) return false;\n  for (int i = 0; i < pos; i++) {\n    if (path[i] == v) return false;\n  }\n  return true;\n}"
          },
          "Complexities": {
            "Time Complexity": "O(n!), where n is the number of vertices in the graph. The factorial time complexity is due to the need to generate all possible vertex sequences.",
            "Space Complexity": "O(n), for the recursion stack and the path array where n is the number of vertices in the graph."
          }
        }
      },
      {
        "Topic": "Topological sorting in DAG",
        "Info": {
          "Definition": "Topological sorting of a Directed Acyclic Graph (DAG) is a linear ordering of vertices such that for every directed edge uv, vertex u comes before v in the ordering. Topological Sorting for a graph is not possible if the graph is not a DAG. This sorting is useful for scheduling tasks, resolving symbol dependencies in compilers, and more.",
          "Algorithms": {
            "Kahn's Algorithm": "vector<int> in_degree(V, 0);\nfor (int u = 0; u < V; u++) {\n  for (int v : adj[u])\n    in_degree[v]++;\n}\nqueue<int> q;\nfor (int i = 0; i < V; i++)\n  if (in_degree[i] == 0)\n    q.push(i);\nint cnt = 0;\nvector<int> top_order;\nwhile (!q.empty()) {\n  int u = q.front();\n  q.pop();\n  top_order.push_back(u);\n  for (int v : adj[u])\n    if (--in_degree[v] == 0)\n      q.push(v);\n  cnt++;\n}\nif (cnt != V) {\n  cout << \"There exists a cycle in the graph\\n\";\n  return;\n}",
            "DFS Based Algorithm": "void dfs(int v, vector<bool> &visited, stack<int> &Stack, vector<int> adj[]) {\n  visited[v] = true;\n  for (int i : adj[v])\n    if (!visited[i])\n      dfs(i, visited, Stack, adj);\n  Stack.push(v);\n}\nvoid topologicalSort(vector<int> adj[], int V) {\n  stack<int> Stack;\n  vector<bool> visited(V, false);\n  for (int i = 0; i < V; i++)\n    if (!visited[i])\n      dfs(i, visited, Stack, adj);\n  while (!Stack.empty()) {\n    cout << Stack.top() << \" \";\n    Stack.pop();\n  }\n}"
          },
          "Complexities": {
            "Time Complexities": {
              "Kahn's Algorithm": "O(V+E) - Where V is the number of vertices and E is the number of edges in the graph",
              "DFS Based Algorithm": "O(V+E) - Similar as above, considering the graph traversal for all vertices and their adjacent vertices"
            },
            "Space Complexity": "O(V) - Additional space for data structures like in-degree array, stack, or queue, depending on the algorithm"
          }
        }
      },
      {
        "Topic": "Ford-Fulkerson Algorithm",
        "Info": {
          "Definition": "The Ford-Fulkerson algorithm computes the maximum flow in a flow network. It initializes the flow to 0 and repeatedly increases it by finding augmenting paths from the source to the sink. The process continues until no augmenting paths are left.",
          "Algorithms": {
            "Code": "int fordFulkerson(int graph[V][V], int s, int t) {\n    int u, v;\n    int rGraph[V][V];\n    for (u = 0; u < V; u++)\n        for (v = 0; v < V; v++)\n             rGraph[u][v] = graph[u][v];\n    int parent[V];\n    int max_flow = 0;\n    while (bfs(rGraph, s, t, parent)) {\n        int path_flow = INT_MAX;\n        for (v = t; v != s; v = parent[v]) {\n            u = parent[v];\n            path_flow = min(path_flow, rGraph[u][v]);\n        }\n        for (v = t; v != s; v = parent[v]) {\n            u = parent[v];\n            rGraph[u][v] -= path_flow;\n            rGraph[v][u] += path_flow;\n        }\n        max_flow += path_flow;\n    }\n    return max_flow;\n}"
          },
          "Complexities": {
            "Time Complexity": "O(max_flow * E), where E is the number of edges. The algorithm runs while there are augmenting paths, and each path can add at most 'max_flow' amount of flow.",
            "Space Complexity": "O(V^2), as it requires storing the residual graph."
          }
        }
      },
      {
        "Topic": "Rabin-Karp Algorithm",
        "Info": {
          "Definition": "The Rabin-Karp Algorithm is a string-searching algorithm that uses hashing to find any one of a set of pattern strings in a text. It is particularly useful for detecting multiple patterns in a text in a single pass. The algorithm matches the hash value of the pattern with the hash value of current substring of the text, and if the hash values match, it then checks for individual character matches.",
          "Algorithms": {
            "Code": "void rabinKarp(string const& s, string const& t) {\n    const int p = 31;\n    const int m = 1e9 + 9;\n    int S = s.size(), T = t.size();\n\n    vector<long long> p_pow(max(S, T));\n    p_pow[0] = 1;\n    for (int i = 1; i < (int)p_pow.size(); i++)\n        p_pow[i] = (p_pow[i-1] * p) % m;\n\n    vector<long long> h(T + 1, 0);\n    for (int i = 0; i < T; i++)\n        h[i+1] = (h[i] + (t[i] - 'a' + 1) * p_pow[i]) % m;\n\n    long long h_s = 0;\n    for (int i = 0; i < S; i++)\n        h_s = (h_s + (s[i] - 'a' + 1) * p_pow[i]) % m;\n\n    for (int i = 0; i + S - 1 < T; i++) { \n        long long cur_h = (h[i+S] + m - h[i]) % m; \n        if (cur_h == h_s * p_pow[i] % m)\n            cout << \"Pattern found at index: \" << i << endl;\n    }\n}"
          },
          "Complexities": {
            "Time Complexity": "Average and best case is O(n+m), where n is the length of text and m is the length of the pattern, but its worst case is O(nm), which occurs when all characters of the pattern and text are same as the hash value of all the substrings of the text will be same.",
            "Space Complexity": "O(n), where n is the length of the text, to store the hash values of all possible substrings of the text."
          }
        }
      },
      {
        "Topic": "Fibonacci Heap",
        "Info": {
          "Definition": "A Fibonacci Heap is a data structure for priority queue operations, consisting of a collection of heap-ordered trees. It has a better amortized running time than many other priority queue data structures including the binary heap and binomial heap.",
          "Algorithms": {
            "Code": "struct Node {\n    int key;\n    Node *prev, *next;\n    Node *child, *parent;\n    int degree;\n    bool marked;\n};\n\n// Initial creation of a Fibonacci heap\nNode* createHeap() {\n    Node* np = nullptr;\n    return np;\n}\n\n// Insertion operation in a Fibonacci heap\nvoid insert(Node* &heap, Node* node) {\n    // Implementation details\n}\n\n// Decrease key operation in a Fibonacci heap\nvoid decreaseKey(Node* &heap, Node* node, int new_val) {\n    // Implementation details\n}\n\n// Delete node operation from a Fibonacci heap\nvoid deleteNode(Node* &heap, Node* node) {\n    // Implementation details\n}"
          },
          "Complexities": {
            "Time Complexity": {
              "Insert": "O(1)",
              "Decrease Key": "O(1) amortized",
              "Delete Node": "O(log n) amortized"
            },
            "Space Complexity": "O(n), where n is the number of elements in the heap."
          }
        }
      },
      {
        "Topic": "Decrease Key and Delete Node from Fibonacci Heap",
        "Info": {
          "Definition": "In a Fibonacci Heap, the decrease key operation decreases the value of a given node, potentially breaking the heap property and requiring a cut and cascading cut operations. The delete node operation involves decreasing the value of the node to negative infinity (or a value lower than any heap element), thus moving it to the root list, and then performing a delete minimum operation.",
          "Algorithms": {
            "DecreaseKey Code": "void decreaseKey(Node* &heap, Node* node, int new_val) {\n    if (heap == nullptr || node == nullptr) return;\n    if (node->key < new_val) {\n        cout << \"New key is greater than current key\";\n        return;\n    }\n    node->key = new_val;\n    Node* parent = node->parent;\n    if (parent != nullptr && node->key < parent->key) {\n        cut(heap, node, parent);\n        cascadingCut(heap, parent);\n    }\n    if (node->key < heap->key) {\n        heap = node;\n    }\n}",
            "DeleteNode Code": "void deleteNode(Node* &heap, Node* node) {\n    decreaseKey(heap, node, INT_MIN);\n    Node* min = removeMin(heap);\n    // Assuming removeMin removes and returns the minimum element from the heap\n}"
          },
          "Complexities": {
            "Time Complexity": "Decrease Key: O(1) amortized, Delete Node: O(log n) amortized",
            "Space Complexity": "O(1), assuming no additional space is required apart from the input."
          }
        }
      },
      {
        "Topic": "Bellman-Ford Algorithm",
        "Info": {
          "Definition": "The Bellman-Ford algorithm computes shortest paths from a single source vertex to all of the other vertices in a weighted graph. It is capable of handling graphs in which some of the edge weights are negative.",
          "Algorithms": {
            "Code": "int V, E; // V is the number of vertices and E is the number of edges\nstruct Edge { int u, v, w; };\nvector<Edge> edges;\n// Initialization\nvector<int> dist(V, INT_MAX);\ndist[src] = 0;\n// Relaxation\nfor(int i = 0; i < V-1; i++)\n  for(auto &edge : edges)\n    if(dist[edge.u] + edge.w < dist[edge.v])\n      dist[edge.v] = dist[edge.u] + edge.w;\n// Check for negative-weight cycles\nfor(auto &edge : edges)\n  if(dist[edge.u] + edge.w < dist[edge.v])\n    throw \"Graph contains a negative-weight cycle\";"
          },
          "Complexities": {
            "Time Complexity": "O(VE) - As it relaxes all edges V-1 times.",
            "Space Complexity": "O(V) - For storing distance and predecessor arrays."
          }
        }
      },
      {
        "Topic": "Strongly Connected Components (SCC)",
        "Info": {
          "Definition": "In a directed graph, a strongly connected component is a maximal set of vertices such that each pair of vertices is reachable from the other, i.e., each vertex in the set is reachable from every other vertex in the set.",
          "Algorithms": {
            "Code": "class Graph {\npublic:\n    int V; // Vertices\n    list<int> *adj; // Adjacency list\n    Graph(int V) { this->V = V; adj = new list<int>[V]; }\n    void addEdge(int v, int w) { adj[v].push_back(w); }\n    void fillOrder(int v, bool visited[], stack<int> &Stack);\n    void DFSUtil(int v, bool visited[]);\n    void printSCCs();\n    Graph getTranspose();\n};\n\nvoid Graph::DFSUtil(int v, bool visited[]) {\n    visited[v] = true;\n    list<int>::iterator i;\n    for(i = adj[v].begin(); i != adj[v].end(); ++i)\n        if(!visited[*i])\n            DFSUtil(*i, visited);\n}\n\nGraph Graph::getTranspose() {\n    Graph g(V);\n    for(int v = 0; v < V; v++)\n        for(list<int>::iterator i = adj[v].begin(); i != adj[v].end(); ++i)\n            g.adj[*i].push_back(v);\n    return g;\n}\n\n// Methods fillOrder and printSCCs to be implemented as per Kosaraju's algorithm steps."
          },
          "Complexities": {
            "Time Complexity": "O(V+E) for both Tarjan's and Kosaraju's algorithms. This is because each edge and vertex in the graph is visited once during the depth-first search process.",
            "Space Complexity": "O(V) for Tarjan's algorithm due to the stack and O(V+E) for Kosaraju's due to the need to store the transpose graph. Additionally, both algorithms require O(V) space for the visited array."
          }
        }
      }
    ]
  }
]
